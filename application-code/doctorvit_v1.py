# -*- coding: utf-8 -*-
"""DoctorVIT_V1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OLGaxTQZl7haB0cU7ZHRnx5V1rN4PNmE
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install python-dotenv

import os
from dotenv import load_dotenv

env_path = '/content/drive/MyDrive/neuroweave.env'

if not os.path.isfile(env_path):
    raise FileNotFoundError(f"Couldn’t find neuroweave.env at:\n  {env_path}\n"
                            "Please confirm the path by inspecting the ls output above.")
load_dotenv(env_path, override=True)

github_user  = os.environ.get('GITHUB_USER')
github_token = os.environ.get('GITHUB_TOKEN')

if not (github_user and github_token):
    raise RuntimeError("Loaded env file, but variables are still missing.")

!pip install git+https://${GITHUB_USER}:${GITHUB_TOKEN}@github.com/ajaviaad/neuronmix.git@main

model_path = "/content/drive/MyDrive/neuroweave"

!unzip /content/drive/MyDrive/transformers.zip -d /content/custom_transformers
import sys
sys.path.insert(0, "/content/custom_transformers")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/custom_transformers/transformers-main

!pip install -e .

import sys
sys.path.insert(0, "/content/custom_transformers/transformers-main/src")

pip install duckduckgo-search

!pip install -q transformers accelerate newspaper3k requests beautifulsoup4
!python -m nltk.downloader punkt -q

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_path = "/content/drive/MyDrive/neuroweave"

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map=None,
    torch_dtype=torch.float16,
    trust_remote_code=True
).to("cuda")

generator = pipeline("text-generation", model=model, tokenizer=tokenizer, device=0)

import os
import sys
import contextlib
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from neuronmix import neuroweave

@contextlib.contextmanager
def suppress_stdout():
    with open(os.devnull, "w") as devnull:
        old_stdout = sys.stdout
        sys.stdout = devnull
        try:
            yield
        finally:
            sys.stdout = old_stdout

model_path = "/content/drive/MyDrive/neuroweave"
device = torch.device("cuda:0")
dtype = torch.float16

with suppress_stdout():
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=dtype,
        low_cpu_mem_usage=True
    )
    tokenizer = AutoTokenizer.from_pretrained(model_path)

model.to(device)
model.eval()

with suppress_stdout():
    neuroweave(model, init_beta=1.2)

if tokenizer.pad_token_id is None:
    tokenizer.pad_token = tokenizer.eos_token

for n, p in model.named_parameters():
    if p.requires_grad and not p.is_cuda:
        raise RuntimeError(f"{n} is on CPU")
for n, b in model.named_buffers():
    if b.numel() and not b.is_cuda:
        raise RuntimeError(f"{n} buffer is on CPU")

print("[ok] All params & buffers are on", device)

from neuronmix import neuroweave
neuroweave(model, init_beta=1.2, patch_emb=True, patch_lm=True);

import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime

def duckduckgo_search(query, max_results=5):
    url = f"https://html.duckduckgo.com/html/?q={query}"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")

    results = []
    for result in soup.select(".result")[:max_results]:
        title = result.select_one(".result__a")
        snippet = result.select_one(".result__snippet")

        if title:
            text = title.text.strip()
            if snippet:
                text += f" – {snippet.text.strip()}"
            href = title.get("href")
            results.append({"body": text, "href": href})
    return results

def extract_years(text: str):
    return [int(y) for y in re.findall(r'\b20\d{2}\b', text)]

def generator_relevance_score(query: str, snippet_text: str) -> float:
    prompt = f"""Decide if the following snippet is relevant to the query.
Query: {query}
Snippet: {snippet_text}
Answer with only "Relevant" or "Irrelevant"."""

    output = generator(prompt, max_new_tokens=10, do_sample=False)[0]["generated_text"]
    output = output.lower()

    if "relevant" in output and "irrelevant" not in output:
        return 1.0
    elif "irrelevant" in output:
        return 0.0
    else:
        return 0.5

def select_snippet(query: str, snippets: list[dict], min_score=0.0) -> dict:
    if not snippets:
        return {"body": "No valid snippet", "href": ""}

    scored = []
    for s in snippets:
        body = s["body"]
        years = extract_years(body)
        most_recent_year = max(years) if years else 0

        score = generator_relevance_score(query, body)

        if score >= min_score:
            scored.append({
                "body": body,
                "href": s.get("href", ""),
                "year": most_recent_year,
                "relevance": score
            })

    if not scored:
        return {"body": "No relevant snippet found", "href": ""}

    max_year = max(item["year"] for item in scored)
    freshest = [item for item in scored if item["year"] == max_year]
    candidates = freshest if max_year > 0 else scored
    best = max(candidates, key=lambda item: item["relevance"])
    return {"body": best["body"], "href": best["href"]}

import re

def _strip_leading_markers(text: str) -> str:
    text = re.sub(r"^\s*(Explanation:|Answer:)\s*", "", text, flags=re.IGNORECASE)
    for bad in [
        "Explanation:",
        "Background:",
        "Relevance:",
        "Answer:",
        "Response:",
        "Question:",
        "Based on the above",
        "The snippet",
        "According to",
        "The passage",
        "The document",
    ]:
        text = re.sub(rf"^(?:{re.escape(bad)})\s*", "", text, flags=re.IGNORECASE)
    return text

_INTERNAL_SECTION_CLEAN = re.compile(r"(?is)(Verifier\s*\(internal[^)]*\)\s*:.*$|Reasoning\s*\(internal[^)]*\)\s*:.*$)")

def _strip_internal_sections(text: str) -> str:
    return _INTERNAL_SECTION_CLEAN.sub("", text).strip()

def _cut_at_end_token(text: str) -> str:
    if "<<<END>>>" in text:
        return text.split("<<<END>>>")[0].strip()
    return text

def _looks_incomplete(text: str) -> bool:
    if not text or len(text) < 10:
        return True
    if text.endswith(("...", "…", "-", "—", ":", ";", ",")):
        return True
    if re.search(r"\[[^\]]*$", text):
        return True
    if not re.search(r"[.!?]\s*$", text):
        return True
    return False

def generate(prompt: str, *args, **kwargs) -> str:
    def _gen(p):
        r = generator(
            p,
            max_new_tokens=3072,
            repetition_penalty=1.0,
            early_stopping=False,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id,
            temperature=0.0,
            do_sample=False,
            top_p=1.0,
        )
        o = r[0]["generated_text"]
        if o.startswith(p):
            o = o[len(p):]
        o = _strip_leading_markers(o)
        o = _cut_at_end_token(o)
        o = _strip_internal_sections(o)
        return o.strip()
    out = _gen(prompt)
    if _looks_incomplete(out):
        reinforce = (
            "\n\nIMPORTANT: Ensure the answer is COMPLETE, self-contained, avoids repetition, and ends with the exact token <<<END>>>. "
            "If you wrote steps, provide 8–12 bulleted steps with full sentences using the bullet symbol •. Do not cite sources."
        )
        out = _gen(prompt + reinforce)
    if "<<<END>>>" in out or _looks_incomplete(out):
        tail_prompt = (
            f"\n\nYou stopped early. Continue and finish the answer below without repeating previous text. "
            f"Ensure completeness (no duplication), then end with <<<END>>>. Do not cite sources.\n\nSo far:\n{out}\n\nContinuation:"
        )
        out2 = _gen(tail_prompt)
        if out2:
            out = out + ("\n" if not out.endswith("\n") else "") + out2
    out = _cut_at_end_token(out).strip()
    out = _strip_internal_sections(out)
    return out

import difflib

def is_low_information(output: str, prompt: str) -> bool:
    output = output.strip().lower()
    if len(output.split()) < 8:
        return True

    deflect_starts = [
        "the snippet does not", "the snippet only", "the text doesn't mention",
        "it is not included", "it is not listed", "no information"
    ]

    if any(output.startswith(p) for p in deflect_starts):
        return True

    import difflib
    similarity = difflib.SequenceMatcher(None, prompt.lower(), output).ratio()
    if similarity > 0.9:
        return True

    return False

import re

def clean_output(text: str) -> str:
    cleaned = re.sub(r'\s?[\(\[]\d{1,3}[\)\]]', '', text)

    cleaned = re.sub(r'\s{2,}', ' ', cleaned)

    return cleaned.strip()

import re
!pip install --quiet gradio>=4.0 rapidfuzz wordfreq requests beautifulsoup4 lxml
import html, re, traceback, os, socket, contextlib, json, difflib
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlencode, urlparse

from collections import defaultdict
import re as _re

_MLP_CANDIDATES = (
    "mlp", "ffn", "ff", "feed_forward", "feedforward",
    "gated_mlp", "glu_block", "swiGLU", "mlp_block"
)
_ACT_ATTRS = ("act_fn", "activation", "activation_fn", "act")
_KNOWN_ACT_MODULES = {
    "ReLU", "GELU", "SiLU", "Swish", "Tanh", "Sigmoid",
    "PhantomAct", "AutoMixedActivation", "NeuroweaveActivation", "Phasor",
    "SwiGLU", "GLU"
}

def _all_modlists(root):
    import torch.nn as nn
    for name, mod in root.named_modules():
        if isinstance(mod, nn.ModuleList) and len(mod) > 0:
            yield name, mod

def _pick_block_list(model):
    import torch.nn as nn
    candidate_paths = [
        "model.layers", "model.model.layers", "model.decoder.layers",
        "transformer.layers", "transformer.h", "decoder.layers", "encoder.layers"
    ]
    cur = model
    for dotted in candidate_paths:
        ok, cur = True, model
        for part in dotted.split("."):
            if not hasattr(cur, part):
                ok = False; break
            cur = getattr(cur, part)
        if ok and isinstance(cur, (list, nn.ModuleList)) and len(cur) > 0:
            return dotted, list(cur)
    best_path, best_list = None, []
    for path, mlist in _all_modlists(model):
        if len(mlist) > len(best_list):
            best_path, best_list = path, list(mlist)
    return best_path, best_list

def _find_activation_in_block(block):
    for attr in _ACT_ATTRS:
        if hasattr(block, attr):
            obj = getattr(block, attr)
            return getattr(obj, "__class__", type(obj)).__name__
    for child_name in _MLP_CANDIDATES:
        if hasattr(block, child_name):
            sub = getattr(block, child_name)
            for attr in _ACT_ATTRS:
                if hasattr(sub, attr):
                    obj = getattr(sub, attr)
                    return getattr(obj, "__class__", type(obj)).__name__
    for name, sub in block.named_modules():
        cls = sub.__class__.__name__
        if cls in _KNOWN_ACT_MODULES:
            return cls
    return "Unknown"

def validate_activation_wiring(model):
    path, blocks = _pick_block_list(model)
    layers_info = []
    for i, blk in enumerate(blocks):
        act_cls = _find_activation_in_block(blk)
        layers_info.append({"index": i, "activation": act_cls})
    unique = sorted(set(x["activation"] for x in layers_info)) if layers_info else []
    summary = (
        f"Detected activation modules across layers: {unique} "
        f"(layers={len(layers_info)}) via '{path or '<largest ModuleList or none>'}'"
    )
    return {
        "block_path": path,
        "layers": layers_info,
        "unique": unique,
        "summary": summary,
    }

def assert_all_layers_use(model, required_substring: str):
    rep = validate_activation_wiring(model)
    mismatches = [x for x in rep["layers"] if required_substring not in x["activation"]]
    if mismatches:
        details = ", ".join(f"L{x['index']}:{x['activation']}" for x in mismatches[:10])
        raise AssertionError(
            f"Expected all layers to include '{required_substring}', but found mismatches: {details} "
            f"(unique={rep['unique']}, block_path={rep['block_path']})"
        )
    return rep

TITLE = "DoctorVIT"
DESC = "Ask your healthcare question"

def _pick_port(start=7860, limit=30):
    for p in range(start, start + limit):
        with contextlib.closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
            if s.connect_ex(("127.0.0.1", p) ) != 0:
                return p
    return start

def _free_port(port):
    os.system(f"fuser -k {port}/tcp >/dev/null 2&>1 || true")
    os.system(f"lsof -ti tcp:{port} | xargs -r kill -9 >/dev/null 2&>1 || true")

def _reg_domain(netloc: str) -> str:
    netloc = netloc.split(":")[0].lower()
    parts = [p for p in netloc.split(".") if p]
    if len(parts) >= 3 and (parts[-2] in {"co","ac","gov","nhs"} and parts[-1] in {"uk","nz"}):
        return ".".join(parts[-3:])
    if len(parts) >= 2:
        return ".".join(parts[-2:])
    return netloc

_CREDIBLE_DOMAINS = {
    "who.int","cdc.gov","nhs.uk","nice.org.uk","ema.europa.eu","fda.gov",
    "aafp.org","merckmanuals.com","bmj.com","nejm.org","thelancet.com",
    "medscape.com","bnf.nice.org.uk","drugs.com","webmd.com","mayoclinic.org"
}

def _is_credible(url: str) -> bool:
    try:
        d = _reg_domain(urlparse(url).netloc)
        return d in _CREDIBLE_DOMAINS
    except Exception:
        return False

def duckduckgo_search(query):
    headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://duckduckgo.com/"}
    url = "https://duckduckgo.com/html/?" + urlencode({"q": query, "kl":"wt-wwo"})
    try:
        r = requests.get(url, headers=headers, timeout=15)
    except Exception:
        return []
    results = []
    if r.status_code != 200:
        return results
    soup = BeautifulSoup(r.text, "lxml")
    for res in soup.select(".result__body"):
        a = res.select_one(".result__a")
        s = res.select_one(".result__snippet")
        if not a:
            continue
        href = a.get("href","")
        title = a.get_text(" ", strip=True)
        snippet = s.get_text(" ", strip=True) if s else ""
        results.append({"title": title, "url": href, "body": snippet})
    return results

def select_snippet(query, results):
    credible = [r for r in results if _is_credible(r.get("url",""))]
    return credible[0] if credible else (results[0] if results else {"body": "", "title":"", "url":""})

def _pre(x: str) -> str:
    x = html.unescape(x or "").strip()
    x = re.sub(r"\s+", " ", x)
    return x

def build_answer_prompt(query, snippet_text):
    q = _pre(query)
    s = _pre(snippet_text or "")
    return (
        f"{s}\n\n"
        "You are a board-certified specialist clinician. Answer deterministically, directly, and without deferring. "
        "Use Title Case section headings that end with a colon. "
        "Write ONLY two sections: 'Specialist Advice:' (one compact paragraph of 4–6 sentences) and 'Disclaimer:'. "
        "In 'Specialist Advice:' cover succinct evaluation with differential priorities and red flags; initial tests with explicit decision thresholds; "
        "first-line pharmacologic options with typical adult dose/route/frequency and major contraindications/interactions; and escalation/referral triggers. "
        "No bullets, numbered lists, tables, or emojis. End exactly with <<<END>>>."
        f"\n\nQuestion: {q}\nAnswer:"
    )


def _mk(role_desc, rules, sections, directive, s, q):
    ctx = f"\n[CONTEXT — DO NOT ECHO]\n{q}\n[/CONTEXT]\n"
    return (
        f"{s}\n\n"
        f"{role_desc}\n"
        "Output Rules:\n"
        + "\n".join(f"- {r}" for r in rules) +
        "\n\nSections (in order):\n" +
        sections + "\n" +
        ctx +
        f"{directive}\n<<<END>>>"
    )

import re
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple

_AUDIENCE_CLINICAL_RE = re.compile(
    r"(?ix)"
    r"\b(physician|doctor|clinician|nurse|rn|pa|np|resident|attending|fellow|med\s*student|"
    r"specialist|consult|rounds?|dispo|admit|work[-\s]?up|ddx|differential|hemodynamic|"
    r"troponin|ecg|ekg|pci|stemi|nstemi|grace|timi|abg|pft|spirometr|fev1|"
    r"iv|im|po|pr|q\d+h|bpm|mmhg|l/min|o2|spo2|bolus|infusion|titration|"
    r"mg|mcg|g/ ?dl|mmol/l|kdigo|acc/?aha|esc|gina|gold|dsm[- ]5|icd[- ]10|cpt|"
    r"stat\s+labs?|trend\s+labs?|cath\s*lab|rapid\s*sequence|rx|tx|dx|sx)\b"
)

def _is_clinical_audience(text: str) -> bool:
    q_text = unicodedata.normalize("NFKC", text or "")
    if _is_insurance_audience(q_text):
        return False
    pattern = re.compile(
        r'\b(?:'
        r'i\s*am\s+(?:a\s+)?clinician|'
        r'i\s*want\s+(?:a\s+)?clinical|'
        r'you\s*are\s+(?:a\s+)?clinician|'
        r'give\s*me\s+(?:a\s+)?clinical|'
        r'tell\s*(?:me\s+)?(?:a\s+)?clinical|'
        r'\w*(?:clinically|clinical|clinician)\w*'
        r')\b', re.I
    )
    return bool(pattern.search(q_text))

import re, unicodedata
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict

@dataclass(frozen=True)
class SenseRule:
    label: str
    positives: List[re.Pattern]
    negatives: List[re.Pattern]
    window: int = 60
    base: float = 0.0
    weight_pos: float = 1.0
    weight_neg: float = 1.0
    case_sensitive: bool = False
    priority: int = 0

@dataclass(frozen=True)
class AmbiguousToken:
    token: re.Pattern
    senses: List[SenseRule]
    default_label: Optional[str] = None

class ContextualDisambiguationRouter:
    _NEAR_NEGATION_RE = re.compile(r"\b(no|not|without|rule\s*out|den(y|ies|ied)|free\s*of|negative\s*for)\b", re.I)

    def __init__(self, rules: List[AmbiguousToken]):
        self.rules = rules

    @staticmethod
    def _norm(text: str) -> str:
        t = unicodedata.normalize("NFKC", text or "")
        t = t.replace("\u2013","-").replace("\u2014","-").replace("\u2212","-")
        t = t.replace("\u2019","'").replace("\u2018","'").replace("\u02BC","'")
        return t

    @staticmethod
    def _decay(center: int, pos: int) -> float:
        d = abs(pos - center)
        return 1.0 / (1.0 + d * 0.05)

    def _window_slice(self, text: str, start: int, end: int, w: int) -> Tuple[str, int, int, int]:
        N = len(text)
        lo = max(0, start - w)
        hi = min(N, end + w)
        center = (start + end) // 2
        return text[lo:hi], lo, hi, center

    def _score_with_patterns(self, hay: str, base_index: int, center: int, pats: List[re.Pattern]) -> float:
        score = 0.0
        for p in pats:
            try:
                for m in p.finditer(hay):
                    mid = base_index + (m.start() + m.end()) // 2
                    score += self._decay(center, mid)
            except Exception:
                continue
        return score

    def _score_span(self, text: str, low: str, span: Tuple[int, int], rule: SenseRule) -> float:
        start, end = span
        ctx, base_idx, _, center = self._window_slice(text, start, end, rule.window)
        if rule.case_sensitive:
            hay, near = ctx, text
        else:
            hay, near = low[base_idx:base_idx+len(ctx)], low
        pos_score = self._score_with_patterns(hay, base_idx, center, rule.positives)
        neg_score = self._score_with_patterns(hay, base_idx, center, rule.negatives)
        lo = max(0, center - 8)
        hi = min(len(near), center + 8)
        if self._NEAR_NEGATION_RE.search(near[lo:hi]):
            neg_score += 0.5
        return rule.base + rule.weight_pos * pos_score - rule.weight_neg * neg_score

    def resolve_scored(self, text: str) -> List[Dict]:
        out = []
        raw = self._norm(text or "")
        low = raw.lower()
        for amb in self.rules:
            try:
                token_iter = list(amb.token.finditer(raw))
            except Exception:
                continue
            for m in token_iter:
                best_tuple = None
                best_score = None
                for s in amb.senses:
                    try:
                        sc = self._score_span(raw, low, (m.start(), m.end()), s)
                    except Exception:
                        sc = float("-inf")
                    tie = s.label
                    cand = (sc, s.priority, tie, s.label)
                    if (best_tuple is None) or (cand > best_tuple):
                        best_tuple, best_score = cand, sc
                if best_tuple is not None:
                    label = best_tuple[3]
                    if best_score is not None and best_score > 0:
                        out.append({"token": amb.token.pattern, "span": (m.start(), m.end()), "label": label, "score": round(float(best_score), 3)})
                    elif amb.default_label is not None:
                        out.append({"token": amb.token.pattern, "span": (m.start(), m.end()), "label": amb.default_label, "score": 0.0})
        return out

    def resolve(self, text: str) -> Dict[str, str]:
        raw = self._norm(text or "")
        low = raw.lower()
        out: Dict[str, str] = {}
        for amb in self.rules:
            try:
                token_iter = list(amb.token.finditer(raw))
            except Exception:
                continue
            for m in token_iter:
                best_tuple = None
                best_score = None
                for s in amb.senses:
                    try:
                        sc = self._score_span(raw, low, (m.start(), m.end()), s)
                    except Exception:
                        sc = float("-inf")
                    tie = s.label
                    cand = (sc, s.priority, tie, s.label)
                    if (best_tuple is None) or (cand > best_tuple):
                        best_tuple, best_score = cand, sc
                if best_tuple is not None:
                    chosen = best_tuple[3]
                    if best_score is not None and best_score > 0:
                        out[amb.token.pattern] = chosen
                    elif amb.default_label is not None:
                        out[amb.token.pattern] = amb.default_label
                elif amb.default_label is not None:
                    out[amb.token.pattern] = amb.default_label
        return out

_EXPLICIT_SPECIALIST_RE = re.compile(r"""(?ix)
(
  \bfor\s+(?:clinicians?|doctors?|physicians?|providers?|hcps?|medical\s+professionals?)\b
| \b(?:specialist|clinical)\s+(?:advice|details?|version|write[-\s]*up|guidance)\b
| \bi\s*(?:am|'m|work\s+as)\s+(?:an?\s+)?(?:doctor|physician|clinician|provider
    |nurse(?:\s*practitioner)?|np|pa|physician\s+assistant
    |pharmacist|dentist|surgeon|paramedic|emt
    |medical\s+student|resident|intern|fellow|attending|consultant(?:\s+physician)?
    |registrar|house\s*officer|sho|gp|general\s+practitioner)\b
| \bact\s+as\s+(?:an?\s+)?(?:specialist|doctor|physician|provider)\b
| \b(?:write|give|produce|draft)\s+(?:an?\s+)?(?:clinical|specialist)\s+
    (?:note|summary|assessment|plan|work[-\s]?up|ddx|h&?p|soap\s*note|progress\s*note
     |admit\s*note|discharge\s*summary|operative\s*note)\b
| \bfrom\s+a\s+clinical\s+(?:perspective|standpoint|angle)\b
| \bboard[-\s]?certified\b
| ,\s?(?-i:MBBS|MBChB|MRCP|FRCP|MRCS|FRCS|FRCPath|FACS|FACEP|FAAEM|FCCP|FACP
        |DMD|DDS|PharmD|RN|LPN|LVN|PA\-?C|CNM|CRNA|MD|D\.?O\.?)\b
)
""")

_HEME_PAT = re.compile(r"(?i)\b(hematolog(?:y|ist)|cbc\b|complete\s*blood\s*count|hemoglobin|hematocrit|wbc\b|platelets?|thrombocyt\w*|neutrophils?|lymphocytes?|mcv|rdw|peripheral\s*smear)\b")
_LABS_PAT = re.compile(r"(?i)\b(cmp\b|bmp\b|metabolic\s*panel|lfts?\b|liver\s*function\s*tests?|alt\b|ast\b|alk(?:aline)?\s*phos|bilirubin|bun\b|creatinine|electrolytes?|na\b|k\b|cl\b|co2\b|bicarb|glucose(?:\s*fasting)?|a1c\b|tsh\b|t3\b|t4\b|lipid\s*panel|cholesterol|ldl\b|hdl\b|triglycerides?)\b")

_SPECIALTY_NAMES = (
    "_PSYCH_PAT","_MEDIT_PAT","_DERM_PAT","_DENT_PAT","_ONC_PAT","_WOMEN_PAT","_GYN_PAT",
    "_PHYSIO_PAT","_NUTR_PAT","_COGN_PAT","_ENT_PAT","_ORTHO_PAT","_GI_PAT","_PULM_PAT",
    "_RAD_PAT","_LABTECH_PAT","_TX_PLAN_PAT","_PEDI_PAT","_CARDIO_PAT","_NEURO_PAT",
    "_NEUROSURG_PAT","_PAINMGMT_PAT","_URO_PAT","_NEPH_PAT","_PHARM_PAT","_HEME_PAT","_LABS_PAT",
    "_GENOMICS_PAT","_BIOTECH_PAT","_INTERNAL_MED_PAT"
)

def _is_specialist_audience(text: str) -> bool:
    if not isinstance(text, str):
        return False
    q = unicodedata.normalize("NFC", text)
    if _EXPLICIT_SPECIALIST_RE.search(q):
        return True
    ql = q.lower()
    if re.search(r"\byou\s*(?:are|'re)\s+(?:an?\s+)?specialist\b", ql):
        return True
    pats = []
    for name in _SPECIALTY_NAMES:
        obj = globals().get(name)
        if isinstance(obj, re.Pattern):
            pats.append(obj)
    for pat in pats:
        try:
            if pat.search(ql):
                return True
        except Exception:
            continue
    try:
        f = globals().get("_is_clinical_audience")
        if callable(f) and f(text):
            return True
    except Exception:
        pass
    return False

import re as _re

_EXPLICIT_INSURANCE_RE = _re.compile(
    r"""(?ix)
(
  \bfor\s+(?:insurance|benefits|billing|coding|revenue\s+cycle|payer|claims?)\s+(?:help|guidance|team|specialist|agent|rep|navigator)\b
| \b(?:insurance|benefits|coverage)\s+navigator\b
| \bbenefits?\s+verification\b|\bVOB\b
| \bprior\s+authori[sz]ation\b|\bPA\b(?!\s*system)
| \bclaims?\s+(?:appeal|denial|reconsideration|grievance)\b
| \bmedical\s+billing\b|\bcoding\b(?!\s*interview)
| \bpharmacy\s+benefits?\b|\bPBM\b|\bformulary\b
| \b(?:Medicare|Medicaid|CMS)\b|\bpublic\s+programs?\b
| \bout[-\s]?of[-\s]?network\b|\bOON\b
| \bexplanation\s+of\s+benefits?\b|\bEOB\b
| \bcost\s+(?:estimate|estimation|calculator)\b|\ballowed\s+amount\b|\bOOP\b|\bcoinsurance\b
| \bcoordination\s+of\s+benefits?\b|\bCOB\b
| \bi\s*(?:am|'m|work\s+as)\s+(?:an?\s+)?(?:
      insurance\s+(?:navigator|specialist|agent|rep|coordinator)
    | benefits?\s+verification\s+specialist
    | prior\s+authori[sz]ation\s+specialist
    | claims?\s+(?:appeals?|denials?)\s+(?:specialist|analyst)
    | medical\s+billing\s+(?:and\s+)?coding\s+(?:specialist|analyst|educator)
    | pharmacy\s+benefits?\s+(?:navigator|coordinator)
    | medicare(?:\/medicaid)?\s+(?:advisor|navigator)
    | revenue\s+cycle\s+(?:specialist|analyst)
  )\b
| \bact\s+as\s+(?:an?\s+)?(?:
      insurance\s+navigator|benefits?\s+verification\s+specialist|prior\s+authori[sz]ation\s+specialist
    | claims?\s+appeals?\s+advisor|medical\s+billing\s+and\s+coding\s+educator
    | pharmacy\s+benefits?\s+navigator|medicare\/?medicaid\s+advisor|out[-\s]?of[-\s]?network\s+navigator
  )\b
| \b(?:write|give|produce|draft|create)\s+(?:an?\s+)?(?:
      benefits?\s+verification\s+checklist|VOB\s+template
    | prior\s+authori[sz]ation\s+(?:workflow|checklist|request|letter|script)
    | claims?\s+appeal\s+(?:guide|letter|template)
    | out[-\s]?of[-\s]?network\s+(?:guide|steps|script)
    | pharmacy\s+benefits?\s+(?:navigation|coverage)\s+guide
    | EOB\s+(?:explainer|explanation)|explanation\s+of\s+benefits?\s+(?:guide|explainer)
    | cost\s+estimation\s+(?:method|worksheet|example|template)
    | coverage\s+verification\s+(?:script|checklist)
  )\b
| \b(?:deductible|copay|coinsurance|out[-\s]?of[-\s]?pocket|max(?:imum)?|allowed\s+amount|preauth|authorization|required)\b
| \b(?:CPT|HCPCS|ICD-10(?:-CM)?|modifiers?)\b
)
"""
)

def _is_insurance_audience(text: str) -> bool:
    import re as _re
    t = text or ""
    if _EXPLICIT_INSURANCE_RE.search(t):
        return True
    if _re.search(r"\b(health\s+plan|health\s+insurance|insurance\s+plan|plan\s+benefits|coverage|benefits|payer|insurer|copay|coinsurance|deductible|out[-\s]?of[-\s]?pocket|oop)\b", t, _re.I):
        return True
    if _re.search(r"\byou\s*(?:are|\'re)\s+(?:an?\s+)?(?:insurance|benefits?|billing|coding)\s+(?:navigator|specialist|advisor|analyst)\b", t, _re.I):
        return True
    for name in ["_INS_NAV_PAT","_VOB_PAT","_PRIOR_AUTH_PAT","_CLAIMS_APPEAL_PAT","_BILLING_CODING_PAT","_PHARM_BENEFITS_PAT","_PUBLIC_PROGRAMS_PAT","_COST_ESTIMATE_PAT","_OON_PAT","_EOB_PAT"]:
        pat = globals().get(name)
        if hasattr(pat, "search") and pat.search(t):
            return True
    return False

import re as _re2

_AMBIGUOUS_UNIGRAMS = {
    r"\bangina\b": {
        "boost_if_near": r"\b(chest|coronary|ischemi\w*|mi\b|cad\b|tropo\w*|ecg|ekg|stemi|nstemi)\b",
        "window": 40,
        "base": 0.5,
        "boost": 1.0
    }
}

def _score_evidence(text: str, hits: dict) -> float:
    t = text or ""
    score = 0.0
    score += 1.0 * hits.get("strong", 0)
    for _ in hits.get("weak_terms", []):
        score += 0.5
    for amb_pat, cfg in _AMBIGUOUS_UNIGRAMS.items():
        if _re2.search(amb_pat, t, _re2.I):
            score += cfg.get("base", 0.5)
            ctx = cfg.get("boost_if_near")
            if ctx:
                m = _re2.search(amb_pat, t, _re2.I)
                w = cfg.get("window", 40)
                start = max(0, m.start() - w); end = min(len(t), m.end() + w)
                if _re2.search(ctx, t[start:end], _re2.I):
                    score += cfg.get("boost", 1.0)
    return score

I = re.IGNORECASE
W = lambda x: re.compile(x, I)
POS_CARD = [W(r"\b(chest\s*pain|pressure|tightness|exertion|coronary|ischemi\w*|mi\b|nstemi|stemi|acute\s*coronary|cad\b|tropo\w*|ecg|ekg|nitro)\b")]
NEG_CARD = [W(r"\b(oral|mucosa|mucosal|palate|buccal|blister|bulla\w*|pemphigoid|bp180|bp230|dif|subepidermal)\b")]
POS_ABH  = [W(r"\bangina\s+bullosa(?:\s+ha?emorrhagica)?\b"), W(r"\boral\s*(blood[-\s]*filled\s*)?blister\b"), W(r"\b(soft|hard)\s*palate\b"), W(r"\bbuccal\s*mucosa\b")]
NEG_ABH  = [W(r"\bpemphigoid\b|\bbullous\s*pemphigoid\b|\bbp180\b|\bbp230\b|\blinear\s+igg\b|\bsubepidermal\b"), W(r"\b(cutaneous|skin|dermis|epidermis|trunk|torso|back|chest)\b")]
POS_BPDERM=[W(r"\b(bullous\s*pemphigoid|pemphigoid|linear\s+igg|c3\b|bp180|bp230|subepidermal|tense\s*bullae|elderly)\b")]
NEG_BPDERM=[W(r"\b(chest\s*pain|coronary|troponin|stemi|nstemi)\b"), W(r"\bangina\s+bullosa(?:\s+ha?emorrhagica)?\b")]
POS_BP_PRESS=[W(r"\b(mm ?hg|systolic|diastolic|vitals?|bp\s*\d{2,3}\/\d{2,3}|hypertension|hypotension|arm\s*cuff|ambulatory)\b")]
POS_ER_ONC=[W(r"\b(estrogen\s*receptor|er\s*pos(itive)?|er\s*neg(ative)?|ihc|breast\s*cancer|pr\b|her2\b)\b")]
POS_ER_ED =[W(r"\b(emergency\s*department|emergency\s*room|presented\s*to\s*er|triage|ed\b)\b")]
POS_INR_COAG=[W(r"\b(coag|warfarin|vitamin\s*k\s*antagonist|bleeding|clot|pt\b|inr\s*goal|anticoag)\b")]
POS_INR_CUR=[W(r"\b(₹|rupee|indian\s*rupee|lakhs?)\b")]
POS_MS_NEU =[W(r"\b(ms\b|multiple\s*sclerosis|demyelinat\w*|optic\s*neuritis|relaps\w*|lesions?\b|mri)\b")]
POS_MS_DRUG=[W(r"\b(morphine\s*sulfate|ms\s*cont(in)?|opioid)\b")]
POS_MS_COMP=[W(r"\b(microsoft|windows|office|excel|msdn|azure)\b")]
POS_CRP_LAB=[W(r"\b(crp\b|c-?reactive\s*protein|inflammation|sepsis|biomarker)\b")]
POS_CRP_BIZ=[W(r"\b(customer\s*relations?|crm|pipeline|qbr|account\s*plan|leads?)\b")]
POS_ACE_RX =[W(r"\b(ace\s*inhibitor|lisinopril|ramipril|enalapril|arb\b|hypertension)\b")]
POS_ACE_GENE=[W(r"\b(ace\s*gene|i/?d\s*polymorphism|enzyme|genotype|rs\d+)\b")]
POS_PT_LAB=[W(r"\b(prothrombin\s*time|coag|warfarin|bleeding)\b")]
POS_PT_PHYS=[W(r"\b(physical\s*therapy|physiotherapy|pt\s*eval|home\s*exercise|rehab)\b")]
POS_UA_LAB=[W(r"\b(urinalysis|dipstick|nitrites?|leukocyte\s*esterase|microscopy)\b")]
POS_ALS_NEU=[W(r"\b(amyotrophic\s*lateral\s*sclerosis|als\b|motor\s*neuron\s*disease|mnd)\b")]
POS_ALS_LIFE=[W(r"\b(advanced\s*life\s*support|als\s*cert|prehospital|ems|paramedic)\b")]
POS_ASD_CARD=[W(r"\b(atrial\s*septal\s*defect|secundum|ostium\s*primum|echo|right\s*atrial|shunt)\b")]
POS_ASD_NEURO=[W(r"\b(autism\s*spectrum|asd\b|neurodevelopmental|social\s*communication|stimming)\b")]
POS_CP_CARD=[W(r"\b(chest\s*pain|cp\b\s*with|pressure|angina|exertion|sweating|ecg|troponin)\b")]
POS_CP_NEURO=[W(r"\b(cerebral\s*palsy|spastic\s*diplegia|gmfcs|birth\s*asphyxia)\b")]
POS_UC_GI=[W(r"\b(ulcerative\s*colitis|pancolitis|bloody\s*diarrhea|mesalamine|5-asa|proctitis)\b")]
POS_UC_URG=[W(r"\b(urgent\s*care|walk[-\s]*in|after\s*hours|clinic)\b")]
TOK_ABH_PHRASE = re.compile(r"\bangina\s+bullosa(?:\s+ha?emorrhagica)?\b|\bABH\b", I)
TOK_BP_PEMPH   = re.compile(r"\bbullous\s*pemphigoid\b", I)
TOK_ANGINA     = re.compile(r"\bangina\b", I)
TOK_BP         = re.compile(r"\bbp\b", I)
TOK_ER         = re.compile(r"\ber\b", I)
TOK_INR        = re.compile(r"\binr\b", I)
TOK_MS         = re.compile(r"\bms\b", I)
TOK_CRP        = re.compile(r"\bcrp\b", I)
TOK_ACE        = re.compile(r"\bace\b", I)
TOK_PT         = re.compile(r"\bpt\b", I)
TOK_UA         = re.compile(r"\bua\b", I)
TOK_ALS        = re.compile(r"\bals\b", I)
TOK_ASD        = re.compile(r"\basd\b", I)
TOK_CP         = re.compile(r"\bcp\b", I)
TOK_UC         = re.compile(r"\buc\b", I)

def _mk_general_cdr() -> ContextualDisambiguationRouter:
    rules = [
        AmbiguousToken(TOK_ABH_PHRASE, [SenseRule("angina_bullosa_haemorrhagica", POS_ABH, NEG_ABH, base=3.0, priority=5)], default_label="angina_bullosa_haemorrhagica"),
        AmbiguousToken(TOK_BP_PEMPH,   [SenseRule("bullous_pemphigoid", POS_BPDERM, NEG_BPDERM, base=2.5, priority=4)], default_label="bullous_pemphigoid"),
        AmbiguousToken(TOK_ANGINA,     [SenseRule("angina_pectoris", POS_CARD, NEG_CARD, base=0.2, priority=3),
                                        SenseRule("angina_bullosa_haemorrhagica", POS_ABH, NEG_ABH, base=0.2, priority=2)]),
        AmbiguousToken(TOK_BP,         [SenseRule("blood_pressure", POS_BP_PRESS, POS_BPDERM, base=0.2, priority=2),
                                        SenseRule("bullous_pemphigoid", POS_BPDERM, POS_BP_PRESS+NEG_ABH, base=0.1, priority=1)]),
        AmbiguousToken(TOK_ER,         [SenseRule("estrogen_receptor", POS_ER_ONC, POS_ER_ED, base=0.1, priority=2),
                                        SenseRule("emergency_room", POS_ER_ED, POS_ER_ONC, base=0.1, priority=1)]),
        AmbiguousToken(TOK_INR,        [SenseRule("coag_parameter", POS_INR_COAG, POS_INR_CUR, base=0.2, priority=2),
                                        SenseRule("currency", POS_INR_CUR, POS_INR_COAG, base=0.0, priority=1)]),
        AmbiguousToken(TOK_MS,         [SenseRule("multiple_sclerosis", POS_MS_NEU, POS_MS_DRUG+POS_MS_COMP, base=0.2, priority=3),
                                        SenseRule("morphine_sulfate", POS_MS_DRUG, POS_MS_NEU+POS_MS_COMP, base=0.1, priority=2),
                                        SenseRule("microsoft", POS_MS_COMP, POS_MS_NEU+POS_MS_DRUG, base=0.0, priority=1)]),
        AmbiguousToken(TOK_CRP,        [SenseRule("lab_marker", POS_CRP_LAB, POS_CRP_BIZ, base=0.1, priority=2),
                                        SenseRule("business_term", POS_CRP_BIZ, POS_CRP_LAB, base=0.0, priority=1)]),
        AmbiguousToken(TOK_ACE,        [SenseRule("ace_inhibitor", POS_ACE_RX, POS_ACE_GENE, base=0.2, priority=2),
                                        SenseRule("ace_gene_enzyme", POS_ACE_GENE, POS_ACE_RX, base=0.1, priority=1)]),
        AmbiguousToken(TOK_PT,         [SenseRule("prothrombin_time", POS_PT_LAB, POS_PT_PHYS, base=0.2, priority=2),
                                        SenseRule("physical_therapy", POS_PT_PHYS, POS_PT_LAB, base=0.1, priority=1)]),
        AmbiguousToken(TOK_UA,         [SenseRule("urinalysis", POS_UA_LAB, [], base=0.2, priority=1)], default_label="urinalysis"),
        AmbiguousToken(TOK_ALS,        [SenseRule("motor_neuron_disease", POS_ALS_NEU, POS_ALS_LIFE, base=0.2, priority=2),
                                        SenseRule("advanced_life_support", POS_ALS_LIFE, POS_ALS_NEU, base=0.1, priority=1)]),
        AmbiguousToken(TOK_ASD,        [SenseRule("atrial_septal_defect", POS_ASD_CARD, POS_ASD_NEURO, base=0.2, priority=2),
                                        SenseRule("autism_spectrum_disorder", POS_ASD_NEURO, POS_ASD_CARD, base=0.2, priority=1)]),
        AmbiguousToken(TOK_CP,         [SenseRule("chest_pain", POS_CP_CARD, POS_CP_NEURO, base=0.2, priority=2),
                                        SenseRule("cerebral_palsy", POS_CP_NEURO, POS_CP_CARD, base=0.2, priority=1)]),
        AmbiguousToken(TOK_UC,         [SenseRule("ulcerative_colitis", POS_UC_GI, POS_UC_URG, base=0.2, priority=2),
                                        SenseRule("urgent_care", POS_UC_URG, POS_UC_GI, base=0.1, priority=1)]),
    ]
    return ContextualDisambiguationRouter(rules)

SENSE_META: Dict[str, Dict] = {
    "angina_bullosa_haemorrhagica": {"specialist":"ENT / Otolaryngologist","framework":"oral-mucosa blister care and airway safety","site":"oral mucosa (soft palate/buccal)","not":["bullous_pemphigoid","autoimmune blistering disease","angina pectoris/cardiac ischemia","cutaneous blistering of chest/back"],"avoid_tests":["DIF/ELISA for BP180/BP230 unless atypical"],"guard":"Do not describe this as a variant of cardiac angina or as a cutaneous blistering disease; it is an oral mucosal, blood-filled blister unrelated to myocardial ischemia, typically traumatic/fragile-mucosa in origin; avoid steroids or immunosuppressants unless atypical; prioritize ENT/oral-mucosa framing and airway risk if the lesion is large."},
    "angina_pectoris": {"specialist":"Cardiologist","framework":"ischemia/ACS risk stratification","site":"cardiovascular system","markers":["ECG changes","troponin","exercise provocation"],"not":["oral mucosal blister","angina bullosa haemorrhagica","cutaneous blisters"],"avoid_tests":[],"guard":"Do not mention oral or cutaneous blisters; do not imply that angina bullosa is a variant of cardiac angina."},
    "bullous_pemphigoid": {"specialist":"Board-Certified Dermatologist","framework":"autoimmune subepidermal blistering","site":"skin","markers":["linear IgG/C3 at BMZ","BP180/BP230 antibodies"],"not":["angina bullosa haemorrhagica"],"avoid_tests":[]},
    "blood_pressure": {"specialist":"Internal Medicine Physician"},
    "estrogen_receptor": {"specialist":"Obstetrician-Gynecologist"},
    "emergency_room": {"specialist":"Internal Medicine Physician"},
    "coag_parameter": {"specialist":"Internal Medicine Physician"},
    "multiple_sclerosis": {"specialist":"Neurologist"},
    "morphine_sulfate": {"specialist":"Pain Management Specialist"},
    "lab_marker": {"specialist":"Internal Medicine Physician"},
    "ace_inhibitor": {"specialist":"Cardiologist"},
    "ace_gene_enzyme": {"specialist":"Internal Medicine Physician"},
    "prothrombin_time": {"specialist":"Internal Medicine Physician"},
    "physical_therapy": {"specialist":"Licensed Physical Therapist"},
    "urinalysis": {"specialist":"Nephrologist"},
    "motor_neuron_disease": {"specialist":"Neurologist"},
    "advanced_life_support": {"specialist":"Internal Medicine Physician"},
    "atrial_septal_defect": {"specialist":"Cardiologist"},
    "autism_spectrum_disorder": {"specialist":"Psychologist"},
    "chest_pain": {"specialist":"Cardiologist"},
    "cerebral_palsy": {"specialist":"Neurologist"},
    "ulcerative_colitis": {"specialist":"Gastroenterologist"},
    "urgent_care": {"specialist":"Internal Medicine Physician"},
}

def _build_generic_guard(label: str) -> str:
    meta = SENSE_META.get(label, {})
    if not meta:
        return ""
    parts = []
    fw = meta.get("framework")
    site = meta.get("site")
    nots = meta.get("not", [])
    avoid = meta.get("avoid_tests", [])
    guard = meta.get("guard")
    if fw: parts.append(f"Use the framework of {fw}.")
    if site: parts.append(f"Anchor the description to {site}.")
    if nots: parts.append("Do not conflate with " + ", ".join(nots) + ".")
    if avoid: parts.append("Avoid suggesting " + "; ".join(avoid) + ".")
    if guard: parts.append(guard)
    if not parts:
        return ""
    return "[CONTEXT — DO NOT ECHO] Disambiguation guard: " + " ".join(parts) + " [/CONTEXT]"

def apply_general_disambiguation(q: str, s: str) -> Dict[str, Optional[str]]:
    router = _mk_general_cdr()
    ctx = f"{s or ''}\n{q or ''}"
    hits = router.resolve_scored(ctx)
    if not hits:
        return {"label": None, "guard": None, "role_hint": None, "score": None}
    best = max(hits, key=lambda d: (d.get("score", 0.0), d.get("label","")))
    label = best["label"]
    score = best.get("score", 0.0)
    guard = _build_generic_guard(label) or None
    role_hint = None
    meta = SENSE_META.get(label, {})
    if score is not None and score >= 0.9 and "specialist" in meta:
        role_hint = meta["specialist"]
    return {"label": label, "guard": guard, "role_hint": role_hint, "score": score}

def _mk_specialist(role, sections, tail, s, q):
    import re as _re
    q_text = (q or "").strip()
    ql = q_text.lower()
    rolel = (role or "").lower()
    hint = apply_general_disambiguation(q_text, s)
    tail_aug = ((tail or "").strip() + (" " + hint["guard"] if hint.get("guard") else "")).strip()
    if hint.get("role_hint"):
        rolel = hint["role_hint"]

    def _infer_clinical_specialist_label(query, role_text, default="Internal Medicine Physician"):
        SPECIALTIES = [
            "Pediatrician",
            "Cardiologist",
            "ENT / Otolaryngologist",
            "General Surgeon",
            "Gastroenterologist",
            "Pulmonologist",
            "Radiologist",
            "Diagnostic Laboratory Technologist",
            "Neurosurgeon",
            "Neurologist",
            "Pain Management Specialist",
            "Medical Oncologist",
            "Obstetrician-Gynecologist",
            "Women's Health Specialist",
            "General Dentist",
            "Board-Certified Dermatologist",
            "Licensed Physical Therapist",
            "Registered Dietitian",
            "Psychiatrist",
            "Psychologist",
            "Urologist",
            "Nephrologist",
            "Pharmacist",
            "Meditation Teacher",
            "Cognitive Health Clinician",
            "Genomics Specialist",
            "Biotech Specialist",
            "Internal Medicine Physician",
        ]
        ROLE_PRIORS = {
            r"\bcardio": "Cardiologist",
            r"\bpsychi": "Psychiatrist",
            r"\bpsycholog": "Psychologist",
            r"\bphysio|physical\s+therap|physiotherap": "Licensed Physical Therapist",
            r"\bneuro(?!surg)": "Neurologist",
            r"\bneurosurg": "Neurosurgeon",
            r"\bendo(crino)?|internal\s+med": "Internal Medicine Physician",
            r"\bpulm|respir": "Pulmonologist",
            r"\bgastro|hepat": "Gastroenterologist",
            r"\bnephro": "Nephrologist",
            r"\bonco": "Medical Oncologist",
            r"\bob[-\s]?gyn|obstet|gyne|women'?s\s+health": "Obstetrician-Gynecologist",
            r"\bwomen'?s\s+health": "Women's Health Specialist",
            r"\bderma": "Board-Certified Dermatologist",
            r"\bent|otolaryng": "ENT / Otolaryngologist",
            r"\bordtho|orthop": "General Surgeon",
            r"\bradio": "Radiologist",
            r"\bdent": "General Dentist",
            r"\bpediat|child\s*(?:health|medicine)": "Pediatrician",
            r"\burolog": "Urologist",
            r"\bpain\s*management|interventional\s*pain": "Pain Management Specialist",
            r"\bpharmac": "Pharmacist",
            r"\bdiet(it|et)|nutrition": "Registered Dietitian",
            r"\blab\s*(tech|technolog|diagnostic)|patholog(y|ist)": "Diagnostic Laboratory Technologist",
            r"\bmeditat|mindful|metta|loving[-\s]?kindness|breathwork|pranayama|yoga(?:\s*nidra)?": "Meditation Teacher",
            r"\bcognit|memory|attention|executive\s*function|adhd|brain\s*fog|working\s*memory|processing\s*speed": "Cognitive Health Clinician",
            r"\bgenom|pharmaco\s*genom|pharmacogen|exome|whole[-\s]?genome|wgs\b|polygenic|pgs\b|cnv\b|snv\b|variant\s*report|vcf\b": "Genomics Specialist",
            r"\bbiotech|cell\s*therap|gene\s*therap|crispr|cas9|car[-\s]?t|aav\b|lentiviral|vector\s*design|rna[-\s]?therap|oligo(?:\s*therapy)?": "Biotech Specialist",
        }
        for pat, lbl in ROLE_PRIORS.items():
            if _re.search(pat, role_text or ""):
                return lbl
        KW = {
            "Cardiologist": [
                r"\b(heart(\s+attack)?|mi\b|myocard|cad\b|coronary|(?:angina\s+pectoris|unstable\s+angina|stable\s+angina|prinzmetal(?:\'s)?\s+angina)|stent|angioplast|cabg|bypass|arrhythm|svt\b|afib\b|atrial\s+fibrillation|hf\b|heart\s+failure|echocardiogram|echo\b|ecg\b|ekg\b|troponin|pericard|endocard|valvular)\b"
            ],
            "Neurologist": [
                r"\b(stroke|cva\b|tia\b|seizure|status\s+epilepticus|epilep|parkinson|dementia|concussion|alzheimer|migraine|cluster\s+headache|neuropath|ms\b|multiple\s+sclerosis|eeg\b|lumbar\s+puncture|bells?\s+palsy|guillain)\b"
            ],
            "Gastroenterologist": [
                r"\b(ibs\b|ibd\b|crohn|ulcerative\s+colitis|gerd\b|reflux|gastritis|peptic\s+ulcer|liver|hepat|cirrhosis|pancreat|gallstone|biliary|colonoscopy|endoscopy|egd\b|ercp\b|gi\s+bleed|hematochezia|melena)\b"
            ],
            "Pulmonologist": [
                r"\b(asthma|copd\b|emphysema|bronchitis|bronchiectasis|pleural|pneumonia|pulmonary\s+fibrosis|sarcoidosis|sleep\s+apnea|osa\b|pe\b|pulmonary\s+embolism|thoracentesis|spirometry|pft\b)\b"
            ],
            "General Surgeon": [
                r"\b(fracture|dislocation|acl\b|pcl\b|meniscus|rotator\s+cuff|labrum|arthroplasty|arthroscopy|hernia|hiatal hernia|spine\s+surgery|scoliosis|carpal\s+tunnel|tennis\s+elbow|ankle\s+sprain|orthop)\b"
            ],
            "Psychiatrist": [
                r"\b(depress|anxiety|panic\s+attack|ptsd\b|ocd\b|bipolar|schizo|psychosis|antidepressant|ssri\b|snri\b|hallucination|antipsychotic|mood\s+stabilizer|clozapine|lithium|suicid|manic|hypomania)\b"
            ],
            "Psychologist": [
                r"\b(psychotherapy|cbt\b|dbt\b|talk\s+therapy|exposure\s+therapy|behavioral\s+activation|schema\s+therapy|psycholog(ist|y)|counseling|counselling)\b"
            ],
            "Board-Certified Dermatologist": [
                r"\b(rash|eczema|dermatitis|psoriasis|acne|rosacea|melanoma|nevus|mole|alopecia|hives|urticaria|pruritus|skin\s+lesion|basal\s+cell|squamous\s+cell)\b"
            ],
            "General Dentist": [
                r"\b(tooth|teeth|dental|cavity|caries|gingiva|gingivitis|periodont|root\s+canal|extraction|implant|crown|filling|braces|orthodontic|toothache)\b"
            ],
            "Obstetrician-Gynecologist": [
                r"\b(obgyn|ob/gyn|gyneco|pelvic|prenatal|antenatal|pregnan|postpartum|cesarean|c[-\s]?section|fibroid|endometr|pcos\b|pap\s+smear|amenorrhea|dysmenorrhea)\b"
            ],
            "Women's Health Specialist": [
                r"\b(women'?s\s+health|well[-\s]?woman|mammography|menopause|perimenopause|hormone\s+therapy|hot\s+flashes|osteoporosis)\b"
            ],
            "Internal Medicine Physician": [
                r"\b(hypertension|blood\s+pressure|hyperlipid(?:emia)?|cholesterol|statin|diabetes|endocrine|endocrinologist|hba1c|metformin|insulin|thyroid|hypo|hyperthy|fever\s+of\s+unknown|general\s+checkup|uti\b|anemia|electrolyte|discharge\s*(?:note|summary)|clinical\s*notes?|prescriptions?|medic(?:ine|ation)s?)\b"
            ],
            "Nephrologist": [
                r"\b(ckd\b|esrd\b|dialysis|proteinuria|hematuria|nephrotic|creatinine|egfr\b|kidney\s+failure|renal\s+biopsy)\b"
            ],
            "Urologist": [
                r"\b(prostate|bph\b|erectile\s+dysfunction|peyronie|urinary\s+retention|kidney\s+stone|renal\s+colic|hematuria|cystoscopy|varicocele|hydrocele)\b"
            ],
            "Medical Oncologist": [
                r"\b(chemotherapy|immunotherapy|targeted\s+therapy|metastatic|tumor\s+board|oncolog(y|ist)|solid\s+tumor|lymphoma|leukemia)\b"
            ],
            "Radiologist": [
                r"\b(mri\b|ct\b|x[-\s]?ray|ultrasound|echo(cardiogram)?|mammogram|imaging\s+report|contrast\s+study|radiograph|pet[-\s]?ct)\b"
            ],
            "Licensed Physical Therapist": [
                r"\b(physio|physical\s+therapy|physiotherapy|rehab(ili)?tation|strengthening\s+exercises?|range\s+of\s+motion|gait\s+training|manual\s+therapy|mcl\b|acl\b|sprain|post[-\s]?op\s+rehab)\b"
            ],
            "Registered Dietitian": [
                r"\b(diet|nutrition|macros|protein\s+intake|fiber|low\s+fodmap|meal\s+plan|nutritional\s+counseling|calorie\s+deficit|weight\s+management|glycemic\s+index)\b"
            ],
            "Pain Management Specialist": [
                r"\b(chronic\s+pain|neuropathic\s+pain|opioid\s+rotation|nerve\s+block|epidural|radiofrequency\s+ablation|spinal\s+cord\s+stimulator|facet\s+joint|pain\s+clinic)\b"
            ],
            "ENT / Otolaryngologist": [
                r"\b(sinusitis|rhinitis|otitis|tonsil|adenoid|hearing\s+loss|tinnitus|vertigo|deviated\s+septum|nasal\s+polyp|laryngitis|epistaxis)\b"
            ],
            "Pediatrician": [
                r"\b(pediatric|child|infant|toddler|newborn|neonate|well[-\s]?child|school\s+physical|immunization|cold|sore throat|infection|fever\s+in\s+child|croup|bronchiolitis)\b"
            ],
            "Diagnostic Laboratory Technologist": [
                r"\b(cbc\b|cmp\b|lft\b|kft\b|pathology\s+report|biopsy\s+processing|specimen\s+handling|reference\s+range|gram\s+stain|culture\s+result)\b"
            ],
            "Neurosurgeon": [
                r"\b(craniotomy|aneurysm\s+clipping|spine\s+decompression|laminectomy|brain surg(?:ery)?|spine surg(?:ery)?|herniated disk|discectomy|glioblastoma|tumor\s+resection|chiari|microdiscectomy)\b"
            ],
            "Pharmacist": [
                r"\b(dosing|dose\s+adjustment|drug\s+interaction|pharmacokinetics|medication\s+counseling|refill|formulation|contraindication|titration)\b"
            ],
            "Meditation Teacher": [
                r"\b(meditation|mindfulness|mindful\s*breathing|breathwork|pranayama|box\s*breathing|4[-\s]?7[-\s]?8|body\s*scan|progressive\s*muscle\s*relaxation|pmr\b|grounding|guided\s*imag(?:ery|ination)|loving[-\s]?kindness(?:\s+meditation)?|metta|yoga(?:\s*nidra)?)\b"
            ],
            "Cognitive Health Clinician": [
                r"\b(cognitive\s*(?:health|rehab|training)?|memory|attention|executive\s*function|processing\s*speed|working\s*memory|brain\s*fog|adhd|organization|planning|focus)\b"
            ],
            "Genomics Specialist": [
                r"\b(genom(?:e|ic)s?|pharmacogen(?:omics|etics)|pgx\b|exome|whole[-\s]?genome|wgs\b|polygenic\s*(?:risk|score)|pgs\b|cnv\b|snv\b|indel|copy[-\s]?number|variant\s*(?:report|interpretation)|vcf\b|hgvs\b|gwas|panel\s*test|carrier\s*screen)\b"
            ],
            "Biotech Specialist": [
                r"\b(biotech(?:nology)?|cell\s*therap(?:y|ies)|gene\s*therap(?:y|ies)|crispr(?:/cas9)?|cas9|base\s*editor|prime\s*editing|car[-\s]?t|t[-\s]?cell\s*therapy|vector\s*(?:design|production)|aav\b|lentiviral|lipid\s*nanoparticle|lnp\b|rna[-\s]?therap(?:y|eutics?)|oligonucleotide|antisense|siRNA|mRNA\s*vaccine)\b"
            ],
        }
        scores = {k: 0.0 for k in SPECIALTIES}
        for label, pats in KW.items():
            for pat in pats:
                hits = _re.findall(pat, ql)
                if hits:
                    scores[label] += len(hits)
        weak = []
        strong_hits = 0
        if _re.search(r"\b(cad\b|coronary|mi\b|myocard|stent|angioplast|cabg|bypass|stemi|nstemi|troponin|ecg|ekg|ischemi\w*)\b", ql):
            strong_hits += 1
        if _re.search(r"\bangina\b", ql) and not _re.search(r"\b(angina\s+pectoris|unstable\s+angina|stable\s+angina|prinzmetal(?:\'s)?\s+angina)\b", ql):
            weak.append(r"\bangina\b")
        if scores.get("Cardiologist", 0) > 0:
            scores["Cardiologist"] = max(scores["Cardiologist"], _score_evidence(ql, {"strong": strong_hits, "weak_terms": weak}))
        if any(scores.values()):
            return max(scores.items(), key=lambda x: (x[1], x[0]))[0]
        return default

    def _normalize_heading(h: str) -> str:
        h = (h or "").strip().rstrip(":")
        if _re.search(r'\badvice\b', h, flags=_re.I):
            h = _re.sub(r'\badvice\b', 'Advice', h, flags=_re.I)
        else:
            h = f"{h} Advice"
        ACR = {"ENT","MRI","CT","EEG","ECG","EKG","PET-CT","PET/CT","OB/GYN","OBGYN","CBC","CMP"}
        def _ttoken(tok: str) -> str:
            t = tok.strip()
            if not t or not t[0].isalpha():
                return tok
            if t.upper() in ACR:
                return t.upper()
            return t[0].upper() + t[1:].lower()
        parts = _re.split(r'(\s+|/|-|&)', h)
        parts = [_ttoken(p) if _re.match(r'^[A-Za-z]+$', p) else p for p in parts]
        h = ''.join(parts).strip()
        return f"{h}:"

    specialist_label = hint.get("role_hint") or _infer_clinical_specialist_label(q_text, rolel)
    advice_heading = _normalize_heading(f"{specialist_label} Advice")

    proc_re = _re.compile(
        r"(?ix)\b("
        r"procedure|operation|surgery|how\s+(?:is|do|does).*(?:done|performed)|during\s+(?:the\s+)?"
        r"|pre[-\s]?op|post[-\s]?op|anesthesia|sedation|prep|recovery|aftercare"
        r"|biopsy|lumbar\s+puncture|spinal\s+tap|colonoscopy|endoscopy|egd|ercp|hysteroscopy|laparoscopy|arthroscopy"
        r"|angioplasty|stent|bypass|cabg|ablation|catheter|port|dialysis|thoracentesis|paracentesis|tracheostomy"
        r"|cesarean|c[-\s]?section|appendectomy|hysterectomy|tonsillectomy|root\s+canal|extraction|implant"
        r"|mri|ct|x[-\s]?ray|ultrasound|echo|ecg|eeg"
        r"|[a-z]+(?:ectomy|otomy|ostomy|plasty|scopy)\b"
        r")"
    )
    is_procedure = bool(proc_re.search(ql))
    want_explain = bool(_re.search(r'\b(explain|why|how|details?|mechanism|rationale|break\s*down|elaborate|teach)\b', ql))
    want_more = bool(_re.search(r'\b(tell\s*me\s*more|more\s+details?|full|complete|comprehensive|longer|steps?)\b', ql))
    core_sections = _re.sub(r'\s*;?\s*Disclaimer\b.*$', '', (sections or '').strip(), flags=_re.I)

    if is_procedure:
        dyn_sections = (
            f"{advice_heading} (ONE compact paragraph; 6-8 sentences; plain-language guidance for the general public; "
            "state what the procedure is for and when it’s used; explain preparation steps and anesthesia/sedation; "
            "describe what happens step-by-step and typical duration; note common sensations and expected discomfort; "
            "summarize key risks/side effects and how often they occur; outline recovery timeline, activity limits, and aftercare; "
            "list urgent red flags after the procedure and when to seek care; mention common alternatives if relevant; "
            "no bullets or numbered lists)"
        )
    else:
        dyn_sections = (
            f"{advice_heading} (ONE compact paragraph; 6-8 sentences; plain-language guidance for the general public; "
            "clear steps for what to do now with brief reasons; include first-line self-care or emergency medicines with typical adult dose/route/frequency and key cautions when appropriate; "
            "briefly suggest 1–3 follow-up tests to confirm the diagnosis when relevant (name each test and why it helps); "
            "give a brief treatment plan overview (first-line options and goals) rather than exhaustive details; "
            "state when to seek urgent versus routine care and the key red flags; avoid jargon; no bullets or numbered lists)"
        )

    if want_explain:
        dyn_sections += "; Explanation (ONE compact paragraph; 10-12 sentences; brief why/how in simple clinical language; no lists or numbered items)"
    if want_more and core_sections:
        dyn_sections += "; " + core_sections
    dyn_sections += "; Disclaimer."

    rules = [
        "Write ONLY the answer; do NOT repeat or quote the question or any instructions.",
        "Use Title Case section headings that end with a colon.",
        "Include ONLY the headings defined in the dynamic sections plus the final 'Disclaimer:'.",
        "The first section (the '* Advice:' one) must be exactly one paragraph; avoid jargon; no bullets or numbered lists.",
        "Use plain, non-technical language; define any unavoidable medical term in simple words.",
        "When suggesting tests, name at most 1-3 and include a short purpose (e.g., 'ECG to check…').",
        "Provide only a brief treatment overview; detailed clinician-level protocols are out of scope here.",
        "Include medication guidance only when appropriate, using generic names with typical adult dose, route, frequency, and key cautions.",
        "Include resuscitation/AED guidance only when clearly indicated by the scenario; otherwise omit.",
        "Do not mention audience or that the response was tailored.",
        "The final heading MUST be exactly 'Disclaimer:'.",
        "End exactly with <<<END>>>."
    ]

    return _mk(
        f"You are a {role}. Provide medically accurate, plain-language guidance the public can use right now.",
        rules,
        dyn_sections,
        tail_aug,
        s,
        q
    )

def _mk_clinical(role, sections, tail, s, q):
    import re as _re, unicodedata
    ctx_all = unicodedata.normalize("NFKC", f"{s or ''}\n{q or ''}")
    if _is_insurance_audience(ctx_all):
        return _mk_insurance(role, sections, tail, s, q)
    q_text = (q or "").lower().strip()
    q_text = q_text.replace("\u2013", "-").replace("\u2014", "-")
    m = _re.search(r"\byou\s+are\s+clini(?:cian|can)\b", q_text)
    is_clinician_cmd = bool(m)
    tail_text = q_text[m.end():].strip() if is_clinician_cmd else ""
    if not is_clinician_cmd:
        return _mk(
            "Router barrier.",
            ["Write NOTHING. Do not output guidance, explanations, headers, or placeholders. End exactly with <<<END>>>."],
            "",
            "",
            s,
            q
        )
    def _disambig_hint(t: str) -> str:
        t = " " + (t or "") + " "
        hints = []
        if _re.search(r"\bangina\s+bullosa(?:\s+hemorrh?agica)?\b|\babh\b", t):
            hints.append("Term 'angina' here matches 'angina bullosa hemorrhagica' (oral mucosal blistering); use ENT/oral-mucosa frameworks, not cardiac ischemia; never describe as a variant of cardiac angina or as a cutaneous blister.")
        elif _re.search(r"\bangina\s+pectoris\b|\btypical\s+exertional\s+chest\s+pain\b", t):
            hints.append("Term 'angina' here matches 'angina pectoris' (cardiac ischemia); apply ACS/ischemia frameworks and do not mention oral or cutaneous blisters.")
        elif _re.search(r"\bangina\b", t):
            hints.append("Ambiguous 'angina' detected; choose between cardiac ischemia vs oral mucosal ABH strictly; do not intermix pathophysiology or manifestations.")
        if _re.search(r"\bheat\s*stroke\b|\bsunstroke\b", t) and _re.search(r"\bstroke\b", t):
            hints.append("Disambiguate 'stroke': heat stroke (thermal emergency) vs cerebrovascular stroke (ischemic/hemorrhagic).")
        if _re.search(r"\bcellulitis\b", t) and _re.search(r"\bstasis\s+dermatitis\b|\bvenous\s+eczema\b", t):
            hints.append("Distinguish cellulitis (bacterial infection) from stasis dermatitis (inflammatory venous disease).")
        if hints:
            return " ".join(hints)
        return ""
    extra_hint = _disambig_hint(tail_text)
    guard_pack = apply_general_disambiguation(q, s)
    guard_hint = guard_pack.get("guard") or ""
    tail_enriched = ((tail or "") + (" " + extra_hint if extra_hint else "") + (" " + guard_hint if guard_hint else "")).strip()
    def first_idx(patterns, text):
        hits = [m.start() for p in patterns for m in [_re.search(p, text)] if m]
        return (min(hits) if hits else None)
    pred_patterns = [r"\bpredict", r"\bprobab", r"\brisk\b", r"\bchance\b", r"\blikeli", r"\bestimat", r"\bpre[-\s]?test\b", r"\bpost[-\s]?test\b", r"\bearly detection\b", r"\bscreen(?:ing)?\b", r"\brisk of\b", r"\bodds\b"]
    deci_patterns = [r"\bdecision\b", r"\bthresholds?\b", r"\bcut[\s-]?offs?\b", r"\bcriteria\b", r"\bwhat to do\b", r"\bmanagement\b", r"\bnext step\b", r"\balgorithm\b", r"\bpathway\b"]
    stag_patterns = [r"\bstage\b", r"\bstaging\b", r"\btnm\b", r"\bfigo\b", r"\bann\s*arbor\b", r"\bgrade(?:\s|/)?stage\b", r"\bstage evaluation\b"]
    treat_patterns = [r"\btreat(?:ment)?\b", r"\btherapy\b", r"\bregimen\b", r"\bchemo", r"\bradiation\b", r"\bsurgery\b", r"\bimmuno?therapy\b", r"\bendocrine\b", r"\btargeted\b", r"\bdrug\b", r"\bmedicat(?:ion)?\b", r"\bdose\b"]
    idx_pred = first_idx(pred_patterns, tail_text)
    idx_deci = first_idx(deci_patterns, tail_text)
    idx_stag = first_idx(stag_patterns, tail_text)
    idx_trea = first_idx(treat_patterns, tail_text)
    intents = []
    if idx_pred is not None: intents.append(("pred", idx_pred))
    if idx_deci is not None: intents.append(("deci", idx_deci))
    if idx_stag is not None: intents.append(("stag", idx_stag))
    if idx_trea is not None: intents.append(("trea", idx_trea))
    selected = [min(intents, key=lambda kv: kv[1])[0]] if intents else ["guide"]
    predictive_section = ("Produce ONE maximally informative paragraph, 10–12 sentences, with no headings or lists: quantify baseline pre-test risk from demographics, epidemiology, and prior history; estimate pre-test probability from the most specific demographic-adjusted prevalence (age, sex, ethnicity, geography, care setting, family history), citing source and year; update to a calibrated post-test probability using Bayes reasoning with likelihood ratios from concrete findings and tests, explicitly using post-test odds = pre-test odds × LR and post-test probability = odds/(1+odds); include sensitivity/specificity or LR+/LR− with provenance and population-match notes; map quantitative ranges with units to risk bands; embed any numeric readings as a single semicolon-separated sentence within the paragraph with no labels or inline headings and without altering any numbers, glyphs, or units; specify the single most decision-changing missing measurement with actionable ranges and how each range would cross management thresholds; state exactly what is not indicated now and the quantitative trigger that would make it indicated; never fabricate numbers—if provenance is unavailable for a value, describe criteria generically and say that evidence for this demographic is unavailable.")
    decision_section = ("Produce ONE maximally informative paragraph, 10–12 sentences, with no headings or lists: state explicit quantitative thresholds and score bands from the appropriate disease framework with provenance (governing body and version/year) and describe the action above versus below each boundary; tie choices to measurable ranges using if–then logic covering labs, biomarkers, lesion size/volume (mm/cm), velocity of change, or validated scores; quantify trade-offs using absolute risk reduction, false-positive and false-negative rates, number needed to treat or harm, or decision-curve net benefit when applicable; define monitoring cadence and precise escalation or stop criteria linked to deltas or percentage change from baseline; identify low-value steps to defer now with the exact quantitative trigger that would make them appropriate; specify safe fallback behavior when uncertainty or out-of-distribution risk is high; never fabricate tools—omit the name if you cannot provide provenance.")
    stage_section = ("Produce ONE maximally informative paragraph, 10–12 sentences, with no headings or lists: assign disease stage using the correct system implied by the condition with governing body/version; justify each component with quantitative findings including primary tumor size or depth in mm/cm, margins or invasion, nodal status with count, size, and extranodal extension, and metastatic evidence by site and modality; specify measurements or tests still required to finalize stage and the cutoffs that would upstage or downstage; describe how stage alters prognosis using risk bands or survival estimates with uncertainty bounds; indicate when re-staging is warranted after treatment and which quantitative changes would trigger it; state what is not indicated at this stage and the measurable condition that would change that.")
    treatment_section = ("Produce ONE maximally informative paragraph, 10–12 sentences, with no headings or lists: personalize the plan to stage, biomarkers, comorbidities, patient goals, and logistics; choose modalities—surgery, radiation, systemic therapy, targeted, immunotherapy, endocrine, or surveillance—and justify with quantitative effect sizes such as absolute benefit, hazard ratio with a 95% confidence interval, and number needed to treat or harm when known, citing sources and years; for drugs or regimens use generic names with typical adult dose ranges, route, frequency, major contraindications or interactions, and renal or hepatic adjustments when relevant; define response and toxicity monitoring with units and intervals and explicit early stop or switch rules tied to thresholds or percentage change; provide dose-modification criteria and supportive care triggers; if a therapy is not indicated now, state why and the exact measurable trigger that would change this; never fabricate tools—omit the name if you cannot provide provenance.")
    guidance_section = ("Produce ONE maximally informative paragraph, 10–12 sentences, with no headings or lists: answer the question directly with precise clinical reasoning; apply the appropriate disease framework and quantitative ranges or categories; give the immediate next step and the single most informative additional datapoint with its actionable ranges and how each range would change management; state what is not indicated now and the measurable trigger that would make it indicated; include clear return and escalation precautions; avoid filler and keep language decision-oriented; never fabricate numbers or tools—omit the name if provenance is absent.")
    explanation_section = ("Produce ONE concise explanatory paragraph, 12–15 sentences, with no headings or lists: explain how the estimates and thresholds were derived and should be interpreted in practice, restating the Bayes update in words and clarifying how validated categories or scores translate into risk bands and management thresholds; describe how to use the numeric ranges within the paragraph without altering any numbers, glyphs, or units and why certain measurements are the most decision-changing; highlight key uncertainties, calibration, and domain-shift caveats and how clinicians should respond; do not introduce new numbers or modify existing ones; keep tone instructional and clinically focused; write 'confidence interval' in full and never use the abbreviation.")
    override_txt = ""
    if isinstance(sections, str):
        m_override = _re.match(r"(?is)^\s*override\s*:\s*(.+)$", sections.strip())
        if m_override:
            override_txt = m_override.group(1).strip()
    if override_txt:
        dyn_sections = override_txt
    else:
        parts = []
        if "pred" in selected: parts.append(predictive_section)
        if "deci" in selected: parts.append(decision_section)
        if "stag" in selected: parts.append(stage_section)
        if "trea" in selected: parts.append(treatment_section)
        if "guide" in selected: parts.append(guidance_section)
        dyn_sections = " ".join(parts)
    rules = [
        "Write ONLY paragraphs; no headings, subheadings, inline headings, labels, lists, bullets, numbering, or any bracketed tokens; never output any square-bracketed content such as [ANSWER], [CONTEXT], [PRIMARY PARAGRAPH], or 'Paragraph 1:'; never echo any role statements or the trigger phrase; do not begin with 'You are'; do not produce any standalone line or sentence ending with a colon; do not output references, citations, bibliographies, URLs, DOIs, or journal/source names.",
        "Assume a healthcare professional reader; use rigorous clinical and statistical language with explicit rationale.",
        "Routing is enabled only when the user's text contains the exact phrase 'you are clinician' or 'you are clinican'.",
        "Select exactly one primary paragraph based on the earliest explicit intent found after the trigger phrase among: predictive diagnosis, decision points, disease stage and stage evaluation, treatment plan.",
        "Write exactly one paragraph.",
        "Estimate pre-test probability from the most specific demographic-adjusted prevalence (age, sex, ethnicity, geography, care setting, family history) and cite source/year; when multiple credible prevalences exist, present a justified range and specify the population and setting, without listing references.",
        "Combine demographic pre-test probability with test performance using Bayes’ theorem and appropriate LR+/LR− or sensitivity/specificity; when multiple tests are used, note conditional dependence and avoid naive multiplication; state whether performance estimates are population-matched to the same demographic or require caution.",
        "When numeric readings are present, embed them as a single semicolon-separated sentence inside the paragraph without changing numbers, units, or glyphs; never precede values with tokens such as 'LR:', 'LR+:', 'LR-:', 'PPV:', or 'NPV:'; express intervals as 'confidence interval' written in full and never as 'CI'.",
        "Use any applicable validated and widely used scoring system, staging framework, reporting lexicon, or clinical decision rule that truly fits the condition and care setting; treat named items as examples only (e.g., BI-RADS [ACR], AJCC TNM, Wells, CHA₂DS₂-VASc, CURB-65, HEART, PERC, Ottawa Ankle Rules, Centor/McIsaac, KDIGO [RIFLE/AKIN], qSOFA/SOFA) and do not limit outputs to this set; for every tool you name, state the governing body or consensus source and version/year if known; never fabricate tool names, and the phrase 'Rotterdam scoring system' must not appear unless the user's text explicitly supplies it and the disease context requires it.",
        "Tie every action to measurable criteria with units and ranges using explicit if–then conditionals; apply disease-appropriate thresholds, categories, and staging implied by the case without hardcoding any single disease or fixed numeric constants.",
        "When exact numeric values are unavailable, present range-conditioned outcomes and specify the single most influential missing datapoint with decision-changing cutoffs; never invent unsupported numbers; if provenance is missing for any numeric, omit that numeric and state the gap explicitly.",
        "Include uncertainty handling, calibration information, and out-of-distribution or domain-shift caveats when applicable.",
        "Integrity check BEFORE finalizing: remove or rewrite any fragment so there are no unmatched parentheses/brackets/quotes, no truncated numeric ranges or intervals, no dangling units or stray dashes, no duplicate title text at the start, no references or citation markers (e.g., [1], (1), superscripts), and no sentence beginning with 'And', 'But', or 'So'. Each paragraph must end with a full stop.",
        "If any sentence contains an incomplete numeric expression or a broken interval/range, immediately rewrite that sentence into a complete self-contained sentence so the paragraph still contains the required number of sentences.",
        "End exactly with <<<END>>>."
    ]
    text = _mk("Clinical paragraph generator with routing.", rules, dyn_sections, tail_enriched, s, q)
    text = unicodedata.normalize("NFKC", text).translate({ord(c): ord('-') for c in "\u2212\u2010\u2011\u2012\u2013\u2014"})
    head_re = _re.compile(r'(?im)^\s*(paragraph\s*\d+|clinical\s*(guidance|specialist\s*advice)|predictive\s*diagnosis|decision\s*points?|treatment\s*plan|disease\s*stage.*|explanatory\s*paragraph)\s*:\s*')
    tag_re = _re.compile(r'\[[^\]]+\]\s*')
    label_re = _re.compile(r'(?im)^\s*(?:LR\+?\s*:|LR-\s*:|PPV\s*:|NPV\s*:|CI\s*:)\s*')
    bullet_re = _re.compile(r'(?m)^\s*(?:•|-|\*)\s+')
    text = head_re.sub("", text)
    text = tag_re.sub("", text)
    text = label_re.sub("", text)
    text = bullet_re.sub("", text)
    text = _re.sub(r'(?i)\bci\s*:', '', text)
    text = text.replace(" CI ", " confidence interval ").replace(" CI.", " confidence interval.")
    lines = text.splitlines()
    out_lines, skip = [], False
    ref_head = _re.compile(r'(?im)^\s*(references?|sources?|bibliography|works\s+cited|global\s+cancer\s+observatory|ca)\s*:\s*$')
    for ln in lines:
        if ref_head.match(ln):
            skip = True
            continue
        if skip:
            if ln.strip() == "":
                skip = False
            continue
        if _re.search(r'https?://\S+|\bdoi:\s*\S+', ln, _re.I):
            continue
        out_lines.append(ln)
    text = "\n".join(out_lines)
    text = _re.sub(r'\n{3,}', '\n\n', text).strip()
    return text

def _mk_insurance(role, sections, tail, s, q):
    import re as _re
    ql = (q or "").lower()
    want_explain = bool(_re.search(r'(?ix)\b(explain|why|how|details?|rationale|break\s*down|teach)\b', ql))
    want_more    = bool(_re.search(r'(?ix)\b(tell\s*me\s*more|more\s+details?|full|complete|comprehensive|longer|steps?)\b', ql))
    is_vob    = bool(_re.search(r'(?ix)\b(vob|benefits?\s+verification|verify\s+benefits?)\b', ql))
    is_pa     = bool(_re.search(r'(?ix)\b(prior\s+authori[sz]ation|pre[-\s]?auth|\bpa\b)\b', ql))
    is_appeal = bool(_re.search(r'(?ix)\b(appeal|denial|reconsideration|grievance|peer[-\s]?to[-\s]?peer)\b', ql))
    is_oon    = bool(_re.search(r'(?ix)\bout[-\s]?of[-\s]?network|\boon\b|single[-\s]?case\s+agreement|sca\b|balance\s+billing\b|\bno\s+surprises\b', ql))
    is_eob    = bool(_re.search(r'(?ix)\b(explanation\s+of\s+benefits|\beob\b)\b', ql))
    is_cost   = bool(_re.search(r'(?ix)\b(cost\s+(estimate|estimation|calculator)|allowed\s+amount|price\s+estimate|o?p\s*max|out[-\s]?of[-\s]?pocket)\b', ql))
    is_pharm  = bool(_re.search(r'(?ix)\b(pharmacy\s+benefits?|formulary|pbm|tier|step\s+therapy|quantity\s+limit|prior\s+auth(?:orization)?\s+for\s+rx|exception\s+request)\b', ql))
    is_public = bool(_re.search(r'(?ix)\b(medicare|medicaid|cms|chip|part\s+[abcd]|advantage|dual\s+eligible|extra\s+help|lis|msps?)\b', ql))
    core_sections = _re.sub(r'\s*;?\s*Disclaimer\b.*$', '', (sections or '').strip(), flags=_re.I)

    if is_vob:
        dyn_sections = (
            "Benefits Verification Specialist Advice (ONE compact paragraph; 10–12 sentences; plain-English verification steps; "
            "identify plan info needed (member ID, group, plan type, effective dates), network tier, PCP/referral rules, and common authorization triggers; "
            "describe exactly how to verify by phone/portal with what questions to ask about deductible, coinsurance, copays, visit limits, exclusions, and carve-outs; "
            "state how to confirm in-network status for provider/facility/tax ID and whether referrals are required; "
            "explain documenting rep name, date/time, call reference number, and quoted benefits; "
            "note COB/secondary coverage checks and carve-outs (behavioral health, PBM); "
            "include cautions to rely on plan documents and recorded references, as benefits are not guarantees of payment; "
            "advise escalation when data conflict or coverage appears incorrect; no lists or numbered items)"
        )
    elif is_pa:
        dyn_sections = (
            "Prior Authorization Specialist Advice (ONE compact paragraph; 10–12 sentences; plain-English PA steps; "
            "explain how to determine if PA is required using plan policy/UM criteria and service codes; "
            "list submission essentials in prose (member/plan, rendering/billing info, diagnosis, CPT/HCPCS, clinical rationale, prior treatments, risk/benefit); "
            "describe portal/fax/phone submission, attachment types, and typical turnaround times; "
            "state how to track status, request expedite criteria, and prepare for peer-to-peer; "
            "explain what to do if denied (levels of appeal and timelines) and evidence to include; "
            "advise documenting reference numbers, dates, reps, and keeping copies of submissions; "
            "include cautions to verify policy version and that approval is not a payment guarantee; no lists or numbered items)"
        )
    elif is_appeal:
        dyn_sections = (
            "Health Plan Appeal Specialist Advice (ONE compact paragraph; 10–12 sentences; plain-English denial navigation; "
            "explain reading the EOB/ERA to identify denial bucket (eligibility, coding, medical necessity, authorization, timely filing); "
            "describe gathering evidence (EOB, clinical notes, guidelines, auth records) and aligning to plan policy; "
            "outline a concise appeal letter structure with facts, basis, policy citations, and requested remedy; "
            "state timelines and levels (internal, external review where applicable) and how to track; "
            "advise escalation paths (case management, supervisor, state resources) and when to request peer-to-peer; "
            "include cautions to use plan forms, preserve deadlines, and document all contacts; no lists or numbered items)"
        )
    elif is_oon:
        dyn_sections = (
            "Out-Of-Network Care Navigator Advice (ONE compact paragraph; 10–12 sentences; plain-English OON guidance; "
            "explain checking network status for provider/facility and exceptions (emergency, no in-network availability); "
            "describe cost exposures (deductible, coinsurance, usual reimbursement methods) and balance-billing risks at a high level; "
            "note federal/state protections may apply in limited scenarios and vary by jurisdiction; "
            "outline steps to explore single-case agreements and negotiate rates, including required information to share; "
            "advise contacting the plan for authorization/benefits and confirming any waivers in writing; "
            "state how to document reference numbers, names, and promised terms; "
            "include verification cautions and escalation options; no lists or numbered items)"
        )
    elif is_eob:
        dyn_sections = (
            "Explanation Of Benefits Advice (ONE compact paragraph; 10–12 sentences; plain-English EOB guidance; "
            "define an EOB as not a bill and describe billed, allowed, plan paid, and member responsibility; "
            "explain common remark/denial codes at a high level and typical next steps; "
            "show how to spot deductible vs coinsurance vs copay and coordination-of-benefits issues; "
            "advise who to call when numbers look wrong and what to ask; "
            "state what to document (rep, date/time, reference number) and what records to keep; "
            "include verification cautions; no lists or numbered items)"
        )
    elif is_cost:
        dyn_sections = (
            "Health Plan Cost Estimation Advice (ONE compact paragraph; 10–12 sentences; plain-English estimate method; "
            "identify inputs needed in prose (CPT/HCPCS, provider/facility, network tier, allowed amount, deductible met, coinsurance, copay); "
            "explain step order: deductible first, then coinsurance, then copay, not exceeding out-of-pocket max; "
            "describe how to obtain the allowed amount from plan/provider and note that charges may vary; "
            "provide a simple sentence-based example with hypothetical numbers clearly labeled; "
            "mention caveats like multiple providers, anesthesia, facility fees, and separate professional vs technical components; "
            "include verification cautions and recommend confirming in writing; no lists or numbered items)"
        )
    elif is_pharm:
        dyn_sections = (
            "Pharmacy Benefits Navigator Advice (ONE compact paragraph; 10–12 sentences; plain-English pharmacy coverage; "
            "explain formulary tiers and typical cost sharing and that exact tiers vary by plan/PBM; "
            "summarize utilization management (step therapy, prior authorization, quantity limits) and how to check requirements; "
            "describe exception/coverage determination requests and the role of medical-necessity rationale; "
            "mention financial assistance avenues and specialty pharmacy coordination when applicable; "
            "include verification cautions and note that coverage decisions are plan-specific; no lists or numbered items)"
        )
    elif is_public:
        dyn_sections = (
            "Public Programs Benefits Advice (ONE compact paragraph; 10–12 sentences; plain-English overview; "
            "summarize eligibility basics and enrollment windows at a high level; "
            "outline core benefits categories and network/referral concepts; "
            "note savings programs and where to verify benefits; "
            "mention appeals/grievances basics and official resources; "
            "include verification cautions and jurisdictional variation; no lists or numbered items)"
        )
    else:
        dyn_sections = (
            "Health Plans Specialist Advice (ONE compact paragraph; 10–12 sentences; plain-English navigation; "
            "describe coverage snapshot (plan type, effective dates), network tier, and core cost-sharing terms; "
            "explain authorization checks and how to verify benefits by portal/phone with key questions; "
            "state what to document (rep, reference number, date/time) and when to escalate; "
            "include verification cautions and note that benefits are not guarantees of payment; no lists or numbered items)"
        )

    if want_explain:
        dyn_sections += "; Explanation (ONE compact paragraph; 5–7 sentences; brief why/how in simple words; no lists)"
    if want_more and core_sections:
        dyn_sections += "; " + core_sections
    dyn_sections += "; Disclaimer."

    rules = [
        "Write ONLY the answer; do NOT repeat or quote the question or any instructions.",
        "Use Title Case section headings that end with a colon.",
        "Include ONLY the headings defined in the dynamic sections plus the final 'Disclaimer:'.",
        "The first section must be exactly one paragraph of 10–12 sentences; no lists, tables, or emojis.",
        "Use plain language; define unavoidable insurance terms briefly.",
        "Do not give legal or financial advice; instruct readers to verify specifics with their plan and provider.",
        "Do not fabricate plan details, CPT/HCPCS codes, coverage decisions, prices, or state-specific rules; use 'Unknown' when inputs are missing.",
        "Benefits verification and authorizations are not guarantees of payment; state this when relevant.",
        "Avoid quoting dollar amounts unless clearly marked as hypothetical or supplied by the user/plan.",
        "End exactly with <<<END>>>."
    ]

    return _mk(
        f"You are a {role} providing accurate, plain-language health insurance navigation that people can use now without replacing plan documents or professional advice.",
        rules,
        dyn_sections,
        tail,
        s,
        q
    )

def _apply_cdr_and_hint(q: str, s: str) -> Optional[str]:
    RX = lambda x, flags=0: re.compile(x, flags)
    LXI = re.IGNORECASE
    RENAL_SIGNS     = [RX(r"\b(ml/?min|ckd(?:-epi)?|creatinine|crcl|renal|nephro|dose|dosing|adjust(?:ment|ing)?)\b", LXI)]
    GENE_SIGNS      = [RX(r"\b(mutation|variant|exon\s*\d+|pathogenic|l\d{3,4}[a-z]?r|t\d{3,4}[a-z]?m|amplification|driver)\b", LXI)]
    ONC_SIGNS       = [RX(r"\b(oncolog|tki|tyrosine\s+kinase|nsclc|adenocarcinoma|solid\s+tumor|metastatic)\b", LXI)]
    COAG_SIGNS      = [RX(r"\b(coag|warfarin|vitamin\s*k\s*antagonist|prothrombin|bleeding|clot|pt\b|inr(?:\s*goal)?)\b", LXI)]
    CURRENCY_SIGNS  = [RX(r"\b(₹|rupee|indi(?:a|an)\s*rupee|lakhs?)\b", LXI)]
    ENDO_SIGNS      = [RX(r"\b(estrogen|progesterone|receptor|her2|ihc|er\/pr)\b", LXI)]
    EMERG_ROOM_SIGS = [RX(r"\b(emergency\s*room|ed\b|a&e\b|triage|presented\s+to\s+er)\b", LXI)]
    NEURO_SIGNS     = [RX(r"\b(ms\b|multiple\s*sclerosis|relaps(?:e|ing)|lesions?|demyelina)", LXI)]
    DRUG_SIGNS      = [RX(r"\b(morphine\s*sulfate|ms\s*cont(in)?|opioid|mg)\b", LXI)]
    MICROSOFT_SIGNS = [RX(r"\b(microsoft|windows|office|msdn)\b", LXI)]
    LAB_SIGNS       = [RX(r"\b(c-reactive\s*protein|hs-?crp|inflammation|sepsis|biomarker)\b", LXI)]
    BUSINESS_SIGNS  = [RX(r"\b(customer\s*relations|account\s*plan|qbr|pipeline|leads?)\b", LXI)]
    CARDIO_SIGNS    = [RX(r"\b(ace\s*inhibitor|lisinopril|enalapril|ramipril|arb|arbs?)\b", LXI)]
    GENE_ENZYME_SIGS= [RX(r"\b(ace\s*gene|i/d\s*polymorphism|enzyme)\b", LXI)]
    PT_LAB_SIGNS    = [RX(r"\b(prothrombin\s*time|coag|warfarin|bleeding)\b", LXI)]
    PT_PHYSIO_SIGNS = [RX(r"\b(physical\s*therapy|physiotherapy|pt\s*eval|home\s*exercise|rehab)\b", LXI)]
    UA_LAB_SIGNS    = [RX(r"\b(urinalysis|dipstick|nitrites?|leukocyte\s*esterase|microscopy)\b", LXI)]
    ER_TOKEN        = RX(r"\bER\b")
    egfr_TOKEN      = RX(r"\bE?GFR\b")
    INR_TOKEN       = RX(r"\bINR\b")
    MS_TOKEN        = RX(r"\bMS\b")
    CRP_TOKEN       = RX(r"\bCRP\b")
    ACE_TOKEN       = RX(r"\bACE\b")
    PT_TOKEN        = RX(r"\bPT\b")
    UA_TOKEN        = RX(r"\bUA\b")
    AMBIGUOUS_REGISTRY = [
        AmbiguousToken(
            token=egfr_TOKEN,
            senses=[
                SenseRule("genomics_gene",   positives=GENE_SIGNS+ONC_SIGNS, negatives=RENAL_SIGNS, base=0.1, weight_pos=1.0, weight_neg=1.0, case_sensitive=True,  priority=2),
                SenseRule("renal_function",  positives=RENAL_SIGNS,          negatives=GENE_SIGNS+ONC_SIGNS, base=0.1, weight_pos=1.0, weight_neg=1.0, case_sensitive=False, priority=1),
            ],
            default_label=None
        ),
        AmbiguousToken(
            token=ER_TOKEN,
            senses=[
                SenseRule("estrogen_receptor", positives=ENDO_SIGNS+ONC_SIGNS, negatives=EMERG_ROOM_SIGS, base=0.0, priority=2, case_sensitive=True),
                SenseRule("emergency_room",    positives=EMERG_ROOM_SIGS,      negatives=ENDO_SIGNS+ONC_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=INR_TOKEN,
            senses=[
                SenseRule("coag_parameter", positives=COAG_SIGNS, negatives=CURRENCY_SIGNS, base=0.2, priority=2, case_sensitive=True),
                SenseRule("currency",       positives=CURRENCY_SIGNS, negatives=COAG_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=MS_TOKEN,
            senses=[
                SenseRule("multiple_sclerosis", positives=NEURO_SIGNS, negatives=DRUG_SIGNS+MICROSOFT_SIGNS, base=0.2, priority=3, case_sensitive=True),
                SenseRule("morphine_sulfate",   positives=DRUG_SIGNS,  negatives=NEURO_SIGNS+MICROSOFT_SIGNS, base=0.1, priority=2, case_sensitive=True),
                SenseRule("microsoft",          positives=MICROSOFT_SIGNS, negatives=NEURO_SIGNS+DRUG_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=CRP_TOKEN,
            senses=[
                SenseRule("lab_marker", positives=LAB_SIGNS, negatives=BUSINESS_SIGNS, base=0.1, priority=2, case_sensitive=True),
                SenseRule("business_term", positives=BUSINESS_SIGNS, negatives=LAB_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=ACE_TOKEN,
            senses=[
                SenseRule("ace_inhibitor", positives=CARDIO_SIGNS, negatives=GENE_ENZYME_SIGS, base=0.1, priority=2, case_sensitive=True),
                SenseRule("ace_gene_enzyme", positives=GENE_ENZYME_SIGS, negatives=CARDIO_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=PT_TOKEN,
            senses=[
                SenseRule("prothrombin_time", positives=PT_LAB_SIGNS, negatives=PT_PHYSIO_SIGNS, base=0.1, priority=2, case_sensitive=True),
                SenseRule("physical_therapy", positives=PT_PHYSIO_SIGNS, negatives=PT_LAB_SIGNS, base=0.0, priority=1, case_sensitive=True),
            ]
        ),
        AmbiguousToken(
            token=UA_TOKEN,
            senses=[
                SenseRule("urinalysis", positives=UA_LAB_SIGNS, negatives=[], base=0.1, priority=1, case_sensitive=True),
            ],
            default_label="urinalysis"
        ),
    ]
    CDR = ContextualDisambiguationRouter(AMBIGUOUS_REGISTRY)
    SENSE_TO_DOMAIN = {
        "genomics_gene":       {"organ_system": "dermatologic"},
        "renal_function":      {"organ_system": "renal"},
        "estrogen_receptor":   {"organ_system": "gynecologic"},
        "emergency_room":      {"organ_system": "internal_medicine"},
        "coag_parameter":      {"organ_system": "hematologic"},
        "currency":            {"organ_system": None},
        "multiple_sclerosis":  {"organ_system": "neurologic"},
        "morphine_sulfate":    {"organ_system": "pain"},
        "microsoft":           {"organ_system": None},
        "lab_marker":          {"organ_system": "internal_medicine"},
        "business_term":       {"organ_system": None},
        "ace_inhibitor":       {"organ_system": "cardiovascular"},
        "ace_gene_enzyme":     {"organ_system": "endocrine"},
        "prothrombin_time":    {"organ_system": "hematologic"},
        "physical_therapy":    {"organ_system": "musculoskeletal"},
        "urinalysis":          {"organ_system": "renal"},
    }
    ctx = f"{s or ''}\n{q or ''}"
    senses = CDR.resolve(ctx)
    for _, sense_label in senses.items():
        hint = SENSE_TO_DOMAIN.get(sense_label)
        if hint and hint.get("organ_system"):
            organ = hint["organ_system"]
            organ_map = {
                "cardiovascular":        build_cardiology_prompt,
                "respiratory":           build_pulmonology_prompt,
                "neurologic":            build_neurology_prompt,
                "urologic":              build_urology_prompt,
                "renal":                 build_nephrology_prompt,
                "gastrointestinal":      build_gastroenterology_prompt,
                "hepatobiliary":         build_gastroenterology_prompt,
                "pancreatic":            build_gastroenterology_prompt,
                "dermatologic":          build_dermatology_prompt,
                "otolaryngologic":       build_ent_prompt,
                "oral-dental":           build_dentistry_prompt,
                "gynecologic":           build_womens_health_prompt,
                "obstetric":             build_womens_health_prompt,
                "musculoskeletal":       build_orthopedics_prompt,
                "radiology":             build_radiology_prompt,
                "pain":                  build_pain_management_prompt,
                "internal_medicine":     build_internal_medicine_prompt,
                "hematologic":           build_internal_medicine_prompt,
                "endocrine":             build_internal_medicine_prompt,
            }
            f = organ_map.get(organ)
            if callable(f):
                return f(q, s)
    return None

def _mk_dual_router(role, sections_specialist, sections_clinical, tail, s, q):
    ctx = f"{s or ''}\n{q or ''}"
    role_l = (role or "").lower()
    if any(k in role_l for k in ["insurance","benefits","prior authorization","claims","appeal","billing","coding","pharmacy benefits","medicare","medicaid","public programs","out-of-network","eob","explanation of benefits","cost estimator","pre-service"]):
        return _mk_insurance(role, sections_specialist, tail, s, q)
    if _is_insurance_audience(ctx):
        return _mk_insurance(role, sections_specialist, tail, s, q)
    pre = _apply_cdr_and_hint(q, s)
    if pre:
        return pre
    if _is_clinical_audience(ctx):
        return _mk_clinical(role, sections_clinical, tail, s, q)
    if _is_specialist_audience(ctx):
        return _mk_specialist(role, sections_specialist, tail, s, q)
    return _mk_specialist(role, sections_specialist, tail, s, q)

def build_psychiatry_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; What To Do Now; Coping Steps (brief how/why); When To Seek Urgent Help; How To Prepare For An Appointment; Resources; Disclaimer."
    clinical   = "Focused Differential And Risk; Assessment (scales, labs/imaging if indicated); Management Options (psychotherapy/pharmacotherapy/safety) With Decision Points; Monitoring And Follow-Up; Documentation And Handoff Pearls; Reference Touchpoints; Disclaimer."
    return _mk_dual_router("Licensed Psychiatrist And Psychologist", specialist, clinical, "Answer now.", s, q)

def build_meditation_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Setup; 5–8 Minute Script (time-stamped); Grounding Option; What To Notice; Daily Practice Tips; Troubleshooting; Disclaimer."
    clinical   = "Indication And Goals; Script Outline And Cues; Contraindications/Precautions; Variations/Progressions; Adherence Strategies; Disclaimer."
    return _mk_dual_router("Meditation Teacher", specialist, clinical, "Answer now.", s, q)

def build_dermatology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Likely Causes; Self-Care And OTC Options (with why/how); When To Stop/Seek Care; Prevention; Disclaimer."
    clinical   = "Morphology-Driven Differential; Work-Up If Indicated; Therapeutic Options (Topical/Systemic/Procedural) With Indications/Contraindications; Monitoring; Documentation Pearls; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Board-Certified Dermatologist", specialist, clinical, "Answer now.", s, q)

def build_dentistry_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Likely Causes; At-Home Comfort (with cautions); What To Avoid; When To Seek Urgent Dental Care; Prevention; Disclaimer."
    clinical   = "Pulpal/Periodontal/Other Differential; Diagnostic Steps; Treatment Pathways; Analgesia/Antibiotic Stewardship; Complication Signs; Follow-Up; Documentation Pearls; Disclaimer."
    return _mk_dual_router("General Dentist", specialist, clinical, "Answer now.", s, q)

def build_oncology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Typical Evaluation; Treatment Options Overview; Side-Effect Care And Support; Key Questions For The Team; Disclaimer."
    clinical   = "Stage-Informed Approach; Work-Up Essentials (Imaging/Pathology/Biomarkers); Management Options By Intent; Toxicity Prevention/Supportive Care; Response Assessment And Surveillance; Key Guidelines/Trials; Disclaimer."
    return _mk_dual_router("Medical Oncologist", specialist, clinical, "Answer now.", s, q)

def build_womens_health_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Evidence-Based Self-Care; Safety Considerations; When To Seek Care; Follow-Up; Disclaimer."
    clinical   = "Focused Differential; Recommended Work-Up; Therapeutic Options (Medical/Procedural) With Decision Points; Counseling Considerations; Follow-Up; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Obstetrician-Gynecologist", specialist, clinical, "Answer now.", s, q)

def build_gynaecologist_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; What It Means; Self-Care (if appropriate); When To Seek Care; Follow-Up; Disclaimer."
    clinical   = "Differential; Evaluation Strategy; Therapeutic Options; Complication Red Flags; Follow-Up And Counseling; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Gynaecologist", specialist, clinical, "Answer now.", s, q)

def build_physiotherapy_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Calm Pain Safely; Gentle Mobility With How-To; Return-To-Activity Steps; Red Flags; Disclaimer."
    clinical   = "Pathomechanics And Differential; Load Management; Phased Plan (Mobility → Motor Control → Strength → Return) With Criteria; Adverse Response Triggers; Documentation Pearls; Disclaimer."
    return _mk_dual_router("Licensed Physical Therapist", specialist, clinical, "Answer now.", s, q)

def build_nutrition_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Daily Targets; Sample Day(s) With Simple Swaps; Grocery/Prep Tips; Cautions; Disclaimer."
    clinical   = "Nutrition Problem Framing; Prescriptive Targets; Strategy (Pattern/Macros/Micros/Fiber/Fluids); Monitoring/Adjustments; Special Conditions If Relevant; Disclaimer."
    return _mk_dual_router("Registered Dietitian Nutritionist", specialist, clinical, "Answer now.", s, q)

def build_dietitian_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Daily Targets; Sample Days; Practical Tips; Follow-Up; Disclaimer."
    clinical   = "Assessment Synthesis; Prescriptive Targets; Structured Meal Pattern; Adjustments For Comorbidities; Outcome Tracking; Follow-Up Plan; Disclaimer."
    return _mk_dual_router("Registered Dietitian", specialist, clinical, "Answer now.", s, q)

def build_cognitive_health_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Practical Strategies (attention/memory/organization) With Brief Why/How; Short Guided Exercise; When To Seek Evaluation; Disclaimer."
    clinical   = "Etiologic Differential; Screening/Assessment Tools; Multimodal Interventions; Monitoring And Outcomes; Referral/Collaboration; Disclaimer."
    return _mk_dual_router("Cognitive Health Clinician", specialist, clinical, "Answer now.", s, q)

def build_pediatrician_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Summary; Age-Specific Considerations; Comfort Measures; Home Monitoring; Red Flags; "
        "School/Daycare Guidance; Disclaimer. "
        "Summary; Pediatric Dose; Max Daily Dose; Renal Adjustments; Hepatic Adjustments; "
        "Contraindications; Side Effects; Disclaimer. "
        "Indication & Route; Pediatric Regimen (mg/kg per DOSE + per-dose cap; frequency); "
        "Max Daily Dose; Renal Dosing (eGFR/CrCl); Hepatic Dosing (Child-Pugh); Key Interactions; Disclaimer."
    )
    clinical = (
        "Age-Stratified Differential; Work-Up; Therapeutic Options; Dosing/Device Principles As Appropriate; "
        "Safety Netting; Documentation Pearls; Disclaimer. "
        "Summary; Pediatric Dose; Max Daily Dose; Renal Adjustments; Hepatic Adjustments; "
        "Contraindications; Side Effects; Disclaimer. "
        "Indication & Route; Pediatric Regimen (mg/kg per DOSE + per-dose cap; frequency); "
        "Max Daily Dose; Renal Dosing (eGFR/CrCl); Hepatic Dosing (Child-Pugh); Key Interactions; Disclaimer."
    )
    return _mk_dual_router("Pediatrician", specialist, clinical, "Answer now.", s, q)

def build_cardiology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Immediate Safety (if applicable); What To Do Now; What To Avoid; Home Monitoring; Tests To Discuss; Medicines And Interactions When Appropriate; Lifestyle And Prevention; Follow-Up; Disclaimer."
    clinical   = "Focused Differential; Initial Assessment And Tests; Immediate Management (unstable vs stable) With Decision Points; Ongoing Management; Consults/Disposition; Secondary Prevention; Follow-Up; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Cardiologist", specialist, clinical, "Answer now.", s, q)

def build_ent_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Likely Causes; Self-Care; What To Avoid; When To Seek Urgent Evaluation; Follow-Up; Disclaimer."
    clinical   = "Otologic/Rhinologic/Laryngologic Differential; Exam/Tests; Medical/Procedural Options With Decision Points; Complication Red Flags; Follow-Up; Documentation Pearls; Disclaimer."
    return _mk_dual_router("ENT / Otolaryngologist", specialist, clinical, "Answer now.", s, q)

def build_orthopedics_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; First-Line Care; Activity Modification; When Imaging Or Clinic Visit Is Needed; Red Flags; Disclaimer."
    clinical   = "Mechanism And Differential; Exam/Imaging Strategy; Management (Conservative/Operative) With Criteria; Rehabilitation Milestones; Complication Surveillance; Documentation Pearls; Disclaimer."
    return _mk_dual_router("General Surgeon", specialist, clinical, "Answer now.", s, q)

def build_gastroenterology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Diet And Lifestyle; Self-Care Options; When To Seek Care; Follow-Up; Disclaimer."
    clinical   = "Upper/Lower GI, Hepatobiliary, Pancreatic Differential; Diagnostic Pathway; Therapeutic Options With Decision Points; Monitoring And Follow-Up; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Gastroenterologist", specialist, clinical, "Answer now.", s, q)

def build_pulmonology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Self-Care And Device Technique; Monitoring At Home; Red Flags; Tests To Discuss; Follow-Up And Prevention; Disclaimer."
    clinical   = "Focused Differential; Diagnostic Strategy; Management Options; Action Planning And Monitoring; Referral/Co-Management; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Pulmonologist", specialist, clinical, "Answer now.", s, q)

def build_radiology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Modality Overview; How To Prepare; Safety Considerations; How To Read A Report; Follow-Up Questions; Disclaimer."
    clinical   = "Imaging Strategy And Sequencing; Protocol Considerations; Interpretation Framework; Reporting/Handoff Pearls; Follow-Up/Correlation; Disclaimer."
    return _mk_dual_router("Radiologist", specialist, clinical, "Answer now.", s, q)

def build_lab_technician_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Test Purpose; Specimen Requirements; Patient Preparation; Collection/Handling Basics; Turnaround Time; Result Basics; How To Contact The Lab; Disclaimer."
    clinical   = "Pre-Analytical Requirements; Collection/Handling/Transport; Rejection Criteria; Stability/Interferences; Turnaround Expectations; Critical Values And Escalation; Documentation; Disclaimer."
    return _mk_dual_router("Diagnostic Laboratory Technologist", specialist, clinical, "Answer now.", s, q)

def build_treatment_planning_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Treatment Goals; Stepwise Plan (phases with timeframes and why/how); Medicines And Devices (OTC vs Rx) With Safety Notes; Non-Drug Measures (sleep, activity, nutrition, stress); Home Monitoring And Self-Tracking (what/when/how); What To Avoid; When To Seek Urgent Or In-Person Care; Prevention And Maintenance; Disclaimer."
    clinical   = "Problem List And Phenotype/Severity; Red Flags And Initial Stabilization; Diagnostic Confirmation/Work-Up If Indicated (labs/imaging/scales); Therapeutic Strategy By Severity/Phenotype; First-Line/Second-Line/Rescue Options With Indications/Contraindications; Dosing, Titration, And Duration (typical ranges; tapering where relevant); Procedural/Device-Based Options With Candidacy Criteria; Comorbidities/Drug-Drug Interactions/Pregnancy-Lactation/Renal-Hepatic Considerations; Adjunctive And Non-Pharmacologic Interventions; Monitoring And Safety (vitals, labs, validated tools; frequency/thresholds); Follow-Up Cadence And Response Criteria; Failure/Escalation/Referral Triggers; Patient Education And Adherence Strategies; Documentation And Coding Pearls; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Condition-Specific Specialist (Treatment Planning)", specialist, clinical, "Answer now.", s, q)

def build_urology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Summary; Immediate Safety (if applicable); What To Do Now; What To Avoid; Home Monitoring; "
        "Red Flags And When To Seek Urgent Care; Tests To Discuss (urinalysis, culture, PSA, ultrasound/CT when relevant); "
        "Medicines And Interactions When Appropriate; Procedure Options Overview; Follow-Up; Disclaimer."
    )
    clinical = (
        "Focused Urologic Differential; Initial Assessment And Tests (UA, culture, imaging with thresholds); "
        "Immediate Management (unstable vs stable) With Decision Points; "
        "Pharmacotherapy (indication→typical adult dose→route→frequency→contraindications/interactions); "
        "Procedural/Operative Options And Candidacy (e.g., TURP, TURBT, lithotripsy) With peri-op considerations; "
        "Disposition/Consults; Follow-Up And Surveillance; Guideline Touchpoints; Disclaimer."
    )
    return _mk_dual_router("Urologist", specialist, clinical, "Answer now.", s, q)

def build_nephrology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Summary; What To Do Now; What To Avoid (e.g., NSAIDs, contrast if high risk); Home Monitoring; "
        "Red Flags And When To Seek Urgent Care; Tests To Discuss (BMP/eGFR, urinalysis, urine ACR); "
        "Medicines And Interactions When Appropriate; Lifestyle And Prevention; Follow-Up; Disclaimer."
    )
    clinical = (
        "Etiology-Focused Differential (AKI vs CKD; prerenal/intrinsic/postrenal); "
        "Initial Assessment And Tests (UA with microscopy, chemistries, indices; imaging for obstruction); "
        "Electrolyte And Acid–Base Management (hyperkalemia, hyponatremia, acidosis) With decision thresholds; "
        "Immediate Management With Decision Points (volume status, BP targets, nephrotoxin stewardship); "
        "Renal-Dose Medication Adjustments And Avoidances; "
        "Indications For Dialysis (AEIOU) And Access Considerations; "
        "Follow-Up And Referral; Guideline Touchpoints; Disclaimer."
    )
    return _mk_dual_router("Nephrologist", specialist, clinical, "Answer now.", s, q)

def build_insurance_navigator_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Coverage Snapshot (plan name, network tier, effective dates); Key Terms (deductible, copay, coinsurance, OOP max); Network Status And Referrals (PCP, specialist, facility); Authorization Requirements (typical triggers); Cost Estimate Method (how to estimate using allowed amount, deductible, coinsurance); How To Verify Benefits (step-by-step call script and questions to ask); Documentation Checklist (what info to have ready); Escalation Path (case management, supervisor, complaint avenues); Disclaimer (general education; verify with plan documents)."
    return _mk_insurance("Health Insurance Navigator", insurance, "Answer now.", s, q)

def build_benefits_verification_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Member And Plan Basics (member ID, group, payer, plan type); Effective Dates And COB; Network Tier And PCP/Referral Rules; Deductible/Coinsurance/Copays (individual/family, amounts met); Benefit Limits (visit caps, day limits); Carve-Outs And Contacts (behavioral health, PBM); Service-Specific Notes (e.g., imaging, PT/OT/ST, DME, surgery, telehealth) with Auth/Referral Requirements; How To Call The Plan (interactive script and exact questions); Documentation Fields (reference number, rep name, date/time); Disclaimer (general education; verify with plan documentation)."
    return _mk_insurance("Benefits Verification Specialist (VOB)", insurance, "Answer now.", s, q)

def build_prior_authorization_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Determine If Authorization Is Required (how to check plan policy and UM criteria); Required Information Checklist (member/plan, rendering, diagnosis, service codes, clinical rationale); Clinical Criteria Summary (typical elements plans look for); Submission Steps (portal/fax/phone with tips); Turnaround Times And Follow-Up Cadence; Peer-To-Peer/Expedite Options; If Denied (levels of appeal, timelines, evidence to include); Documentation Standards (reference #s, dates, names); Disclaimer (general education; verify with the payer)."
    return _mk_insurance("Prior Authorization Specialist", insurance, "Answer now.", s, q)

def build_claims_appeal_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Read The EOB/ERA (billed vs allowed vs member responsibility); Common Denial Buckets (eligibility, coding, medical necessity, authorization, timely filing); Evidence To Gather (EOB, clinical notes, auth proof, coding references); Appeal Letter Outline (facts, basis, policy citations, requested remedy); Timelines And Levels (internal levels, external review eligibility); Escalation Path (supervisor, grievance, state DOI contacts); Tracking And Documentation; Disclaimer (general education)."
    return _mk_insurance("Claims Appeal Advisor", insurance, "Answer now.", s, q)

def build_medical_billing_coding_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Identify The Service (place of service, global periods, bundling rules); Code Families Overview (CPT/HCPCS/ICD-10-CM) With Illustrative Examples; Modifiers And When They Apply (general rules); Documentation Requirements (medical necessity, signatures, time); Common Pitfalls (upcoding, unbundling, cloning); Resources (official guidelines); Disclaimer (education only; code from documentation)."
    return _mk_insurance("Medical Billing And Coding Educator", insurance, "Answer now.", s, q)

def build_pharmacy_benefits_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Formulary Tiers And Cost Sharing; Utilization Management (step therapy, prior auth, quantity limits); How To Check Coverage (PBM portal, pharmacist, plan phone tree); Alternatives And Exception Requests (medical necessity letter basics); Financial Assistance Options (manufacturer assistance, charity programs; eligibility overview); Pharmacy Coordination (in-network, specialty pharmacy transfers); Disclaimer (general education; verify with PBM/plan)."
    return _mk_insurance("Pharmacy Benefits Navigator", insurance, "Answer now.", s, q)

def build_public_programs_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Eligibility Overview; Enrollment Windows (Initial, Special, Annual); Program Parts And Benefits (Medicare A/B/C/D, Medigap, Medicaid categories); Savings Programs (LIS/Extra Help, MSPs); Provider Networks And Referrals; Appeals And Grievances Basics; Key Contacts And Official Resources; Disclaimer (general education; verify with CMS/state agency)."
    return _mk_insurance("Medicare/Medicaid Programs Advisor", insurance, "Answer now.", s, q)

def build_cost_estimation_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Inputs Needed (CPT/HCPCS, provider/facility, network tier, allowed amount, deductible met, coinsurance, copay); Estimation Steps (deductible then coinsurance then copay, not exceeding OOP max); Worked Example (simple numbers, explain each step); How To Get Allowed Amount (call script for payer/provider); Caveats (multiple providers, anesthesia, facility fees); Disclaimer (estimate only; verify with plan and providers)."
    return _mk_insurance("Pre-Service Cost Estimator", insurance, "Answer now.", s, q)

def build_out_of_network_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "Identify Network Status And Exceptions (emergency, no in-network availability); Cost Considerations (usual OON reimbursement methods, balance billing risk); Protections Overview (e.g., federal No Surprises Act scenarios at a high level); Negotiation/Single-Case Agreement Basics; Steps To Take (scripts for plan and provider calls); Escalation And Assistance (case management, state resources); Disclaimer (general education; verify with plan/state rules)."
    return _mk_insurance("Out-Of-Network Care Navigator", insurance, "Answer now.", s, q)

def build_eob_explainer_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    insurance = "What An EOB Is (not a bill); How To Read It (billed, allowed, not covered, deductible, copay, coinsurance, plan paid, member responsibility); Common Remark/Denial Codes (generic meanings and next steps); If The Numbers Look Wrong (who to call and what to ask); Records To Keep (dates, reps, reference numbers); Disclaimer (general education)."
    return _mk_insurance("Explanation Of Benefits (EOB) Explainer", insurance, "Answer now.", s, q)

def build_neurosurgery_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; What Surgery May Involve; Non-Surgical Options; When Surgery Is Urgent; How To Prepare; Recovery Basics; Risks And Consent Basics; Follow-Up; Disclaimer."
    clinical   = "Neuroanatomic Localization And Surgical Differential; Imaging/Work-Up; Indications And Contraindications For Surgery; Operative Options And Selection Criteria; Perioperative Management; Postoperative Monitoring And Complications; Nonoperative And Adjunct Options; Disposition And Follow-Up; Documentation Pearls; Disclaimer."
    return _mk_dual_router("Neurosurgeon", specialist, clinical, "Answer now.", s, q)

def build_neurology_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Likely Neurologic Causes; What To Do Now; Red Flags; Tests To Discuss; Medicines And Devices When Appropriate; Lifestyle And Prevention; Follow-Up; Disclaimer."
    clinical   = "Syndromic Localization And Focused Differential; Initial Assessment And Tests; Acute Versus Chronic Management With Decision Points; Disease-Modifying And Symptomatic Therapies; Safety Netting And Return Precautions; Consults/Disposition; Monitoring And Follow-Up; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Neurologist", specialist, clinical, "Answer now.", s, q)

def build_pain_management_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Self-Care And Safe Analgesic Use; Activity And Pacing; Non-Drug Measures; Devices When Appropriate; What To Avoid; When To Seek Urgent Care; Options To Discuss (Therapy, Medications, Injections); Follow-Up; Disclaimer."
    clinical   = "Pain Phenotype (nociceptive/neuropathic/nociplastic); Differential And Red Flags; Assessment Tools; Multimodal Analgesia (nonpharmacologic and pharmacologic) With Decision Points; Interventional Options And Candidacy; Imaging And Diagnostic Blocks; Risk Mitigation (agreements, PDMP, UDT); Functional Goal Setting; Comorbidities And Interactions; Monitoring And Follow-Up; Documentation/Regulatory Pearls; Guideline Touchpoints; Disclaimer."
    return _mk_dual_router("Pain Management Specialist", specialist, clinical, "Answer now.", s, q)

def build_pharmacist_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = "Summary; Adult Dose; Pediatric Dose; Max Daily Dose; Renal Adjustments; Hepatic Adjustments; Contraindications; Side Effects; Disclaimer."
    clinical   = "Indication & Route; Adult Regimen (single standard dose; frequency); Pediatric Regimen (mg/kg per DOSE + per-dose cap; frequency); Max Daily Dose; Renal Dosing (eGFR/CrCl); Hepatic Dosing (Child-Pugh); Key Interactions; Disclaimer."
    return _mk_dual_router("Pharmacist", specialist, clinical, "Answer now.", s, q)

def build_internal_medicine_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Summary; "
        "Professional Discharge Summary (principal diagnosis; secondary diagnoses; procedures; brief hospital course by problem; key labs/imaging with dates; "
        "medications at discharge with start/stop/changes and reasons; pending results; follow-up appointments/tests with timing; activity/diet; return precautions; author/date); "
        "Discharge Note (reason for admission; day-of-discharge status; vitals/exam highlights; reconciled med list with dose/route/frequency; patient education given; "
        "follow-up provider/services; equipment/DME; safety counseling; signatures); "
        "Clinical Notes (H&P/Progress/SOAP templates: CC; HPI with pertinent positives/negatives; ROS; PMH/PSH/FH/SH; allergies/meds; exam by system; "
        "objective data with trends; assessment & plan by problem with orders/monitoring and contingency plans; brief billing/coding elements); "
        "General Medicines Advice (medication reconciliation; how to take each medicine and timing with meals; missed-dose rules; contraindications/precautions; "
        "common interactions including OTC/herbals/alcohol and class duplications; 'sick day' rules for ACEi/ARB/diuretics/metformin/SGLT2; "
        "tapering/starting cautions for steroids/beta-blockers/SSRIs/benzodiazepines; monitoring labs/parameters with typical frequency; "
        "pregnancy/lactation and renal/hepatic adjustment flags to discuss with a clinician; vaccine and preventive-care touchpoints; safe OTC use; "
        "storage and disposal; adherence strategies; cost-saving options (generics, 90-day fills, assistance programs); when to seek urgent care); "
        "Patient Instructions (plain-language after-visit summary: what to do now, medicines with how/why, warning signs, contact numbers); "
        "Disclaimer."
    )
    clinical = (
        "Clinical Guidance (focused differential; red flags; initial tests with decision thresholds and next steps; "
        "initial stabilization/management for unstable vs stable presentations; first-line pharmacologic options with typical adult dose/route/frequency and "
        "major contraindications/interactions including renal/hepatic adjustments; non-drug measures; consults/disposition; monitoring and follow-up; "
        "guideline touchpoints); "
        "Disclaimer."
    )
    return _mk_dual_router("Internal Medicine Physician", specialist, clinical, "Answer now.", s, q)

def build_genomics_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Role: You are a PhD-level clinical genomicist and molecular geneticist writing for an expert audience.\n"
        "Objective: Provide a rigorous, end-to-end answer that synthesizes molecular mechanisms and analytical rigor; explain clearly and precisely.\n"
        "Structure:\n"
        "1) Executive Summary (2–4 sentences; the core answer).\n"
        "2) Direct Answer To The User’s Question.\n"
        "3) Molecular Mechanism And Editing Strategy:\n"
        "   • Locus, transcript, exon/intron context, HGVS syntax for variant if present.\n"
        "   • Editing approach comparison: nuclease HDR vs NHEJ, base editing, prime editing; justify choice.\n"
        "   • Guide design: PAM options, spacer length, strand, mismatch tolerance, predicted off-target tiers.\n"
        "   • Repair template or pegRNA design: orientation, PBS/RT lengths, blocking mutations, silent PAM edits.\n"
        "   • Allele specificity, compound heterozygosity, and zygosity handling.\n"
        "4) Delivery And Experimental System:\n"
        "   • Ex vivo vs in vivo; cell type; primary cells, iPSCs, organoids, animal model if applicable.\n"
        "   • Vector/modality choice and justification: LNP mRNA/gRNA, RNP electroporation, AAV, non-viral.\n"
        "   • Dose units, MOI or µg per 10^6 cells, editing kinetics, repeat dosing constraints.\n"
        "5) Assays And Readouts:\n"
        "   • On-target quantification: amplicon NGS, Sanger ICE/TIDE, digital PCR; HDR vs indel fractions.\n"
        "   • Off-target profiling: in silico ranking, CIRCLE-seq/CHANGE-seq/AMP-seq, GUIDE-seq/HTGTS.\n"
        "   • Functional rescue: transcript/protein, electrophysiology, cellular phenotype relevant to the gene.\n"
        "6) Bioinformatics And QC:\n"
        "   • Read depth, base quality, indel spectrum, phasing, allele fraction; strand bias checks.\n"
        "   • Mapping/reference build, canonical transcript selection, repeat content, GC bias.\n"
        "7) Variant Interpretation And Clinical Framing:\n"
        "   • Classification using ACMG/AMP where applicable; zygosity, penetrance, expressivity.\n"
        "   • Mosaicism, somatic vs germline contexts, inheritance patterns, carrier status.\n"
        "8) Risks, Constraints, And Ethics:\n"
        "   • Off-targets, bystander edits, large deletions/inversions, p53 selection, immunogenicity.\n"
        "   • Germline transmission risk, consent, incidental findings boundaries.\n"
        "9) Worked Example (tie to the user’s scenario if any data provided):\n"
        "   • Show guide/pegRNA sequence design, PAM, orientation; check complement vs reverse-complement; antiparallel 5'→3'.\n"
        "   • Quality checks: alphabet validity, equal lengths where needed, orientation sanity.\n"
        "10) Plain-Language Restatement (2–3 sentences for non-experts who may read along).\n"
        "11) Limitations And Next Steps.\n"
        "12) Disclaimer: Educational information only; not clinical advice.\n"
        "Rules:\n"
        "• Write concisely, technically precise, and citation-style where appropriate without fabricating sources.\n"
        "• If the user provides sequences, never alter them; detect strand and report reverse-complement when needed.\n"
        "• Use standard notation: HGVS, RefSeq/Ensembl IDs if present; 5'→3' orientation explicitly.\n"
        "• If crucial inputs are missing, state assumptions explicitly and offer minimal safe defaults.\n"
    )
    clinical = (
        "Role: You are a PhD-level clinical genomicist operating in a translational/clinical diagnostics context.\n"
        "Objective: Connect molecular editing or variant analysis to clinical utility at expert depth.\n"
        "Structure:\n"
        "1) Clinical Context: indication, phenotype, specimen type, relevant test scope (panel/WES/WGS), orthogonal assays.\n"
        "2) Assay Overview: library prep, capture/amplicon design, coverage targets, key QC thresholds, contamination metrics.\n"
        "3) Calling And Interpretation: pipeline, filtering, annotation sources, classification (ACMG/AMP), zygosity, phasing.\n"
        "4) Therapeutic Relevance: biomarkers, genotype–phenotype correlations, pharmacogenomics where applicable.\n"
        "5) Actionability: clinical trials, compassionate use, companion diagnostics; confirmatory testing plan.\n"
        "6) Safety And Limitations: false positives/negatives, VUS handling, ancestry-related database biases.\n"
        "7) Documentation: HGVS reporting, references to internal SOPs, consent and data-sharing notes.\n"
        "8) Plain-Language Explanation for mixed audiences.\n"
        "9) Disclaimer: Not medical advice; consult treating clinician.\n"
        "Rules:\n"
        "• Use precise clinical language; avoid speculation; clearly separate evidence from hypothesis.\n"
        "• Where user context is ambiguous, state boundary conditions and provide branch recommendations.\n"
    )
    return _mk_dual_router("Genomics Specialist", specialist, clinical, "Answer now.", s, q)


def build_biotech_prompt(query, snippet_text):
    q = _pre(query); s = _pre(snippet_text or "")
    specialist = (
        "Role: You are a PhD-level biotechnology scientist with deep expertise in gene and cell therapy, nucleic-acid therapeutics, and biologics.\n"
        "Objective: Deliver a rigorous, mechanism-grounded plan with development-grade detail.\n"
        "Structure:\n"
        "1) Executive Summary.\n"
        "2) Direct Answer.\n"
        "3) Mechanistic Rationale:\n"
        "   • Target biology, causal pathway, modality fit (CRISPR variants, AAV, LNP mRNA, siRNA, ASO, mAb, CAR-T).\n"
        "   • Editing or modulation strategy; compare alternatives and justify selection.\n"
        "4) Design Considerations:\n"
        "   • Target selection and gRNA/siRNA/ASO design principles; specificity, bystander risks.\n"
        "   • Delivery vector: payload size, tropism, manufacturability, re-dosing feasibility, immunogenicity.\n"
        "   • Dosing units and scaling (in vitro, animal-to-human allometry where applicable), regimen, endpoints.\n"
        "5) Assays And Readouts:\n"
        "   • Potency: on-target activity, functional rescue assays; biodistribution and expression kinetics.\n"
        "   • Safety: off-targets, genotoxicity, innate/adaptive immunity activation; GLP tox outline.\n"
        "6) Development And CMC:\n"
        "   • Process flow, critical quality attributes (CQAs), acceptance criteria, stability; release testing panel.\n"
        "   • Scale-up/out, tech transfer, analytics (HPLC, LC–MS, ddPCR, NGS, capsid titer, LNP size/ENCAP%).\n"
        "7) Translational And Clinical:\n"
        "   • Indication, patient selection, biomarkers, inclusion/exclusion; endpoints and study design (dose-escalation, expansion).\n"
        "   • Risk mitigation, monitoring plan, stopping rules; comparator and standard-of-care context.\n"
        "8) Regulatory And Access:\n"
        "   • IND/IMPD dossier highlights (nonclinical, CMC, clinical), RMAT/PRIME potential; companion diagnostics.\n"
        "9) Plain-Language Explanation.\n"
        "10) Limitations And Next Steps.\n"
        "11) Disclaimer: Educational; not clinical or legal advice.\n"
        "Rules:\n"
        "• Use precise technical language; provide numerical ranges where typical; avoid unverifiable claims.\n"
        "• If user supplies data, ground calculations in those values; otherwise state assumptions.\n"
        "• Prefer modality-agnostic reasoning first, then specify the leading choice with justification.\n"
    )
    clinical = (
        "Role: You are a PhD-level translational scientist partnering with clinical teams.\n"
        "Objective: Map the biotech strategy to patient-level implementation and evidence generation.\n"
        "Structure:\n"
        "1) Translational Context: disease stage, line of therapy, unmet need, prior/failed modalities.\n"
        "2) MOA And Biomarker Strategy: predictive/prognostic markers, companion Dx feasibility, sampling schedule.\n"
        "3) Manufacturing/CMC In Clinic: batch release gating, chain-of-identity/custody, stability and handling.\n"
        "4) Dosing Schema And PK/PD: exposure–response hypotheses, biodistribution, shedding, immunogenicity monitoring.\n"
        "5) Safety Profile: anticipated AEs, DLT definitions, REMS-like mitigations.\n"
        "6) Efficacy Endpoints And Design: primary/secondary endpoints, surrogate markers, statistical powering sketch.\n"
        "7) Comparators/SoC And Access: comparator rationale, crossover, payer-relevant outcomes.\n"
        "8) Plain-Language Summary.\n"
        "9) Disclaimer.\n"
        "Rules:\n"
        "• Anchor recommendations to plausible clinical workflows; flag uncertainties explicitly.\n"
        "• Provide branching plans if key decisions depend on data not provided by the user.\n"
    )
    return _mk_dual_router("Biotechnology Specialist", specialist, clinical, "Answer now.", s, q)

import re, json, functools

_PSYCH_PAT = re.compile(r"(?i)(?<!\w)(?:depression|depressed|anxiety|panic attack|panic disorder|ptsd|ocd|intrusive thoughts|compulsion|bipolar|schizo|psychosis|hallucination|mania|hypomania|mood disorder|counsel(?:l)?ing|psychotherap(?:y|ist)|talk therapy|cbt|dbt|insomnia|burnout|stress|grief)(?!\w)")
_MEDIT_PAT = re.compile(r"(?i)(?<!\w)(?:meditation|mindfulness(?:\s*practice)?|breathing exercise|breathwork|box breathing|4-7-8|body scan|grounding|progressive muscle relaxation|pmr|guided meditation)(?!\w)")
_DERM_PAT  = re.compile(r"(?i)(?<!\w)(?:acne|pimples?|blackheads?|whiteheads?|eczema|dermatitis|psoriasis|rosacea|rash|hives|urticaria|itch|pruritus|mole|nevus|melanoma|sunburn|tinea|ringworm|athlete'?s?\s*foot|onychomycosis|dandruff|seborrheic|alopecia|hair loss|warts?)(?!\w)")
_DENT_PAT  = re.compile(r"(?i)(?<!\w)(?:toothache|tooth pain|dental|cavity|caries|gingivitis|periodontitis|wisdom tooth|extraction|root canal|braces|enamel|sensitivity|mouth ulcer|canker sore|abscess)(?!\w)")
_ONC_PAT   = re.compile(r"(?i)(?<!\w)(?:oncolog(?:y|ist)|cancer|tumou?r|carcinoma|sarcoma|leukemia|lymphoma|metasta(?:sis|tic)|chemotherapy|immunotherapy|radiation|targeted therapy|precision medicine|cell therapy|gene therapy|oncolytic virus)(?!\w)")
_WOMEN_PAT = re.compile(r"(?i)(?<!\w)(?:pregnan|prenatal|antenatal|postpartum|breastfeeding|lactation|contraception|birth control|iud|pill|menstruation|periods?|pcos|endometriosis|pap(?:\s*smear)?|cervical screening|fibroids?|menopause|hot flashes?|obgyn|gyneco|pelvic pain|vaginal|uterine|ovarian)(?!\w)")
_GYN_PAT   = re.compile(r"(?i)(?<!\w)(?:gynaecolog(?:y|ist)|gynecolog(?:y|ist)|gynae|obgyn)(?!\w)")
_PHYSIO_PAT= re.compile(r"(?i)(?<!\w)(?:physio|physical therapy|physiotherapy|rehab|rehabilitation|range of motion|rom|strengthen(?:ing)?|stretch(?:es|ing)?|exercise plan|home exercise program|low back pain|knee pain|shoulder pain|rotator cuff|tendonitis|tendinopathy|sprain|strain|sciatica|posture|ergonomics)(?!\w)")
_NUTR_PAT  = re.compile(r"(?i)(?<!\w)(?:dietitian|dietitan|diet(?:\s*plan)?|nutrition|meal plan|calories|protein|carbs?|carbohydrate|fat|fiber|fibre|sodium|cholesterol|macros?|glycemic|low[-\s]?fodmap|gluten[-\s]?free|dash(?:\s*diet)?|mediterranean|keto|weight (?:loss|gain)|diabetic diet|renal diet|celiac)(?!\w)")
_COGN_PAT  = re.compile(r"(?i)(?<!\w)(?:memory|attention|concentration|brain fog|cognition|executive function|adhd)(?!\w)")

_INS_NAV_PAT = re.compile(r"(?i)(?<!\w)(?:health(?:\s*care)?\s*insur(?:ance)?|insurance\s+plan|health\s+plan|plan\s+benefits?|benefit\s+summary|policy\s*(?:number|id)|payer|member\s*id|coverage|deductible|co[-\s]?pay|copay|coinsurance|oop(?:\s*max)?|out[-\s]?of[-\s]?pocket|max(?:imum)?|in[-\s]?network|out[-\s]?of[-\s]?network|network)(?!\w)")
_VOB_PAT     = re.compile(r"(?i)(?<!\w)(?:benefits?\s*verification|verify benefits|eligibility (?:check|verification)|vob|coverage check|insurance verification)(?!\w)")
_PA_PAT      = re.compile(r"(?i)(?<!\w)(?:prior\s*authorization|pre[-\s]?auth|precert(?:ification)?|authorization required|utilization management|peer[-\s]?to[-\s]?peer)(?!\w)")
_APPEAL_PAT  = re.compile(r"(?i)(?<!\w)(?:denial|denied claim|appeal|reconsideration|grievance|external review)(?!\w)")
_BILLING_PAT = re.compile(r"(?i)(?<!\w)(?:cpt|hcpcs|icd[-\s]?10|modifier|billing|coding|upcoding|unbundling|place of service|global period|bundling)(?!\w)")
_PHARM_BENEFIT_PAT = re.compile(r"(?i)(?<!\w)(?:formulary|pbm|tier|step therapy|quantity limit|drug (?:authorization|coverage)|prior auth (?:for )?medication|copay card|specialty pharmacy)(?!\w)")
_PUBLIC_PROG_PAT   = re.compile(r"(?i)(?<!\w)(?:medicare|medicaid|chip|cms|medigap|part\s*[abcd]\b|advantage plan|extra help|\blis\b|\bmsp\b)(?!\w)")
_COST_EST_PAT      = re.compile(r"(?i)(?<!\w)(?:cost estimate|estimate (?:my )?out[-\s]?of[-\s]?pocket|allowed amount|price transparency|coinsurance calculation|oop estimate)(?!\w)")
_OON_PAT           = re.compile(r"(?i)(?<!\w)(?:out[-\s]?of[-\s]?network|\boon\b|balance bill(?:ing)?|single[-\s]?case agreement|\bsca\b|no surprises act)(?!\w)")
_EOB_PAT           = re.compile(r"(?i)(?<!\w)(?:explanation of benefits|\beob\b|\bera\b|remark code|member responsibility)(?!\w)")

_ENT_PAT    = re.compile(r"(?i)(?<!\w)(?:\bent\b|otolaryngolog(?:y|ist)|ear(?:ache|(?:\s*infection)?)|otitis|hearing loss|tinnitus|vertigo|dizz(?:y|iness)|sinusitis|rhinitis|throat|tonsillitis|laryngitis|epistaxis|nosebleed|sleep apnea|snoring|deviated septum)(?!\w)")
_ORTHO_PAT  = re.compile(r"(?i)(?<!\w)(?:orthop(?:a|e)dic|orthopedist|fracture|sprain|strain|dislocation|\bacl\b|meniscus|rotator cuff|shoulder dislocation|back pain|knee pain|hip pain|arthritis|tendon(?:itis|opathy)|bursitis|carpal tunnel)(?!\w)")
_GI_PAT     = re.compile(r"(?i)(?<!\w)(?:gastroenterolog(?:y|ist)|\bgi\b|abdominal pain|\bibs\b|\bibd\b|ulcer|gerd|reflux|constipation|diarrhea|nausea|vomiting|liver|hepatitis|pancreatitis|gallstones?|celiac|colonoscopy)(?!\w)")
_PULM_PAT   = re.compile(r"(?i)(?<!\w)(?:pulmonolog(?:y|ist)|lung|asthma|\bcopd\b|emphysema|bronchitis|pneumonia|shortness of breath|dyspn?ea|wheez\w*|chronic cough|inhaler|spiro(?:metry)?)(?!\w)")
_RAD_PAT    = re.compile(r"(?i)(?<!\w)(?:radiolog(?:y|ist)|imaging report|x-?ray|ultra\s*sound|ct(?:\s*scan)?|\bmri\b|pet[-\s]?ct|contrast|gadolinium|iodinated|bi[-\s]?rads)(?!\w)")
_LABTECH_PAT= re.compile(r"(?i)(?<!\w)(?:lab(?:orator(?:y|ies))?|lab test|phlebotom(?:y|ist)|specimen|tube|\bsst\b|\bedta\b|citrate|order of draw|hemoly[sz]is|fasting (?:blood )?test|collection|handling|turnaround time|\btat\b)(?!\w)")
_TX_PLAN_PAT = re.compile(r"(?i)(?<!\w)(?:treatment\s*plan|management\s*plan|care\s*plan|therapy\s*plan|plan\s*of\s*care|\btx\s*plan\b)(?!\w)")
_PEDI_PAT   = re.compile(r"(?i)(?<!\w)(?:pediatric(?:ian|s)?|pediatrics|\bpeds\b|child(?:ren)?|kid(?:s)?|infant|toddler|cold|sore throat|infection|newborn|neonate|baby|adolescent|teen(?:ager)?|school[-\s]?age)(?!\w)")

_CARDIO_PAT = re.compile(r"(?i)(?<!\w)(?:cardio(?:logy|logist)|heart(?: attack| failure| disease)?|(?:angina\s+pectoris|unstable\s+angina|stable\s+angina|prinzmetal(?:'s)?\s+angina)|chest pain|palpitations?|arrhythmia|atrial fibrillation|a[-\s]?fib|\bafib\b|tachycardia|bradycardia|hypertension|high blood pressure|syncope|edema)(?!\w)")
_NEURO_PAT  = re.compile(r"(?i)(?<!\w)(?:neurolog(?:y|ist)|seizures?|epilep\w*|concussion|stroke|t\.?i\.?a\.?|\btia\b|headache|migraine|cluster headache|neuropath\w*|multiple sclerosis|parkinson|tremor|movement disorder|dementia|\bals\b|myasthenia|weakness|numbness|tingling|radiculopath\w*|peripheral neuropathy)(?!\w)")
_NEUROSURG_PAT = re.compile(r"(?i)(?<!\w)(?:neurosurg(?:eon|ery)|herniated disk|spine surg(?:ery)?|laminectomy|discectomy|spinal fusion|decompression|craniotomy|aneurysm (?:clipping|coiling)|ventriculoperitoneal shunt|vp shunt|csf shunt|hydrocephalus|chiari|intracranial pressure|\bicp\b|tumor resection)(?!\w)")
_PAINMGMT_PAT = re.compile(r"(?i)(?<!\w)(?:pain management|interventional pain|nerve block|epidural steroid injection|\besi\b|medial branch block|facet (?:joint )?injection|radiofrequency ablation|\brfa\b|trigger point injection|spinal cord stimulator|\bscs\b|intrathecal pump)(?!\w)")

_URO_PAT   = re.compile(r"(?i)(?<!\w)(?:urolog(?:y|ist)|prostate|\bbph\b|\bpsa\b|hematuria|kidney\s*stone|renal\s*colic|nephrolithiasis|cystitis|\buti\b|pyelonephritis|prostatitis|epididymitis|orchitis|varicocele|hydrocele|phimosis|paraphimosis|incontinence|overactive\s*bladder|erectile\s*dysfunction|\bed\b|nocturia|urinalysis|urosepsis|\bturp\b|\bturbt\b)(?!\w)")

_PHARM_PAT = re.compile(r"(?i)(?<!\w)(?:pharmac(?:ist|y)|\brx\b|prescription|dose|dosing|posology|mg/kg|units?/kg|per[-\s]?kg|loading\s*dose|maintenance\s*dose|max(?:imum)?\s*daily|\bmd(?:d)?\b|titrate|titration|adjust(?:ment|ing)?|renal(?:ly)?|hepatic|\bcrcl\b|child[-\s]?pugh|drug[-\s]?interaction|\bddi\b|contraindicat(?:ion|ed)|side\s*effects?|adverse|toxicit(?:y|ies)|monitor(?:ing)?|\btdm\b|therapeutic\s*(?:range|window|drug\s*monitoring)|reconstitut(?:e|ion)|diluent|infusion|rate|stabilit(?:y|ies)|\biv\b|intravenous|\bim\b|intramuscular|\bsc\b|subcut(?:aneous)?|\bpo\b|oral|tablet|capsule|suspension|solution|mg/m[l1]|mcg/m[l1])(?!\w)")

_IM_PAT = re.compile(r"(?ix)\b( internal\s*medicine|internist|primary\s*care|\bpcp\b|hospitalist|follow[-\s]?up|after[-\s]?visit\s*summary|\bavs\b|preventive\s*care|screen(?:ing)?|hypertension|\bbp\b|hyperlipid(?:emia)?|cholesterol|statins?|diabetes|\ba1c\b|\bhba1c\b|metformin|insulin|thyroid|anemia|electrolyte\s*(?:imbalance|disorders?)|\buti\b|urinary\s*tract\s*infection|vaccine|immuni(?:zation|sation)|\bcmp\b|\bbmp\b|\bcbc\b )\b")

_GENOMICS_PAT = re.compile(r"(?i)(?<!\w)(?:genom(?:e|ic|ics)|dna|rna|sequenc(?:e|ing)|variant(?:s)?|mutation|polymorphism|snps?|indels?|cnvs?|structural variant|vcf|fastq|bam|alignment|bioinformatic(?:s)?|pharmacogenom(?:ics|ics)|pgx|copy number|polygenic|gwas|crispr|base editing|cyp2d6|cyp2c19|slco1b1)(?!\w)")
_BIOTECH_PAT  = re.compile(r"(?i)(?<!\w)(?:biotech(?:nology)?|biopharma|biologic(?:s)?|cell(?:ular)? therapy|gene therapy|vector production|viral vector|aav|lentiviral?|retroviral?|mrna|oligonucleotide|lnp|process development|upstream processing|downstream purification|bioreactor|gmp|cdmo|tech transfer)(?!\w)")
_NEPH_PAT     = re.compile(r"(?i)(?<!\w)(?:nephrolog(?:y|ist)|chronic kidney disease|ckd|\besrd\b|acute kidney injury|aki|proteinuria|albuminuria|hematuria|glomerulonephritis|nephrotic|nephritic|dialysis|hemodialysis|peritoneal dialysis|renal failure|mineral bone disorder|electrolyte imbalance)(?!\w)")

_INS_CTX_PAT = re.compile(r"(?ix)\b( insurance|benefits?|coverage|copay|coinsurance|deductible|\beob\b|prior\s*auth|appeal|denial|\boon\b|out[-\s]?of[-\s]?network|formulary|\bpbm\b )\b")
_DIET_CTX_PAT = re.compile(r"(?ix)\b( diet|nutrition|calories|protein|carb|fat|fiber|meal\s*plan|dietitian|\bdash\b|low[-\s]?fodmap|glycemic )\b")
_MEDITATION_CTX_PAT = re.compile(r"(?ix)\b( meditation|mindfulness|breathwork|guided\s+meditation|box\s+breathing|4-7-8|\bpmr\b|body\s*scan )\b")

_SPECIALTY_PATTERNS = {
    "psychiatry": [_PSYCH_PAT],
    "meditation": [_MEDIT_PAT, _MEDITATION_CTX_PAT],
    "dermatologic": [_DERM_PAT],
    "oral-dental": [_DENT_PAT],
    "oncology": [_ONC_PAT],
    "gynecologic": [_GYN_PAT, _WOMEN_PAT],
    "musculoskeletal": [_ORTHO_PAT, _PHYSIO_PAT],
    "nutrition": [_NUTR_PAT, _DIET_CTX_PAT],
    "cognitive": [_COGN_PAT],
    "otolaryngologic": [_ENT_PAT],
    "gastrointestinal": [_GI_PAT],
    "respiratory": [_PULM_PAT],
    "radiology": [_RAD_PAT],
    "laboratory": [_LABTECH_PAT],
    "pediatrics": [_PEDI_PAT],
    "cardiovascular": [_CARDIO_PAT],
    "neurologic": [_NEURO_PAT],
    "neurosurgery": [_NEUROSURG_PAT],
    "pain": [_PAINMGMT_PAT],
    "urologic": [_URO_PAT],
    "renal": [_NEPH_PAT],
    "genomics": [_GENOMICS_PAT],
    "biotech": [_BIOTECH_PAT],
    "pharmacy": [_PHARM_PAT],
    "insurance": [_INS_CTX_PAT, _INS_NAV_PAT, _VOB_PAT, _PA_PAT, _APPEAL_PAT, _BILLING_PAT, _PHARM_BENEFIT_PAT, _PUBLIC_PROG_PAT, _COST_EST_PAT, _OON_PAT, _EOB_PAT],
    "internal-medicine": [_IM_PAT, _TX_PLAN_PAT],
}

_VERIFIER_SYS = (
    "You are a medical concept disambiguator. "
    "Return strict JSON with keys exactly: topic, anatomy, organ_system, domain_hint, intent. "
    "topic: canonical condition/procedure/test. "
    "anatomy: most specific body site (e.g., 'oral mucosa','tongue','heart','esophagus','skin'). "
    "organ_system: one of {cardiovascular,respiratory,gastrointestinal,hepatobiliary,pancreatic,renal,urologic,gynecologic,obstetric,endocrine,hematologic,musculoskeletal,neurologic,dermatologic,oral-dental,otolaryngologic,ophthalmologic,psychiatry,psychology,nutrition,insurance,biotech,genomics}. "
    "domain_hint: one token like {diagnosis,symptom,procedure,medication,insurance}. "
    "intent: ≤12 words. "
    "Return JSON only."
)
def _verifier_user(q: str) -> str:
    q = " ".join((q or "").split())
    return f"User: {q[:500]}\nJSON only."

_VERIFIER_JSON_RE = re.compile(r"\{[\s\S]*\}$", re.M)

@functools.lru_cache(maxsize=256)
def _verify_topic_json(q: str) -> dict:
    try:
        txt = generate(_VERIFIER_SYS + "\n" + _verifier_user(q), max_new_tokens=64, temperature=0.0)
    except TypeError:
        txt = generate(_VERIFIER_SYS + "\n" + _verifier_user(q))
    m = _VERIFIER_JSON_RE.search(txt or "")
    if not m:
        return {}
    try:
        data = json.loads(m.group(0))
    except Exception:
        try:
            import ast
            data = ast.literal_eval(m.group(0))
        except Exception:
            return {}
    if not isinstance(data, dict):
        return {}
    for k in ["topic","anatomy","organ_system","domain_hint","intent"]:
        v = data.get(k, "")
        data[k] = v if isinstance(v, str) else str(v or "")

    norm_map = {
        "cardio":"cardiovascular","resp":"respiratory","pulm":"respiratory","gi":"gastrointestinal",
        "hepatic":"hepatobiliary","hepatology":"hepatobiliary","pancreas":"pancreatic","renal/kidney":"renal",
        "kidney":"renal","uro":"urologic","gyn":"gynecologic","ob":"obstetric","derm":"dermatologic",
        "ent":"otolaryngologic","oral":"oral-dental","dental":"oral-dental","ophtho":"ophthalmologic",
        "neuro":"neurologic","heme":"hematologic","msk":"musculoskeletal","psych":"psychiatry","ins":"insurance",
        "nutrition/diet":"nutrition"
    }
    os_l = data.get("organ_system","").lower().strip()
    data["organ_system"] = norm_map.get(os_l, os_l)
    dh = data.get("domain_hint","").lower().strip()
    if dh in {"meds","rx","drug"}: dh = "medication"
    if dh in {"proc"}: dh = "procedure"
    if dh in {"dx"}: dh = "diagnosis"
    data["domain_hint"] = dh

    for k in list(data.keys()):
        if k not in {"topic","anatomy","organ_system","domain_hint","intent"}:
            data.pop(k, None)
    return data

def _match_specialties(text: str):
    t = text or ""
    hits = {}
    for spec, pats in _SPECIALTY_PATTERNS.items():
        score = 0
        for p in pats:
            if p.search(t):
                score += 1
        if score:
            hits[spec] = score

    if "psychiatry" in hits and "oncology" in hits:
        hits.pop("psychiatry", None)
    return hits

_PRIORITY = [
    "oncology","neurosurgery","cardiovascular","neurologic","urologic","renal",
    "gastrointestinal","respiratory","otolaryngologic","dermatologic","oral-dental",
    "pediatrics","pain","radiology","laboratory","pharmacy","nutrition","psychiatry",
    "cognitive","musculoskeletal","biotech","genomics","meditation","insurance","internal-medicine"
]

def _pick_by_priority(hits: dict) -> str:
    if not hits:
        return ""
    max_score = max(hits.values())
    cands = [s for s,v in hits.items() if v==max_score]
    for s in _PRIORITY:
        if s in cands:
            return s
    return sorted(cands)[0]

def _prefer_bucket_from_meta(meta: dict) -> str:
    anatomy = (meta.get("anatomy") or "").lower()
    if any(k in anatomy for k in ["oral", "tongue", "gingiva", "tooth", "teeth", "mouth", "buccal", "palate"]): return "oral-dental"
    if any(k in anatomy for k in ["throat", "pharynx", "larynx", "nasal", "sinus", "tonsil", "ear", "nose"]): return "otolaryngologic"
    if any(k in anatomy for k in ["skin", "cutaneous", "scalp", "lip", "cheek"]): return "dermatologic"
    return ""

def _route_from_meta(meta: dict, q: str) -> str:
    organ = (meta.get("organ_system") or "").lower()
    domain = (meta.get("domain_hint") or "").lower()
    if domain == "insurance" or organ == "insurance":
        return "insurance"
    organ_map = {
        "cardiovascular":"cardiovascular","respiratory":"respiratory","pulmonary":"respiratory",
        "neurologic":"neurologic","urologic":"urologic","gastrointestinal":"gastrointestinal",
        "hepatobiliary":"gastrointestinal","pancreatic":"gastrointestinal","dermatologic":"dermatologic",
        "otolaryngologic":"otolaryngologic","oral-dental":"oral-dental","gynecologic":"gynecologic",
        "obstetric":"gynecologic","musculoskeletal":"musculoskeletal","radiology":"radiology",
        "pain":"pain","pharmacy":"pharmacy","renal":"renal","psychiatry":"psychiatry",
        "psychology":"psychiatry","nutrition":"nutrition","ophthalmologic":"internal-medicine",
        "endocrine":"internal-medicine","hematologic":"internal-micine",
        "genomics":"genomics","biotech":"biotech"
    }

    organ_map["hematologic"] = "internal-medicine"
    if organ in organ_map:
        return organ_map[organ]
    b = _prefer_bucket_from_meta(meta)
    if b:
        return b
    if re.search(_IM_PAT, q or ""):
        return "internal-medicine"
    return ""

def _extract_seed_terms(p):
    s = p.pattern
    s = re.sub(r"\(\?i[x]?\)", "", s)
    s = re.sub(r"\(\?<?[=!].*?\)", " ", s)
    s = re.sub(r"\(\?:", "(", s)
    s = re.sub(r"\(\?[imxs-]+\)", "", s)
    s = re.sub(r"\\b", " ", s)
    s = re.sub(r"\\[wWdDsS]+", " ", s)
    s = re.sub(r"\[\^?.*?]", " ", s)
    s = re.sub(r"[()?\*+\{\}|^$\\]", " ", s)
    s = re.sub(r"\s{2,}", " ", s).strip()
    toks = [t.strip() for t in s.split() if len(t.strip()) >= 3]
    return toks[:50]

@functools.lru_cache(maxsize=256)
def _build_seeds():
    seeds = {}
    for spec, pats in _SPECIALTY_PATTERNS.items():
        bag, seen = [], set()
        for p in pats:
            for t in _extract_seed_terms(p):
                tl = t.lower()
                if tl not in seen and not re.fullmatch(r"[a-z]\w?", tl):
                    seen.add(tl)
                    bag.append(t)
        seeds[spec] = bag[:60]
    return seeds

def _learn_from_patterns(text: str) -> str:
    seeds = _build_seeds()
    lines = ["Classify a medical query into exactly one specialty from this list:"]
    lines.append(", ".join(sorted(seeds.keys())))
    lines.append("Use the seed terms only as meaning hints; infer from context even if words differ. Return JSON with key specialty.")
    for spec, tok in seeds.items():
        lines.append(f"{spec}: " + ", ".join(tok[:30]))
    prompt = "\n".join(lines) + "\nQuery: " + (text or "").strip() + "\nJSON only."
    try:
        out = generate(prompt, max_new_tokens=24, temperature=0.0)
    except TypeError:
        out = generate(prompt)
    m = _VERIFIER_JSON_RE.search(out or "")
    if not m:
        return ""
    try:
        obj = json.loads(m.group(0))
        return str(obj.get("specialty","") or "").strip().lower()
    except Exception:
        return ""

def route_specialty(query: str, snippet_text: str = "", use_verifier: bool = True, use_learner: bool = True):
    t = " ".join((query or "").split())
    s = " ".join((snippet_text or "").split())

    meta = {}
    if use_verifier:
        meta = _verify_topic_json(t) or {}
        pref = _route_from_meta(meta, t)
        if pref:
            return {"specialty": pref, "source": "verifier", "verified": True, "details": meta}

    hit_scores = _match_specialties(t + " " + s)
    if hit_scores:
        pick = _pick_by_priority(hit_scores)
        return {"specialty": pick, "source": "regex", "verified": False, "details": {}}

    if use_learner:
        sp = _learn_from_patterns(t + " " + s)
        if sp in _SPECIALTY_PATTERNS:
            return {"specialty": sp, "source": "learner", "verified": False, "details": {}}

    if re.search(_IM_PAT, t):
        return {"specialty": "internal-medicine", "source": "rule", "verified": False, "details": {}}

    return {"specialty": "", "source": "none", "verified": False, "details": {}}

_DUAL_CONTRAST_RE = re.compile(
    r"""(?ix)
    (?:
        # Branch A: compare-intent + "between A and B"
        (?:difference|diff(?:erence)?|compare(?:d)?|comparison|contrast)\b
        .*?\bbetween\b\s+(?P<a>[^?;:,.]+?)\s+\band\b\s+(?P<b>[^?;:,.]+)
      |
        # Branch B: compare-intent + separators (allows 'and' here)
        (?:difference|diff(?:erence)?|compare(?:d)?|comparison|contrast)\b
        \s+(?P<a2>[^?;:,.]+?)\s*
        (?:\bversus\b|\bvs\.?\b|\bv\.?\b|/|,|\band\b|&)\s*
        (?P<b2>[^?;:,.]+)
      |
        # Branch C: no intent words, only explicit vs/versus/v
        (?P<a3>[^?;:,.]+?)\s*
        (?:\bversus\b|\bvs\.?\b|\bv\.?\b)\s*
        (?P<b3>[^?;:,.]+)
    )
    """,
)

def parse_dual_contrast(q: str):
    m = _DUAL_CONTRAST_RE.search(q or "")
    if not m:
        return None
    a = (m.group("a") or m.group("a2") or m.group("a3") or "").strip(" .:-\"'()[]")
    b = (m.group("b") or m.group("b2") or m.group("b3") or "").strip(" .:-\"'()[]")
    return (a, b) if a and b else None

_parse_dual_contrast = parse_dual_contrast

def _specialty_label_from_bucket(bucket: str) -> str:
    bucket = (bucket or "").lower().strip()
    return {
        "cardiovascular": "Cardiologist",
        "respiratory": "Pulmonologist",
        "neurologic": "Neurologist",
        "urologic": "Urologist",
        "renal": "Nephrologist",
        "gastrointestinal": "Gastroenterologist",
        "hepatobiliary": "Gastroenterologist",
        "pancreatic": "Gastroenterologist",
        "dermatologic": "Board-Certified Dermatologist",
        "otolaryngologic": "ENT / Otolaryngologist",
        "oral-dental": "General Dentist",
        "gynecologic": "Obstetrician-Gynecologist",
        "obstetric": "Obstetrician-Gynecologist",
        "musculoskeletal": "General Surgeon",
        "radiology": "Radiologist",
        "pain": "Pain Management Specialist",
        "oncology": "Medical Oncologist",
        "biotech": "Biotech Specialist",
        "genomics": "Genomics Specialist",
        "pharmacy": "Pharmacist",
        "nutrition": "Registered Dietitian",
        "psychiatry": "Psychiatrist",
        "insurance": "Insurance Specialist",
        "internal-medicine": "Internal Medicine Physician",
        "cognitive": "Cognitive Health Clinician",
    }.get(bucket, "Specialist")

def _normalize_advice_heading(h: str) -> str:
    h = (h or "").strip().rstrip(":")
    parts = re.split(r'(\s+|/|-|&)', h)
    def _cap(tok: str) -> str:
        if not tok or not tok[0].isalpha():
            return tok
        ACR = {"ENT","MRI","CT","EEG","ECG","EKG","PET-CT","PET/CT","OB/GYN","OBGYN","CBC","CMP"}
        return tok.upper() if tok.upper() in ACR else tok[0].upper() + tok[1:].lower()
    parts = [_cap(p) if re.match(r'^[A-Za-z]+$', p) else p for p in parts]
    return ''.join(parts).strip() + ":"

def build_dual_contrast_specialist(query: str, snippet_text: str):
    q = _pre(query); s = _pre(snippet_text or "")
    halves = _parse_dual_contrast(q or "")
    if not halves:
        return None
    qa, qb = halves
    ra = route_specialty(qa, s, use_verifier=True, use_learner=True)
    rb = route_specialty(qb, s, use_verifier=True, use_learner=True)
    spa = (ra.get("specialty") or "").lower()
    spb = (rb.get("specialty") or "").lower()
    head_a = _normalize_advice_heading(f"{_specialty_label_from_bucket(spa)} Advice")
    head_b = _normalize_advice_heading(f"{_specialty_label_from_bucket(spb)} Advice")
    section_spec = (
        "(ONE compact paragraph; 6–8 sentences; simple clinical language for the general public; "
        "clear steps for what to do now with brief reasons; include first-line self-care or emergency medicines "
        "with typical adult dose/route/frequency and key cautions when appropriate; briefly suggest 1–3 follow-up "
        "tests to confirm the diagnosis when relevant (name each test and why it helps); give a brief treatment plan "
        "overview rather than exhaustive details; state when to seek urgent versus routine care and the key red flags; "
        "avoid jargon; no bullets or numbered lists)"
    )
    dyn_sections = f"{head_a} {section_spec}; {head_b} {section_spec}; Disclaimer."
    rules = [
        "Write ONLY the answer; do NOT repeat or quote the question or any instructions.",
        "Use Title Case section headings that end with a colon.",
        "Include ONLY the two Advice headings above plus the final 'Disclaimer:'.",
        "Each Advice section must be exactly one paragraph of 6–8 sentences; no lists, tables, or emojis.",
        "Use plain, non-technical language; define any unavoidable medical term in simple words.",
        "When suggesting tests, name at most 1–3 and include a short purpose (e.g., 'ECG to check…').",
        "Provide only a brief treatment overview; detailed clinician-level protocols are out of scope here.",
        "Include medication guidance only when appropriate, using generic names with typical adult dose, route, frequency, and key cautions.",
        "Do not mention audience or that the response was tailored.",
        "The final heading MUST be exactly 'Disclaimer:'.",
        "End exactly with <<<END>>>."
    ]
    return _mk(
        "You are a medical specialist writing for the general public. Provide two separate Advice sections for the two topics, stitched into one answer.",
        rules,
        dyn_sections,
        "Answer now.",
        s,
        q
    )

def _detect_specialty(query, snippet_text):
    _duo = _parse_dual_contrast(query or "")
    if _duo:
        resp = build_dual_contrast_specialist(query, snippet_text)
        if resp:
            return resp
    qn = " ".join((query or "").lower().split())
    if _TX_PLAN_PAT.search(qn):
        routed = route_specialty(query, snippet_text, use_verifier=True, use_learner=True)
        sp = (routed.get("specialty") or "").lower()
        persona_map = {
            "pediatrics": "Pediatrician (Treatment Planning)",
            "cardiovascular": "Cardiologist (Treatment Planning)",
            "otolaryngologic": "ENT / Otolaryngologist (Treatment Planning)",
            "musculoskeletal": "General Surgeon (Treatment Planning)",
            "gastrointestinal": "Gastroenterologist (Treatment Planning)",
            "respiratory": "Pulmonologist (Treatment Planning)",
            "radiology": "Radiologist (Treatment Planning)",
            "laboratory": "Diagnostic Laboratory Technologist (Treatment Planning)",
            "neurosurgery": "Neurosurgeon (Treatment Planning)",
            "neurologic": "Neurologist (Treatment Planning)",
            "pain": "Pain Management Specialist (Treatment Planning)",
            "oncology": "Medical Oncologist (Treatment Planning)",
            "biotech": "Biotech & Translational Scientist (Treatment Planning)",
            "genomics": "Clinical Genomicist (Treatment Planning)",
            "gynecologic": "Obstetrician-Gynecologist (Treatment Planning)",
            "oral-dental": "General Dentist (Treatment Planning)",
            "dermatologic": "Board-Certified Dermatologist (Treatment Planning)",
            "musculoskeletal-physio": "Licensed Physical Therapist (Treatment Planning)",
            "nutrition": "Registered Dietitian (Treatment Planning)",
            "psychiatry": "Psychiatrist (Treatment Planning)",
            "urologic": "Urologist (Treatment Planning)",
            "renal": "Nephrologist (Treatment Planning)",
            "pharmacy": "Pharmacist (Treatment Planning)",
            "internal-medicine": "Internal Medicine Physician (Treatment Planning)",
        }
        persona = persona_map.get(sp) or "Internal Medicine Physician (Treatment Planning)"
        return build_treatment_planning_prompt(query, snippet_text, persona=persona)
    if _OON_PAT.search(qn):           return build_out_of_network_prompt(query, snippet_text)
    if _EOB_PAT.search(qn):           return build_eob_explainer_prompt(query, snippet_text)
    if _APPEAL_PAT.search(qn):        return build_claims_appeal_prompt(query, snippet_text)
    if _PA_PAT.search(qn):            return build_prior_authorization_prompt(query, snippet_text)
    if _VOB_PAT.search(qn):           return build_benefits_verification_prompt(query, snippet_text)
    if _PHARM_BENEFIT_PAT.search(qn): return build_pharmacy_benefits_prompt(query, snippet_text)
    if _PUBLIC_PROG_PAT.search(qn):   return build_public_programs_prompt(query, snippet_text)
    if _COST_EST_PAT.search(qn):      return build_cost_estimation_prompt(query, snippet_text)
    if _BILLING_PAT.search(qn):       return build_medical_billing_coding_prompt(query, snippet_text)
    if _INS_NAV_PAT.search(qn):       return build_insurance_navigator_prompt(query, snippet_text)
    routed = route_specialty(query, snippet_text, use_verifier=True, use_learner=True)
    sp = (routed.get("specialty") or "").lower()
    builder_map = {
        "pediatrics":         build_pediatrician_prompt,
        "cardiovascular":     build_cardiology_prompt,
        "otolaryngologic":    build_ent_prompt,
        "musculoskeletal":    build_orthopedics_prompt,
        "gastrointestinal":   build_gastroenterology_prompt,
        "respiratory":        build_pulmonology_prompt,
        "radiology":          build_radiology_prompt,
        "laboratory":         build_lab_technician_prompt,
        "neurosurgery":       build_neurosurgery_prompt,
        "neurologic":         build_neurology_prompt,
        "pain":               build_pain_management_prompt,
        "oncology":           build_oncology_prompt,
        "biotech":            build_biotech_prompt,
        "genomics":           build_genomics_prompt,
        "gynecologic":        build_womens_health_prompt,
        "oral-dental":        build_dentistry_prompt,
        "dermatologic":       build_dermatology_prompt,
        "nutrition":          build_dietitian_prompt,
        "meditation":         build_meditation_prompt,
        "psychiatry":         build_psychiatry_prompt,
        "urologic":           build_urology_prompt,
        "renal":              build_nephrology_prompt,
        "pharmacy":           build_pharmacist_prompt,
        "insurance":          build_insurance_navigator_prompt,
        "internal-medicine":  build_internal_medicine_prompt,
        "cognitive":          build_psychiatry_prompt,
    }
    if sp in builder_map:
        return builder_map[sp](query, snippet_text)
    if re.search(_IM_PAT, qn):
        return build_internal_medicine_prompt(query, snippet_text)
    return None

_SELF_HARM_RE = re.compile(r"""(?ix)\b(kill\s*myself|end\s*my\s*life|suicide|self[-\s]*harm|hurt\s*myself|cut(?:ting)?\s*myself|\bod\b|i\s*want\s*to\s*die|(?:hang)\s*myself|die\s*by\s*suicide)\b""")
_HARM_OTHERS_RE = re.compile(r"""(?ix)\b((?:kill|murder|shoot|bomb|kidnap|abduct)\b)""")
_HC_UNITS_RE = re.compile(r"\b(?:mg|mcg|µg|g|iu|units?|mL|ml|L|mg/kg|mcg/kg|mEq|mmol/?L|µmol/?L)\b", re.I)
_HC_VITALS_RE = re.compile(
    r"(?i)\b(?:bp|blood\s*pressure)\s*\d{2,3}/\d{2,3}\b|"
    r"\b(?:hr|heart\s*rate|pulse)\s*\d{2,3}\b|"
    r"\b(?:rr|resp(?:iratory)?\s*rate)\s*\d{1,2}\b|"
    r"\b(?:spo2|o2\s*sats?|oxygen\s*saturation)\s*\d{2}%\b|"
    r"\b(?:temp(?:erature)?|t)\s*\d{2}\s*[cf]\b"
)
_HC_DOSING_RE = re.compile(
    r"\b(?:q\d{1,2}\s*(?:h|hr|hrs|d)|qod|od|bd|bid|tid|qid|qhs|qam|qpm|prn|stat|po|oral|iv|im|sc|subcut|sq|topical|transdermal|inhal(?:ed|ation)|intranasal|pr|sl|buccal)\b",
    re.I,
)
_HC_MORPH_DISEASE_RE = re.compile(
    r"\b[a-z]{3,}(?:itis|emia|osis|oma|opathy|algia|uria|rrhea|neuropathy|dermatitis|carditis|nephritis|hepatitis|arthrit(?:is)?|myopathy|cardiomyopathy|encephalopathy)\b",
    re.I,
)
_HC_MORPH_PROC_RE = re.compile(
    r"\b[a-z]{3,}(?:ectomy|otomy|plasty|scopy|graphy|gram|stomy|centesis|ablation|biopsy|pexy|lysis|desis|arthroplasty|catheterization|angioplasty|transplant(?:ation)?)\b",
    re.I,
)
_HC_DRUG_SUFFIX_RE = re.compile(
    r"\b[a-z]{3,}(?:pril|sartan|olol|statin|azole|cycline|floxacin|cillin|mycin|prazole|tidine|caine|dronate|zide|mide|gliptin|gliflozin|glitazone|mab|nib|limus|avir|ovir|mol)\b",
    re.I,
)
_HC_LAB_RE = re.compile(
    r"\b(?:wbc|rbc|hgb|hct|hba1c|a1c|tsh|t3|t4|ldl|hdl|tg|alt|ast|alp|ggt|crp|esr|inr|ptt|pt|troponin|creatinine|bun|egfr|cbc|cmp|lfts?|bilirubin|d[- ]?dimer|psa|cea|afp|ca[- ]?125|her2|brca)\b|"
    r"\b(?:mg/dl|mmol/l|meq/l|u/l|iu/l|ng/ml|pg/ml)\b",
    re.I,
)
_HC_ANAT_RE = re.compile(
    r"\b(?:cardio|coronary|neuro|pulmo|renal|hepatic|derma|gastro|endocrine|thyroid|pancrea|colon|stomach|liver|kidney|lung|heart|brain|skin|bone|muscle|spine|ocular|optic|otitis|sinus|ear|nose|throat|prostate|breast|ovary|uterus|cervix|test(?:is|es)|adrenal|pituitary|spleen|gallbladder)\w*\b",
    re.I,
)
_HC_BODY_RE = re.compile(
    r"\b("
    r"head|scalp|skull|face|eye|eyes|eyelid|eyebrow|eyelash|pupil|iris|ear|ears|eardrum|nose|nostril|sinus|mouth|lip|tongue|tooth|teeth|gum|jaw|cheek|palate|throat|tonsil|larynx|voice box|trachea|windpipe|neck|nape|"
    r"shoulder|clavicle|collarbone|scapula|arm|upper arm|elbow|forearm|wrist|hand|palm|finger|thumb|nail|"
    r"chest|rib|sternum|breast|axilla|armpit|back|spine|spinal cord|vertebra|"
    r"abdomen|belly|stomach|navel|umbilicus|flank|groin|pelvis|hip|buttock|"
    r"genital|penis|scrotum|testicle|testis|vagina|vulva|uterus|cervix|ovary|"
    r"thigh|knee|patella|leg|calf|ankle|heel|foot|feet|toe|toes|sole|"
    r"brain|cerebellum|cerebrum|nerve|tendon|ligament|cartilage|muscle|fascia|marrow|bone|"
    r"artery|vein|capillary|blood|plasma|platelet|red blood cell|white blood cell|"
    r"lung|bronchus|bronchi|alveoli|diaphragm|"
    r"heart|atrium|ventricle|aorta|valve|"
    r"liver|kidney|spleen|pancreas|gallbladder|bile duct|"
    r"bladder|urethra|prostate|colon|rectum|anus|"
    r"thyroid|parathyroid|adrenal|pituitary|hypothalamus|ovaries|testes|"
    r"skin|dermis|epidermis|hair|follicle|sweat gland|sebaceous gland|"
    r"organ|tissue|cell"
    r")\b",
    re.I,
)
_HC_DOC_RE = re.compile(r"""(?ix)
\b(
    hpi|ros|pmh|psh|fh|sh|soc(?:ial)?\s*hx|med(?:ication)?\s*hx|all(?:ergy|ergies)|
    a\/?p|assessment(?:\s*\/\s*plan)?|plan|impression|
    h&?p|history\s*(?:and|&)\s*physical|
    soap(?:\s*note)?|
    progress\s*note|clinic(?:al)?\s*note|office\s*note|triage\s*note|ed\s*note|er\s*note|
    consult(?:ation)?\s*note|admission\s*note|discharge\s*(?:note|summary)|
    operative\s*note|op\s*note|procedure\s*note|
    attending\s*addendum|resident\s*note|nursing\s*note|
    radiology\s*report|pathology\s*report|lab\s*report
)\b
""")
_HC_ACRONYM_RE = re.compile(r"""(?ix)
\b(
  ECG|EKG|EEG|MRI|CT|XR|US|PET(?:-CT|\/CT)?|
  CBC|CMP|BMP|LFT|KFT|ABG|PFT|FEV1|SpO2|O2|BP|HR|RR|
  AED|CPR|BLS|ALS|
  SSRI|SNRI|TCA|MAOI|CBT|DBT|PTSD|OCD|ADHD|
  NSAID|DME|DVT|PE|GERD|IBS|IBD|CKD|AKI|UTI|
  HbA1c|A1C|TSH|T3|T4|LDL|HDL|PSA|
  OB\/GYN|OBGYN|ENT|PT|OT|ROM|PMR
)\b
""")

_HC_GENERAL_RE = re.compile(r"""(?ix)
\b(
    symptom(?:s)?|signs?|stress|tension|burnout|distress|
    diagnosis|diagnose|screen(?:ing)?|risk\s*factors?|prevention|prognosis|
    management|treatment|therap(?:y|ies)|
    procedure|surgery|operation|first\s*aid|resuscitation|bls|als|aed|defibrillat(?:or|ion)|cpr|
    biomarker|tumou?r\s*marker|genetic\s*test|imaging|x[-\s]?ray|ultra\s*sound|ct|mri|
    vaccine|immunization|side\s*effects?|contraindications?|precautions?|dos(?:e|ing)|mg\/?kg|tablet|capsule|syrup|
    concussion|fracture|sprain|hypertension|diabetes|asthma|cancer|infection|antibiotic|antiviral|analgesic|
    chemotherapy|radiation|

    meditat(?:e|ion|ive)\b|mindfulness\b|guided\s*meditation|guided\s*imagery|visuali[sz]ation|
    loving[-\s]?kindness(?:\s+meditation)?|lovingkindness(?:\s+meditation)?|love[-\s]?kindness(?:\s+meditation)?|
    metta(?:\s+meditation)?|lkm(?:\s+meditation)?|compassion\s*meditation|kindness\s*meditation|
    breath(?:ing)?\s*exercise(?:s)?|breathwork|pranayama|box\s*breath(?:ing)?|4[-\s]?7[-\s]?8\s*breath(?:ing)?|
    body\s*scan|grounding\s*techniques?|progressive\s*muscle\s*relaxation|pmr\b|relaxation\s*training|
    acceptance\s*and\s*commitment\s*therapy|(?:\bact\b)|cognitive\s*behavioral\s*therapy|\bcbt\b|
    dialectical\s*behavior\s*therapy|\bdbt\b|exposure\s*therapy|behavioral\s*activation|
    sleep\s*hygiene|insomnia\s*treatment|stress\s*reduction|mindfulness[-\s]?based|

    cognition|cognitive\s*(?:training|rehabilitation|exercises?|stimulation)|brain\s*fog|
    attention|focus|concentration|memory\s*exercise(?:s)?|executive\s*function|working\s*memory|
    adhd|\badd\b|neurocognitive|cognitive\s*screen(?:ing)?|\bmo(?:ca|ca[-\s]?test)\b|\bmmse\b|

    psychiatrist|psychologist|psychotherapy|therapy|

    genom(?:e|ic|ics)|genetic(?:s)?|genotyping|sequenc(?:e|ing)|ngs\b|whole\s+(?:exome|genome)\s+sequenc(?:e|ing)|\bwgs\b|\bwes\b|
    exome\s*panel|panel\s*testing|\bgwas\b|polygenic\s*risk\s*score|\bprs\b|\bsnp(?:s)?\b|\bcnv(?:s)?\b|\bsv(?:s)?\b|
    variant\s*(?:calling|classification|interpretation|annotation|filtration)|\bacmg\b|pathogenic(?:ity)?|likely\s*pathogenic|\bvus\b|
    precision\s*medicine|personal(?:i)?zed\s*medicine|targeted\s*therap(?:y|ies)|companion\s*diagnostic(?:s)?|\bcdx\b|
    pharmacogenom(?:y|ic|ics)|\bpgx\b|\bcyp\d+[a-z0-9]*\b|

    reference\s*genome|reference\s*build|grch(?:37|38)\b|hg(?:19|38)\b|refseq|ensembl|
    library\s*prep|adapter\s*(?:trim|trimming)|umi(?:s)?\b|unique\s*molecular\s*identifier(?:s)?|
    barcod(?:e|ing)|demultiplex(?:ing)?|sample\s*index(?:es)?|index\s*hop(?:ping)?|
    basecall(?:er|ing)|guppy|dorado|bcl2fastq|
    read(?:s)?|paired[-\s]?end|single[-\s]?end|insert\s*size|fragment\s*size|coverage|depth|mean\s*coverage|uniformity|
    long[-\s]?read|short[-\s]?read|hifi\s*reads?|circular\s*consensus|ccs\b|subreads?|n50\b|
    nanopore|ont\b|promethion|minion|flongle|illumina|hiseq|novaseq|miseq|nextseq|iSeq|bgiseq|mgiseq|pacbio|sequel\s*ii?e?\b|

    fastq\b|fasta\b|bam\b|cram\b|bai\b|crai\b|sam\b|vcf\b|bcf\b|bed\b|gff3?\b|gtf\b|
    fastqc|multiqc|seqkit|cutadapt|trimmomatic|fastp|
    alignment|mapper|bwa(?:[-\s]mem2?)?\b|bowtie2?\b|minimap2\b|hisat2\b|star\b|novoalign|
    duplicate\s*mark(?:ing|er)?|picard|mosdepth|samtools|bcftools|freebayes|gatk|mutect2?|haplotypecaller|lofreq|
    cnvkit|manta|delly|lumpy|sniffles|pbsv|svim|strelka2?|vardict|varscan|deepvariant|
    annotation|vep\b|annovar|snpeff|db\s*snp|clinvar|gnomad|hgvs\b|cosmic\b|
    expression|rna[-\s]?seq|kb\s*python|salmon|kallisto|rsem|featureCounts|htseq(?:[-\s]?count)?|
    differential\s*expression|deseq2|edger|limma|pseudobulk|tpm\b|fpkm\b|counts?\b|

    single[-\s]*cell|single[-\s]*nucleus|snrna[-\s]?seq|scrna[-\s]?seq|\bscatac[-\s]?seq\b|atac[-\s]?seq|chip[-\s]?seq|dnase[-\s]?seq|hi[-\s]?c|
    spatial\s*transcriptomics|visium|xenium|cosmx|merfish|
    seurat|scanpy|anndata|loom|doublet\s*detect(?:ion)?|harmony|bbknn|integration|
    dimension(?:al)?\s*reduction|umap|t[-\s]?sne|leiden|louvain|trajectory\s*inference|pseudotime|

    gene\s*therapy|gene\s*editing|crispr(?:[-\s]?cas\d+)?|cas\d+|base\s*editing|prime\s*editing|pegRNA|sgRNA|guide\s*rna|
    hdr|nhej|off[-\s]?target|on[-\s]?target|pam\s*site|
    aav\b|adeno[-\s]?associated\s*virus|lentiviral?|retroviral?|viral\s*vector|vector\s*delivery|serotype|
    in[-\s]?vivo|ex[-\s]?vivo|in[-\s]?situ|
    car[-\s]?t\b|t[-\s]?cell\s*therapy|tcr\s*therapy|nk\s*cell\s*therapy|cell\s*therapy|stem\s*cell\s*therapy|ipscs?|

    monoclonal\s*antibod(?:y|ies)|\bmabs?\b|bispecific|trispecific|adc\b|antibody[-\s]?drug\s*conjugate|fusion\s*protein|
    biologic(?:s)?|biosimilar(?:s)?|reference\s*product|interchangeab(?:le|ility)|totality\s*of\s*evidence|

    transcriptom(?:e|ics)|proteom(?:e|ics)|metabolom(?:e|ics)|multi[-\s]?omics?|
    epigenom(?:e|ics)|methyl(?:ome|ation)|bisulfite(?:\s*sequenc(?:e|ing))?|
    differential\s*methylation|dmrs?|\bdmr\b|

    bioinformatic(?:s)?|pipeline|workflow|lims|eln|sample\s*tracking|batch\s*effect|normalization|
    pathway\s*enrichment|gene\s*set\s*enrichment|gsea\b|go\b|kegg|reactome|string\s*db|
    qc\b|qa\b|data\s*integrity|alcoa\+?|audit\s*trail|part\s*11|annex\s*11|metadata|

    dna\b|r(?:ibo)?na\b|deoxyribo(?:nucleic\s*acid)?|nucleic\s*acid(?:s)?|nucleotide(?:s)?|
    base[-\s]?pair(?:s|ing)?|complement(?:ary|arity)|reverse[-\s]?complement|
    watson[-\s]?crick|double[-\s]?helix|5['’]?\s*(?:-|→|to)\s*3['’]?|
    antisense|sense\s*strand|coding\s*strand|template\s*strand|
    codon|anticodon|transcription|translation|m?rna\b|t?rna\b|r?rna\b|
    adenine|thymine|guanine|cytosine|uracil|poly[-\s]?a\s*tail|introns?|exons?|
    start\s*codon|stop\s*codon|open\s*reading\s*frame|orf\b|

    oncogenomic(?:s)?|molecular\s*profiling|tumou?r\s*profiling|somatic\s*vs?\s*germline|somatic\s+mutation|germline\s+mutation|
    actionable\s*mutation|driver\s*mutation|passenger\s*mutation|tumou?r\s*mutational\s*burden|\btmb\b|msi[-\s]?h|\bdmmr\b|\bmmr\b|
    hr(?:d|d\s*score)\b|loss\s*of\s*heterozygosity|\bloh\b|cnloh\b|copy\s*number\s*(?:alteration|amplification|gain|loss)|\bcna(?:s)?\b|
    pd[-\s]?l1|\balk\b|\bbrca1?\b|\bbrca2\b|\btp53\b|\begfr\b|\bkras\b|\bnras\b|\bbraf\b|\bpi3k\b|\bpik3ca\b|\bpten\b|\berbb2\b|\bher2\b|\bmet\b|\bfgfr[23]\b|\bidh[12]\b|\bms[hm][26]\b|\bmlh1\b|\bpms2\b|\bntrk[123]?\b|\bret\b|\bros1\b|
    fusions?|rearrangements?|amplifications?|
    immunohistochem(?:istry|ical)|\bihc\b|\bfish\b|in[-\s]?situ\s*hybridization|
    liquid\s*biops(?:y|ies)|\bctdna\b|minimal\s*residual\s*disease|\bmrd\b|tumou?r\s*purity|variant\s*allele\s*frequency|\bvaf\b|
    tumour[-\s]?normal\s*matched|ffpe\b|coverage\s*depth|read\s*depth|bioinformatic\s*pipeline|
    amp\b|asco\b|cap\b|amp/asco/cap|

    biotech|biotechnolog(?:y|ies)|translational\s*(?:research|medicine)|genomics|

    proteomics?|protein\s*analys(?:is|es)|protein\s*characterization|protein\s*quantification|
    western\s*blot|sds[-\s]?page|two[-\s]?dimensional\s*gel|2d[-\s]?page|isoelectric\s*focusing|ief\b|
    mass\s*spectromet(?:ry|ric)|lc[-\s]?ms(?:\/ms)?|gc[-\s]?ms|maldi(?:[-\s]?tof)?\b|esi[-\s]?ms|
    chromatography|hplc\b|uhplc\b|uplc\b|sec\b|size[-\s]?exclusion|iec\b|ion[-\s]?exchange|rp[-\s]?hplc|reverse[-\s]?phase|
    capillary\s*electrophoresis|ce[-\s]?ms|
    elisa\b|immunoassay|sandwich\s*assay|luminex\b|multiplex\s*assay|
    immunoprecipitation|co[-\s]?ip|pull[-\s]?down|affinity\s*purification|his[-\s]?tag|ni[-\s]?nta|protein\s*a\/g|
    surface\s*plasmon\s*resonance|spr\b|bio[-\s]?layer\s*interferometry|bli\b|itc\b|dsc\b|circular\s*dichroism|cd\s*spectroscop\w*|
    x[-\s]?ray\s*crystallograph\w*|\bnmr\b|cryo[-\s]?em|
    post[-\s]?translational\s*modifications?|ptms?|phosphorylation|glycosylation|ubiquitin(?:ation)?|acetylation|methylation|
    protease\s*assays?|kinase\s*assays?|enzyme\s*kinetics|
    recombinant\s*expression|cho\b|hek\s*293|e\.?coli|baculovirus|yeast\s*expression|cell[-\s]?free\s*expression|
    uniprot\b|pdb\b|alphafold2?\b|colabfold\b|blast[pn]?\b|hmmer\b|rosetta\b|fold(?:ing)?\s*stabilit\w*|

    q(?:pcr|rt[-\s]?pcr|rtpcr)\b|ddpcr\b|sanger\s*sequenc\w*|capillary\s*sequenc\w*|microarray|
    methylation\s*array|450k\b|epic\b|

    upstream\s*processing|downstream\s*purification|bioreactor|single[-\s]?use|fed[-\s]?batch|perfusion|
    tff\b|ultra[-\s]?filtration|diafiltration|chromatograph(?:y|ic)|
    formulation\s*development|stability\s*study|release\s*testing|potency\s*assay|specification|
    cmo\b|cdmo\b|tech\s*transfer|scale[-\s]?up|process\s*validation|ppq\b|qbd\b|doe\b|pat\b|
    cgm[pP]\b|gmp\b|glp\b|gcp\b|gxp\b|cmc\b|module\s*3|regulator(?:y|ies?)|ind\b|cta\b|bla\b|maa\b|nda\b|ima\b|
    immunogenicit(?:y|ies)|anti[-\s]?drug\s*antibodies?|ada\b|nab\b|neutralizing\s*antibodies|pk/?pd|biodistribution|toxicokinetics?|

    health\s*(?:plan|insurance|benefit(?:s)?|coverage|policy)
)\b
""")

_NON_TECH_RE = re.compile(r"\b(?:python|javascript|java|sql|docker|kubernetes|api|sdk|gpu|model|function|class|bug|deployment|server|database|regex)\b", re.I)
_NON_FIN_RE = re.compile(r"\b(?:stock|crypto|bitcoin|forex|interest rate|mortgage|tax|budget|invoice|revenue|profit|earnings)\b", re.I)
_NON_MISC_RE = re.compile(r"\b(?:recipe|cook|bake|hotel|flight|travel|itinerary|football|crop|soccer|nba|fifa|gaming|console|movie|tickets?|concert)\b", re.I)

def preprocess_text(text: str) -> str:
    text = html.unescape(text or "")
    text = re.sub(r'(?i)\b(?:e\.?\s*g\.?)\b\.?', 'e.g.', text)
    text = re.sub(r'(?i)\b(?:i\.?\s*e\.?)\b\.?', 'i.e.', text)
    text = text.strip()
    text = re.sub(r"\s+", " ", text)
    if not re.match(r".*[.?!]$", text):
        text += "?"
    return text

def _healthcare_heuristic_label(text: str) -> str:
    t = (text or "")
    if _HC_BODY_RE.search(t):
        return "health"
    pos = 0
    pos += 2 * len(_HC_UNITS_RE.findall(t))
    pos += 3 * len(_HC_VITALS_RE.findall(t))
    pos += 2 * len(_HC_DOSING_RE.findall(t))
    pos += 2 * len(_HC_MORPH_DISEASE_RE.findall(t))
    pos += 3 * len(_HC_MORPH_PROC_RE.findall(t))
    pos += 3 * len(_HC_DRUG_SUFFIX_RE.findall(t))
    pos += 2 * len(_HC_LAB_RE.findall(t))
    pos += 1 * len(_HC_ANAT_RE.findall(t))
    pos += 3 * len(_HC_DOC_RE.findall(t))
    pos += 4 * len(_HC_ACRONYM_RE.findall(t))
    pos += 3 * len(_HC_GENERAL_RE.findall(t))
    if pos > 30: pos = 30
    neg = 0
    neg += 3 * len(_NON_TECH_RE.findall(t))
    neg += 2 * len(_NON_FIN_RE.findall(t))
    neg += 1 * len(_NON_MISC_RE.findall(t))
    if neg > 20: neg = 20
    if pos >= 6 and (pos - neg) >= 3:
        return "health"
    if neg >= 6 and pos <= 3:
        return "non"
    return "uncertain"

def _raw_classify(prompt: str) -> str:
    result = generator(
        prompt,
        max_new_tokens=1024,
        repetition_penalty=1.0,
        early_stopping=True,
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.pad_token_id,
        temperature=0.0,
        do_sample=False,
        top_p=1.0,
    )
    out = result[0]["generated_text"]
    if out.startswith(prompt):
        out = out[len(prompt):]
    return out.strip()

def is_healthcare_question(query: str) -> bool:
    q = preprocess_text(query)

    allow_names = [
        "_HC_BODY_RE",
        "_HC_GENERAL_RE",
        "_HC_DOC_RE",
        "_MEDIT_PAT",
        "_COGN_PAT",

        "_INS_NAV_PAT", "_VOB_PAT", "_PA_PAT", "_APPEAL_PAT", "_BILLING_PAT",
        "_PHARM_BENEFIT_PAT", "_PUBLIC_PROG_PAT", "_COST_EST_PAT", "_OON_PAT", "_EOB_PAT",
    ]
    for name in allow_names:
        pat = globals().get(name)
        if hasattr(pat, "search") and pat.search(q):
            return True

    label = _healthcare_heuristic_label(q)
    if label == "health":
        return True
    if label == "non":
        return False

    cls_prompt = (
    "You are a precise, literal classifier. "
    "Decide if the user's question is PRIMARILY about human healthcare/medicine. "
    "INCLUDE as healthcare: human diseases, symptoms, diagnosis, tests, treatments, medications, procedures, "
    "clinical guidelines, mental health, meditation/mindfulness practices, genomics/biotechnology/bioinformatics as health interventions, "
    "nutrition as it relates to health, public health, occupational or environmental exposures with explicit human health impact, "
    "and healthcare systems/health insurance. "
    "EXCLUDE (answer NO) if the question is primarily about socioeconomics, politics, law/policy, education, agriculture/crops, environment or climate policy in general, "
    "sports, travel, entertainment, finance, or software/IT—unless the question explicitly frames these in terms of human health, medical care, exposure, risk, outcomes, or health system operations. "
    "If and only if the main focus is healthcare/medicine, output exactly: YES. Otherwise output exactly: NO.\n\n"
    f"Question: {q}\n"
    "Answer (YES or NO only):"
)
    try:
     out = _raw_classify(cls_prompt).upper()
    except Exception:
     return label != "non"
    return out.startswith("YES")

def _self_harm_support_response(query: str) -> str:
    p = (
        "You are a compassionate mental-health support assistant. The user may mention self-harm. "
        "Write a short, generic, location-agnostic response that includes: "
        "1) an empathetic opening, 2) immediate safety guidance to contact local emergency services if at risk, "
        "3) advice to reach a local suicide/crisis hotline without listing specific phone numbers or URLs, "
        "4) one brief breathing exercise and a 3–5 step mini-meditation, "
        "5) encouragement to seek professional help and to reach out to someone they trust. "
        "Keep it under 150 words, use plain language and second person, and avoid links, numbers, or country names."
        f"\n\nUser: {preprocess_text(query)}\nResponse:"
    )
    try:
        raw = generate(p, max_new_tokens=300, temperature=0.0)
    except TypeError:
        raw = generate(p)
    txt = _safe_text(raw, query)
    return txt if txt else "If you are in immediate danger, contact your local emergency number now. You deserve support; consider speaking with a trusted person and a local crisis hotline. Try slow breathing: inhale 4, hold 4, exhale 4, hold 4, for a minute. Sit comfortably and notice five things you see, four you feel, three you hear, two you smell, and one you taste. A mental health professional can help—please reach out today."

def guard_and_build_prompt(query, snippet_text):
    import re
    q = (query or "")
    qn = " ".join(q.lower().split())

    self_harm_intent = re.compile(
        r"(?ix)\b("
        r"(?:i\s*(?:want|plan|intend|am\s+going)\s*to\s*(?:die|kill\s*myself|end\s*my\s*life|overdose|poison\s*myself|hurt\s*myself))"
        r"|(?:how\s*to\s*(?:kill\s*myself|commit\s*suicide|overdose|poison\s*myself))"
        r"|(?:best\s*way\s*to\s*(?:die|kill\s*myself|poison\s*myself))"
        r")\b"
    )
    harm_others_intent = re.compile(
        r"(?ix)\b("
        r"(?:how\s*to|best\s*way\s*to|ways?\s*to|i\s*(?:want|plan|intend)\s*to)\s*"
        r"(?:kill|poison(?!\s+ivy)|hurt|harm|stab|shoot(?:\s*up)?|bomb|kidnap|abduct|make\s*(?:a|some)?\s*poison)\b"
        r".*?\b(?:someone|people|person|him|her|them|class|crowd|school|office|neighbor|boss|wife|husband|partner|teacher|ex|stranger)\b"
        r")"
    )
    make_poison_intent = re.compile(
        r"(?i)\b(?:how\s*to|steps?\s*to|recipe\s*for|make|synthesi[sz]e|create)\s+(?:a|some)?\s*poison(?!\s+ivy)\b"
    )

    benign_toxicology = re.compile(
        r"(?i)\b(accidentally|unintentionally|exposed|ingested|swallowed|contact|poison\s*control|tox(?:icology|in)|msds|first\s*aid|what\s*to\s*do|treatment|antidote)\b"
    )

    if self_harm_intent.search(qn) or (_SELF_HARM_RE.search(qn) if '_SELF_HARM_RE' in globals() else False):
        return "SELF_HARM_SUPPORT"

    if harm_others_intent.search(qn) or make_poison_intent.search(qn) or (_HARM_OTHERS_RE.search(qn) if '_HARM_OTHERS_RE' in globals() else False) or re.search(r"(?i)\b(kill|murder|shoot(?:\s*up)?|bomb|kidnap|abduct)\b", qn):
        if not benign_toxicology.search(qn):
            return "I am DoctorVIT, and I am here only for health-related questions. I cannot answer any requests outside of healthcare or health plan topics. Please rephrase your question to focus on symptoms, first aid, prevention, medication safety, tests, treatment options, or insurance/benefits so I can help responsibly. If anyone is in immediate danger, contact local emergency services now."

    if 'is_healthcare_question' in globals() and not is_healthcare_question(q):
        return "I am DoctorVIT, and I am here only for health-related questions. I cannot answer any requests outside of healthcare or health plan topics. Please rephrase your question to focus on symptoms, first aid, prevention, medication safety, tests, treatment options, or insurance/benefits so I can help responsibly. If anyone is in immediate danger, contact local emergency services now."

    sp = None
    try:
        sp = _detect_specialty(q, snippet_text)
    except Exception:
        sp = None
    if sp:
        return sp
    return _rephrase_assist_prompt(q)

def _strip_meta_overview_speak(text: str) -> str:
    if not text:
        return text
    META_PATTERNS = [
        r'(?i)\bwrite a (?:concise|brief|short)\b.*\bprofessional overview\b',
        r'(?i)\bhighly professional overview\b',
        r'(?i)\banswer(?:s|ing)? (?:the )?user(?:\'s)? question directly\b',
        r'(?i)\breturn (?:just|only) the corrected text\b',
        r'(?i)\bonly fix grammar\b',
        r'(?i)\bkeep .*? exactly the same\b',
        r'(?i)\bthe original text (?:was|is) already (?:grammatically )?correct\b',
        r'(?i)\bgrammar (?:was|is) already correct\b',
        r'(?i)\bno (?:changes|edits) (?:were|are) needed\b',
        r'(?i)\b(as|you are) (?:an?|the)\s+\w+(?:\s\w+){0,4}\s+(assistant|editor|clinician|doctor|pharmacist|bot)\b',
        r'(?i)\bthis (?:overview|answer|response)\b',
        r'(?i)\bthe (?:overview|answer|response)\b',
        r'(?i)\bit clearly states\b',
        r'(?i)\bit emphasizes\b',
        r'(?i)\boverall,\s*(?:this|the)\s+(?:overview|answer|response)\b',
        r'(?i)\bno steps\b',
        r'(?i)\bplease use proper (?:spelling and grammar|spelling|grammar)\b'
    ]
    meta_re = [re.compile(p) for p in META_PATTERNS]
    parts = re.split(r'(?<=[.!?])\s+|\n+', text.strip())
    kept = []
    for s in parts:
        ss = s.strip()
        if not ss:
            continue
        if any(r.search(ss) for r in meta_re):
            continue
        kept.append(ss)
    sep = '\n' if '\n' in text else ' '
    out = sep.join(kept).strip()
    return out

def clean_output(text: str) -> str:
    if not text:
        return ""
    t = text
    t = re.sub(r"https?://\S+|www\.\S+", "", t)
    t = re.sub(r"<script[\s\S]*?</script>", "", t)
    t = re.sub(r"```.*?```", "", t, flags=re.DOTALL)
    garbage_regex = re.compile(r"(?i)(note:|only in english|all rights reserved|opyright|do not publish|generated.*?ai|assistant.*?opyright)")
    meta_regex = re.compile(r"(?i)\b(sql|database|query|table|column|row|select|insert|update|delete|schema|python|javascript|function|class|script|module|api|sdk|token|prompt|temperature|model|parser|syntax)\b")
    verb_regex = re.compile(r"\b(am|is|are|was|were|be|being|been|have|has|had|do|does|did|can|could|may|might|shall|should|will|would|must|treat|cause|prevent|increase|reduce|check|monitor|take|stop|start|affect|lower|raise|control|measure|diagnose|screen|advise|avoid|drink|eat|exercise)\b", re.I)
    def _is_heading_like(s):
        if not s:
            return False
        w = s.strip()
        if re.search(r"[.?!]$", w):
            return False
        words = w.split()
        if len(words) <= 2:
            return True
        if len(words) <= 8 and w.isupper():
            return True
        cap_ratio = sum(1 for x in words if x[:1].isupper()) / max(1, len(words))
        return len(words) <= 8 and cap_ratio > 0.6
    def _is_keyword_list(s):
        return s.count(",") >= 3 and not verb_regex.search(s or "")
    cleaned_lines, seen = [], set()
    for ln in t.splitlines():
        raw = ln.strip()
        if not raw:
            if cleaned_lines and cleaned_lines[-1] != "":
                cleaned_lines.append("")
            continue
        if garbage_regex.search(raw):
            continue
        if meta_regex.search(raw):
            continue
        if re.match(r"^\s*#{1,6}\s+\S", raw):
            continue
        if _is_heading_like(raw):
            continue
        if _is_keyword_list(raw):
            continue
        if re.search(r"(?i)\b(reader interactions|report a problem|how do i cite|citation|subscribe|sign in)\b", raw):
            continue
        if re.search(r"\b\w+\.(com|org|net|io|edu)\b", raw):
            continue
        if re.search(r"(?i)\b(apa|mla|chicago)\b", raw):
            continue
        if re.search(r"(?i)\b(you have reached your limit|additional views|start over)\b", raw):
            continue
        key = re.sub(r"\W+", "", raw.lower())
        if key in seen:
            continue
        seen.add(key)
        cleaned_lines.append(raw)
    cleaned = "\n".join(cleaned_lines)
    cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)
    cleaned = "\n".join(re.sub(r"[ \t]{2,}", " ", x).strip() for x in cleaned.split("\n"))
    return cleaned.strip()

def _strip_echo(answer: str, query: str) -> str:
    q = (query or "").strip().lower()
    a = (answer or "").lstrip()
    if q and a.lower().startswith(q):
        a = a[len(query):].lstrip(" \n:-")
    a_lines = [ln for ln in a.splitlines() if ln.strip().lower() != q]
    return "\n".join(a_lines).strip()

def _normalize(text):
    text = re.sub(r"\r\n?", "\n", text or "")
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def _html_wrap(answer: str) -> str:
    return f"""
    <div style="white-space: pre-wrap; font-family: Inter, ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto; font-size: 16px; line-height: 1.75; color:#0f172a; max-width: 800px; margin: 8px auto 2px auto; padding: 18px 20px; background: #ffffff; border: 1px solid #e5e7eb; border-radius: 14px;">
    {html.escape(answer)}
    </div>
    """

def _strip_code_blocks(text: str) -> str:
    if not text:
        return text
    text = re.sub(r"<code[\s\S]*?</code>", "", text)
    text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)
    text = re.sub(r"^\s*(import |from |def |class |#\!|#\s|if __name__ == ['\"]__main__['\"]:).*$", "", text, flags=re.MULTILINE)
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    return text

def _looks_like_code_explanation(text: str) -> bool:
    if not text:
        return False
    return bool(re.search(r"(?i)\b(this code|the (?:code|function|script|class)|python|in code|the snippet)\b", text))

def _looks_like_nlp_explanation(text: str) -> bool:
    if not text:
        return False
    return bool(re.search(r"(?i)\b(spacy|auxpass|dependency|pos tag|token(?:ization)?|lemma|parse tree|syntax|fronting|matcher|phrase\s*matcher|pipeline|nlp model|linguistic[s]?)\b", text))

def _repair_med_prompt(query: str, snippet_text: str) -> str:
    return _rephrase_assist_prompt(query)

def _safe_text(raw: str, query: str) -> str:
    if not raw:
        return ""
    raw = _cut_at_end_token(raw)
    txt = _strip_code_blocks(raw)
    txt = _strip_echo(txt, query)
    txt = _normalize(txt)
    return txt.strip() or raw.strip()

_DOSE_PHRASE_RE = re.compile(r"(?i)(?<![A-Za-z])\d+(?:\.\d+)?\s*(?:mcg|µg|mg|g|iu|units?|mL|ml|L)(?:\s*(?:/\s*(?:kg|m²|m2|day|d|dose)))?")
_FREQ_RE = re.compile(r"(?i)\b(q\d+\s*(?:h|hr|hrs)|q\d{1,2}h|once daily|twice daily|every\s+\d+\s*(?:hours?|days?)|(?:od|bd|bid|tid|qid|qhs|qam|qpm)\b)")
_ROUTE_RE = re.compile(r"(?i)\b(po|oral|sublingual|buccal|iv|intravenous|im|intramuscular|sc|subcut(?:aneous)?|topical|transdermal|inhal(?:ation|ed)?|intranasal|nasal|ophthalmic|otic|rectal|pr)\b")
_CONC_RE = re.compile(r"(?i)\b(?:mcg|µg|mg)\s*/\s*(?:mL|L)\b")
_UNDER2_YEARS_RE = re.compile(r"(?i)\b(?:under|less\s*than|younger\s*than|<)\s*2\s*years?\b|\b1\s*(?:year|yr|yo|y/o)\b")
_UNDER2_MONTHS_RE = re.compile(r"(?i)\b(\d{1,2})\s*(?:months?|mos?|mths?|m/o)\b")
_INFANT_TERMS_RE = re.compile(r"(?i)\b(newborn|neonate|infant)\b")
_QUERY_AGE_RE = re.compile(r"(?i)\b(\d{1,2})\s*(?:-?\s*(?:year|yr)\s*old|years?|yrs?|yo|y/o)\b")
_RANGE_YEARS_RE = re.compile(r"(?i)\b(\d{1,2})\s*(?:–|-|—|to)\s*(\d{1,2})\s*(?:years?|yrs?)\b")
_UNDER_OVER_RE = re.compile(r"(?i)\b(under|over)\s*(\d{1,2})\s*(?:years?|yrs?)\b")
_CHILD_CONTEXT_RE = re.compile(r"(?i)\b(child|children|kid|kids|baby|infant|toddler|newborn|neonate)\b")

def _mentions_under2(text: str) -> bool:
    if not text:
        return False
    if _UNDER2_YEARS_RE.search(text) or _INFANT_TERMS_RE.search(text):
        return True
    for m in _UNDER2_MONTHS_RE.findall(text):
        try:
            if int(m) < 24:
                return True
        except ValueError:
            pass
    return False

_AGE_YEARS_RE = re.compile(r'(?i)\b(\d+(?:\.\d+)?)\s*(?:years?|yrs?|y)\b')
_AGE_YEARS_OLD_ONLY_RE = re.compile(r'(?i)\b(\d+(?:\.\d+)?)\s*(?:-?\s*(?:year|yr))\s*-?\s*old\b')
_AGE_YO_RE = re.compile(r'(?i)\b(\d+(?:\.\d+)?)\s*(?:yo|y/o)\b')

_AGE_MONTHS_OLD_RE = re.compile(r'(?i)\b(\d+(?:\.\d+)?)\s*(?:-?\s*(?:months?|mos?|mths?))\s*-?\s*old\b')
_AGE_MONTHS_MO_SLASH_RE = re.compile(r'(?i)\b(\d+(?:\.\d+)?)\s*m/o\b')
_AGE_MONTHS_WITH_AGE_PREFIX_RE = re.compile(r'(?i)\bage\s*(?:is|:)?\s*(\d+(?:\.\d+)?)\s*(?:months?|mos?|mths?)\b')

def _extract_age_months_strict(text: str):
    t = (text or "").lower()
    m = _AGE_MONTHS_OLD_RE.search(t)
    if m:
        try:
            return float(m.group(1).replace(',', '.'))
        except Exception:
            pass
    m = _AGE_MONTHS_MO_SLASH_RE.search(t)
    if m:
        try:
            return float(m.group(1).replace(',', '.'))
        except Exception:
            pass
    m = _AGE_MONTHS_WITH_AGE_PREFIX_RE.search(t)
    if m:
        try:
            return float(m.group(1).replace(',', '.'))
        except Exception:
            pass
    return None

def _is_under_two_from_text(text: str) -> bool:
    t = (text or "").lower()

    m = _AGE_YEARS_RE.search(t) or _AGE_YEARS_OLD_ONLY_RE.search(t) or _AGE_YO_RE.search(t)
    if m:
        try:
            return float(m.group(1).replace(',', '.')) < 5
        except Exception:
            pass

    mm = _extract_age_months_strict(t)
    if mm is not None:
        try:
            return float(mm) < 60.0
        except Exception:
            pass

    return False


def _extract_age_from_query(text: str):
    if not text:
        return None
    m = _QUERY_AGE_RE.search(text)
    if not m:
        return None
    try:
        return int(m.group(1))
    except Exception:
        return None

def _age_ranges_in_sentence(s: str):
    ranges = []
    for a, b in _RANGE_YEARS_RE.findall(s):
        try:
            lo = int(a); hi = int(b)
            if lo <= hi:
                ranges.append(("range", lo, hi))
        except Exception:
            pass
    m = _UNDER_OVER_RE.search(s)
    if m:
        kind = m.group(1).lower()
        try:
            n = int(m.group(2))
            if kind == "under":
                ranges.append(("under", n))
            elif kind == "over":
                ranges.append(("over", n))
        except Exception:
            pass
    singles = []
    for g in _QUERY_AGE_RE.findall(s):
        try:
            singles.append(int(g[0] if isinstance(g, tuple) else g))
        except Exception:
            pass
    return ranges, singles

def _filter_age_mismatch(text: str, query: str) -> str:
    age = _extract_age_from_query(query or "")
    if not age:
        return text
    blocks = re.split(r'(?:\n\s*\n)+', text.strip())
    kept_blocks = []
    for b in blocks:
        sents = re.split(r'(?<=[.!?])\s+', b.strip())
        kept_sents = []
        for s in sents:
            if not s.strip():
                continue
            if not re.search(r'(?i)\b(child|children|kid|kids|aged|age|years?\s*old|yrs?|yo|y/o)\b', s):
                kept_sents.append(s)
                continue
            ranges, singles = _age_ranges_in_sentence(s)
            if not ranges and not singles:
                kept_sents.append(s)
                continue
            ok = False
            for r in ranges:
                if r[0] == "range" and r[1] <= age <= r[2]:
                    ok = True
                if r[0] == "under" and age < r[1]:
                    ok = True
                if r[0] == "over" and age > r[1]:
                    ok = True
            if age in singles:
                ok = True
            if ok:
                kept_sents.append(s)
        kb = " ".join(kept_sents).strip()
        if kb:
            kept_blocks.append(kb)
    return "\n\n".join(kept_blocks).strip() if kept_blocks else text

def dose_verification_filter(text: str) -> str:
    if text is None:
        return ""
    t = text
    patterns = [
        r'(?is)\b(?:dose|dosage)[^.?\n]*?(?:=|:)[^.?\n]*?(?:x|×|\*)[^.?\n]*?(?:/|÷)\s*(?:100|1000)\b[^.?\n]*[.?!]?',
        r'(?is)\b(?:weight|kg)[^.?\n]*?(?:x|×|\*)[^.?\n]*?\b(?:age|years?|yrs?|yo|y/o)\b[^.?\n]*?(?:/|÷)\s*(?:100|1000)\b[^.?\n]*[.?!]?',
        r'(?is)\b(?:age|years?|yrs?|yo|y/o)[^.?\n]*?(?:x|×|\*)[^.?\n]*?\b(?:weight|kg)\b[^.?\n]*?(?:/|÷)\s*(?:100|1000)\b[^.?\n]*[.?!]?',
        r'(?im)^.*for example.*?(?:/|÷)\s*(?:100|1000)\b.*$'
    ]
    for p in patterns:
        t = re.sub(p, '', t)
    t = re.sub(r'\n{3,}', '\n\n', t).strip()
    return t

def _strip_sentence_initial_yes(text: str) -> str:
    if not text:
        return text
    return re.sub(r'(?mi)(^|(?<=[.!?]))\s*(?:yes,\s*|\?+,?\s*)', r'\1', text)

_list_item_re = re.compile(r'^\s*(?:\d+[.)]|[-*•])\s+(.*)$')

def _is_list_block(block: str) -> bool:
    lines = [ln for ln in block.splitlines() if ln.strip()]
    if not lines:
        return False
    return all(_list_item_re.match(ln) for ln in lines)

def _norm_sentence(s: str) -> str:
    s = s.strip()
    s = _list_item_re.sub(r'\1', s)
    s = re.sub(r'^[\'"“”‘’]+|[\'"“”‘’]+$', '', s)
    s = s.rstrip(' .;:!?')
    s = re.sub(r"[^\w\s]", ' ', s)
    s = re.sub(r'\b(the|a|an|any|your|their|his|her|its|our)\b', ' ', s, flags=re.I)
    s = re.sub(r'\s+', ' ', s)
    return s.lower().strip()

def _sentences_from_paragraph(block: str):
    parts = re.split(r'(?<=[.!?])\s+', block.strip())
    return [p for p in parts if p.strip()]

def _items_from_list(block: str):
    items = []
    for ln in block.splitlines():
        if not ln.strip():
            continue
        m = _list_item_re.match(ln)
        items.append((m.group(1) if m else ln).strip())
    return items

try:
    from rapidfuzz import fuzz as _rf_fuzz
except Exception:
    _rf_fuzz = None

def _similarity_ratio(a: str, b: str) -> float:
    if _rf_fuzz:
        try:
            s1 = _rf_fuzz.token_sort_ratio(a, b) / 100.0
            s2 = _rf_fuzz.token_set_ratio(a, b) / 100.0
            s3 = _rf_fuzz.partial_ratio(a, b) / 100.0
            s4 = _rf_fuzz.ratio(a, b) / 100.0
            return max(s1, s2, s3, s4)
        except Exception:
            pass
    return difflib.SequenceMatcher(None, a, b).ratio()

def _dedupe_repeated_content(text: str, sent_threshold: float = 0.88, para_threshold: float = 0.9) -> str:
    if not text:
        return text
    blocks = [b for b in re.split(r'(?:\n\s*\n)+', text.strip()) if b.strip()]
    kept_blocks = []
    seen_sents_norm = []
    for block in blocks:
        if _is_list_block(block):
            items = _items_from_list(block)
            new_items, norm_items = [], []
            for it in items:
                n = _norm_sentence(it)
                if any(_similarity_ratio(n, m) >= sent_threshold for m in norm_items):
                    continue
                if any(_similarity_ratio(n, m) >= sent_threshold for m in seen_sents_norm):
                    continue
                new_items.append(it)
                norm_items.append(n)
                seen_sents_norm.append(n)
            if new_items:
                kept_blocks.append("\n".join(f"{x}" for x in new_items))
            continue
        sents = _sentences_from_paragraph(block)
        new_sents = []
        local_norms = []
        for s in sents:
            n = _norm_sentence(s)
            if any(_similarity_ratio(n, _norm_sentence(prev)) >= sent_threshold for prev in new_sents):
                continue
            if any(_similarity_ratio(n, m) >= sent_threshold for m in seen_sents_norm):
                continue
            new_sents.append(s)
            local_norms.append(n)
        para = " ".join(new_sents).strip()
        if not para:
            continue
        if any(_similarity_ratio(_norm_sentence(para), _norm_sentence(pb)) >= para_threshold for pb in kept_blocks):
            continue
        kept_blocks.append(para)
    if not kept_blocks:
        return text
    return "\n\n".join(kept_blocks).strip()

def _dedupe_lead_title(text: str) -> str:
    import re as _re
    t = (text or "")
    if not t.strip():
        return t

    m = _re.match(
        r"(?is)^\s*(?P<t1>([A-Z][\w'’\-]+(?:\s+[A-Z][\w'’\-]+){2,12}))\s*(?:[:\-–—]\s*)?(?P<t2>(?P=t1))\b",
        t,
    )
    if m:
        return t[m.start('t2'):].lstrip()

    words = list(_re.finditer(r"[A-Za-z0-9'’\-]+", t))
    n = len(words)
    for mlen in range(min(12, n // 2), 3, -1):
        same = True
        for i in range(mlen):
            if words[i].group(0).lower() != words[i + mlen].group(0).lower():
                same = False
                break
        if same:
            cut = words[mlen].start()
            return t[cut:].lstrip(" :–—-")
    return t.lstrip()

_MIX_VERBS = re.compile(r"(?i)\b(mix|mixed|mixing|dilute|diluted|diluting|combine|combined|stir|stirred|stirring|administer(?:ed)?\s+with|take(?:n)?\s+with|give(?:n)?\s+with)\b")
_MILK_JUICE = re.compile(r"(?i)\b(milk|breast\s*milk|formula|fruit\s*juice|juice|orange\s*juice|apple\s*juice|grape\s*juice|grapefruit\s*juice)\b")

def _enforce_no_milk_juice(text: str) -> str:
    if not text:
        return text
    blocks = re.split(r'(?:\n\s*\n)+', text.strip())
    changed = False
    new_blocks = []
    for b in blocks:
        if _is_list_block(b):
            items = _items_from_list(b)
            kept = []
            for it in items:
                s = it.strip()
                if _MIX_VERBS.search(s) and _MILK_JUICE.search(s):
                    changed = True
                    continue
                kept.append(it)
            if kept:
                new_blocks.append("\n".join(f"{x}" for x in kept))
            continue
        sents = _sentences_from_paragraph(b)
        kept_sents = []
        for s in sents:
            if _MIX_VERBS.search(s) and _MILK_JUICE.search(s):
                changed = True
                continue
            kept_sents.append(s)
        if kept_sents:
            new_blocks.append(" ".join(kept_sents))
    out = "\n\n".join(new_blocks).strip()
    if changed and "Safety note: Do not mix medicines with milk or fruit juice." not in out:
        caution = "Safety note: Do not mix medicines with milk or fruit juice. Unless a clinician or the product label explicitly permits it, use plain water for administration."
        out = (caution + "\n\n" + out).strip()
    return out if out else text

def _age_is_two_or_under(text: str) -> bool:
    t = (text or "").lower()
    if re.search(r'\b(under|less\s*than|below)\s*(?:or\s*equal\s*to\s*)?(?:2|two)\s*(?:years?|yrs?)\b', t):
        return True
    if re.search(r'\b(?:≤|<=)\s*2\s*(?:years?|yrs?)\b', t):
        return True
    if re.search(r'\b(?:2|two)[-\s]?(?:year|yr)\s*old\b', t):
        return True
    if re.search(r'\b(?:2|two)\s*(?:yo|y/o|yrs?\s*old|years?\s*old)\b', t):
        return True
    if re.search(r'\bage\s*(?:is|:)?\s*(?:2|two)\b', t):
        return True
    for m in re.findall(r'\b(\d{1,3})\s*months?\b', t):
        try:
            if int(m) <= 24:
                return True
        except ValueError:
            pass
    if re.search(r'\b(neonate|newborn|infant)\b', t):
        return True
    return False

def _maybe_add_under2_caution(text: str, query: str) -> str:
    import re
    q = query or ""
    if not _needs_dose_answer(q):
        return text or ""

    if re.search(r'(?i)\bkids?\b', q):
        return (
            "Caution (<2 years): Dosing and administration should be directed by a clinician. "
            "Use the supplied oral syringe, verify product strength (mg/mL), and avoid self-dosing without professional advice. "
            "It is not advised to administer any medicine to children under 2 years of age unless specifically prescribed and supervised.\n\n"
            "We value health of your child and therefore we do not recommend any medicine for them other than Panadol drops and Panadol Liquid that can be used for mild to moderate pain in babies over one month old.\n\n"
            "Panadol drops: Dose: 10–15 mg/kg per dose every 4–6 hours; Max: 75 mg/kg/day. Use the supplied oral syringe and verify the bottle strength (mg/mL).\n"
            "Panadol suspension: Dose: 10–15 mg/kg per dose every 4–6 hours; Max: 75 mg/kg/day. Check the concentration (e.g., mg/5 mL) to measure the correct volume.\n\n"
            "For other health issues, consult a Pediatrician."
        )

    return text or ""

def _apply_general_safety_overrides(text: str, query: str) -> str:
    t = _enforce_no_milk_juice(text)
    t = _maybe_add_under2_caution(text=t, query=query)
    t = _dedupe_repeated_content(t)
    return t

_LEADIN_RE = re.compile(
    r'^\s*(?:how to|steps? to|procedure for|management of|'
    r'diagnosis of|evaluation of|assessment of|first aid for|care for|'
    r'what to do for|work[-\s]?up (?:of|for)|approach to)\s+',
    flags=re.IGNORECASE
)

def _extract_topic(q: str) -> str:
    topic = _LEADIN_RE.sub('', q or '').strip()
    return topic.rstrip('?.:;,')

_PROC_PAT = re.compile(r"(?i)\b(steps?|procedure|process|how to|first aid|resuscitation|cpr|aed|bls|als|choking|airway|breathing|circulation|bleeding control|wound care|burns?|sprain|strain|immobilization|bandag(?:e|ing)|recovery position|heimlich|abdominal thrusts)\b")

def _is_procedure_process(q: str) -> bool:
    return bool(_PROC_PAT.search(q or ""))

from typing import Optional

def _rephrase_assist_prompt(query: str, snippet_text: Optional[str] = None) -> str:
    q = _pre(query)
    s = _pre(snippet_text or "")

    return (
        f"{s}\n\n"
        "You are a Board-Certified Specialist Clinician. Answer deterministically, directly, and without deferring. "
        "Write ONLY the answer; do NOT repeat or quote the question or any instructions. "
        "Use Title Case section headings that end with a colon. "
        "Write ONE or TWO sections in this order: 'Clinical Specialist Advice:'; include 'Referral Advice:' ONLY when the user presents a clinical case "
        "(symptoms, signs, exam, vitals, or test results) or when referral is otherwise clinically indicated. "
        "Do NOT write 'Referral Advice:' for general informational questions.\n"
        "'Clinical Specialist Advice:' MUST be ONE cohesive paragraph of 10–12 sentences covering: succinct evaluation with differential priorities and key red flags; "
        "initial tests with explicit decision thresholds (name at most 1–3 and explain the purpose); first-line pharmacologic options with typical adult dose/route/frequency "
        "and major contraindications/interactions; and clear escalation/referral triggers. Keep this as prose; no lists.\n"
        "If included, 'Referral Advice:' MUST be ONE cohesive paragraph of 3–5 sentences that: names the most relevant specialist/subspecialist with rationale; "
        "specifies urgency based on the patient’s presentation (routine, expedited within days, or same-day/emergency) using clinical severity/red flags rather than fixed times; "
        "states any pre-referral work-up to complete; and notes explicit escalation triggers. Do NOT use bullets or numbered lists in this section.\n"
        "Use clear, plain medical English and briefly define unavoidable terms. "
        "Provide only a brief treatment overview; detailed clinician-level protocols are out of scope. "
        "Include resuscitation/AED guidance ONLY when clearly indicated by the scenario; otherwise omit. "
        "No bullets, numbered lists, tables, or emojis anywhere. "
        "The final heading MUST be exactly 'Disclaimer:'. End exactly with <<<END>>>."
        f"\n\nQuestion: {q}\nAnswer:"
    )

from typing import Optional

def _dual_rephrase_assist_prompt(query: str, snippet_text: Optional[str] = None) -> str:
    q = _pre(query)
    s = _pre(snippet_text or "")
    return (
        f"{s}\n\n"
        "You are a Board-Certified Specialist Clinician. Answer deterministically, directly, and without deferring. "
        "Write ONLY the answer; do NOT repeat or quote the question or any instructions. "
        "Use Title Case section headings that end with a colon. "
        "Write exactly ONE section: 'Clinical Guidance:'. Do NOT include any 'Referral Advice:' section for any reason.\n"
        "'Clinical Guidance:' MUST be ONE cohesive paragraph of 10–12 sentences covering: succinct evaluation with differential priorities and key red flags; "
        "initial tests with explicit decision thresholds (name at most 1–3 and explain the purpose); first-line pharmacologic options with typical adult dose/route/frequency "
        "and major contraindications/interactions; and clear escalation triggers. Keep this as prose; no lists.\n"
        "Use clear, plain medical English and briefly define unavoidable terms. "
        "Provide only a brief treatment overview; detailed clinician-level protocols are out of scope. "
        "Include resuscitation/AED guidance ONLY when clearly indicated by the scenario; otherwise omit. "
        "No bullets, numbered lists, tables, or emojis anywhere. "
        "End exactly with <<<END>>>."
        f"\n\nQuestion: {q}\nAnswer:"
    )

def _strip_role_artifacts(text: str) -> str:
    if not text:
        return text
    t = text
    t = re.sub(r'(?mi)^\s*question\s*:\s*.*$', '', t)
    t = re.sub(r'(?mi)^\s*q\s*:\s*.*$', '', t)
    t = re.sub(r'(?mi)^\s*answer\s*:\s*', '', t)
    t = re.sub(r'(?mi)^\s*a\s*:\s*', '', t)
    t = re.sub(r'\b(?:a|an)\s*:\s*(?:assistant|user)\b', '', t, flags=re.I)
    t = re.sub(r'(?mi)^\s*(?:assistant|user)\s*:\s*', '', t)
    t = re.sub(r'\s*:\s*(?:assistant|user)\b', '', t, flags=re.I)
    t = re.sub(r'\(\s*(?:assistant|user)\s*\)', '', t, flags=re.I)
    t = re.sub(r'(?mi)^\s*(?:coach|doctor|dr)\s*:\s*.*$', '', t)
    t = re.sub(r'(?mi)^\s*user\s*input\s*:\s*.*$', '', t)
    t = re.sub(r'\s+([,.;:!?])', r'\1', t)
    t = re.sub(r'[ \t]{2,}', ' ', t)
    t = re.sub(r'\n{3,}', '\n\n', t)
    return t.strip()

def _normalize_numbered_steps(text: str) -> str:
    if not text:
        return text
    lines = text.splitlines()
    numbered_re = re.compile(r'^\s*(\d+)[\.)]\s+(.*)$')
    bullet_re = re.compile(r'^\s*[-*•]\s+(.*)$')
    step_colon_re = re.compile(r'^\s*[A-Z][^:\n]{1,120}:\s*.*$')
    out_lines = []
    in_list = False
    n = 1
    for i, ln in enumerate(lines):
        stripped = ln.strip()
        m_num = numbered_re.match(ln)
        m_bul = bullet_re.match(ln)
        if m_num:
            if not in_list:
                in_list = True
                n = 1
            out_lines.append(f"{n}. {m_num.group(2).strip()}")
            n += 1
        elif in_list and m_bul:
            text_part = m_bul.group(1).strip()
            out_lines.append(f"{n}. {text_part}")
            n += 1
        elif in_list and step_colon_re.match(ln):
            out_lines.append(stripped)
        elif stripped == "":
            out_lines.append(ln)
        else:
            out_lines.append(ln)
            in_list = False
    return "\n".join(out_lines).strip()

def _organize_paragraphs(text: str) -> str:
    if not text:
        return text
    lines = text.splitlines()
    merged = []
    for i, ln in enumerate(lines):
        cur = ln.rstrip()
        if merged:
            prev = merged[-1]
            if prev and not re.search(r'[.!?]"?\s*$', prev) and cur and cur[:1].islower():
                merged[-1] = prev.rstrip() + " " + cur.lstrip()
                continue
        merged.append(cur)
    t = "\n".join(merged)
    t = re.sub(r'[ \t]+\n', '\n', t)
    t = re.sub(r'\n{3,}', '\n\n', t)
    blocks = [b.strip() for b in re.split(r'(?:\n\s*\n)+', t.strip()) if b.strip()]
    normalized = []
    for b in blocks:
        b = re.sub(r'\s{2,}', ' ', b)
        normalized.append(b.strip())
    return "\n\n".join(normalized).strip()

def _strip_inline_enumerators(text: str) -> str:
    if not text:
        return text
    enum_token = re.compile(r'(?:(?<=\s)|^)\(?\d{1,2}[\.)](?=\s)')
    paras = re.split(r'(?:\n\s*\n)+', text.strip())
    cleaned = []
    for p in paras:
        if _is_list_block(p):
            cleaned.append(p)
            continue
        q = enum_token.sub('', p)
        q = re.sub(r'\s{2,}', ' ', q).strip()
        cleaned.append(q)
    return "\n\n".join(cleaned).strip()

try:
    from rapidfuzz import process as _rf_process, fuzz as _rf_fuzz2
except Exception:
    _rf_process, _rf_fuzz2 = None, None

try:
    from wordfreq import top_n_list as _wf_top_n, zipf_frequency as _wf_zipf
except Exception:
    _wf_top_n, _wf_zipf = None, None

_TRUSTED_VOCAB = None
_word_re = re.compile(r"[A-Za-z][A-Za-z'-]*")
_WEIGHT_RE_KG = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*kg\b")
_WEIGHT_RE_LB = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:lb|lbs|pounds?)\b")

def _ensure_vocab():
    global _TRUSTED_VOCAB
    if _TRUSTED_VOCAB is not None:
        return
    vocab = set()
    if _wf_top_n:
        try:
            for w in _wf_top_n("en", n_top=200000, wordlist="large"):
                if w and w.isalpha():
                    vocab.add(w.lower())
        except Exception:
            pass
    _TRUSTED_VOCAB = vocab

def _zipf(word):
    try:
        if _wf_zipf:
            return _wf_zipf(word, "en")
    except Exception:
        pass
    return 0.0

_SYMPTOM_TERMS = (
    "pain", "tenderness", "swelling", "soreness",
    "numbness", "tingling", "weakness", "redness", "itching", "burning", "cramps"
)
_BODY_WORD = r"(?:chest|head|neck|back|abdomen|abdominal|stomach|belly|throat|ear|eye|shoulder|arm|elbow|wrist|hand|finger|hip|knee|leg|ankle|foot|toe)"

def _fix_bodypart_noun_confusions(text: str) -> str:
    if not text:
        return text
    pat = re.compile(fr"(?i)\b({_BODY_WORD})\s+(patient|patients)\b")
    def repl(m):
        part = m.group(1)
        best, best_sc = "pain", _zipf(f"{part.lower()} pain")
        for term in _SYMPTOM_TERMS:
            sc = _zipf(f"{part.lower()} {term}")
            if sc > best_sc:
                best, best_sc = term, sc
        return f"{part} {best}"
    return pat.sub(repl, text)

_ACRO_REV_RE = re.compile(r'(?i)\b([A-Za-z][A-Za-z-]+(?:\s+[A-Za-z][A-Za-z-]+){0,7})\s*\(\s*([A-Z]{2,6})\s*\)')
_ACRO_FWD_RE = re.compile(r'\b([A-Z]{2,6})\s*\(\s*([^)]+?)\s*\)')

def _norm_space(s: str) -> str:
    return re.sub(r'\s+', ' ', (s or '').strip())

def _build_acronym_map_from_corpus(results, min_count: int = 2):
    texts = _corpus_texts(results)
    counts = defaultdict(lambda: defaultdict(int))
    for t in texts:
        for m in _ACRO_FWD_RE.finditer(t):
            acro = m.group(1).upper()
            exp  = _norm_space(m.group(2).lower())
            if 3 <= len(exp) <= 80:
                counts[acro][exp] += 1
        for m in _ACRO_REV_RE.finditer(t):
            exp  = _norm_space(m.group(1).lower())
            acro = m.group(2).upper()
            if 3 <= len(exp) <= 80:
                counts[acro][exp] += 1
    acro_map = {}
    for acro, bag in counts.items():
        exp, n = max(bag.items(), key=lambda kv: kv[1])
        if n >= min_count:
            acro_map[acro] = exp
    return acro_map

def _normalize_acronyms_in_text(text: str, acro_map: dict) -> str:
    if not text or not acro_map:
        return text
    def fix_rev(m):
        exp, acro = m.group(1), m.group(2).upper()
        canon = acro_map.get(acro)
        if not canon:
            return m.group(0)
        return f"{_case_like(exp, canon)} ({acro})"
    def fix_fwd(m):
        acro, exp = m.group(1).upper(), m.group(2)
        canon = acro_map.get(acro)
        if not canon:
            return m.group(0)
        return f"{acro} ({_case_like(exp, canon)})"
    text = _ACRO_REV_RE.sub(fix_rev, text)
    text = _ACRO_FWD_RE.sub(fix_fwd, text)
    return text

def _fix_medical_confusables_general(text: str) -> str:
    if not text:
        return text
    text = re.sub(r'(?i)\bmac\s*\(\s*maximum alveolar concentration\s*\)', 'MAC (minimum alveolar concentration)', text)
    text = re.sub(r'(?i)\bmaximum alveolar concentration\b(?=[^.)]*\bMAC\b)', 'minimum alveolar concentration', text)
    return text

_SEEDED_ACRO = {
    "MAC": "minimum alveolar concentration",
    "GCS": "glasgow coma scale",
    "COPD": "chronic obstructive pulmonary disease",
    "ARDS": "acute respiratory distress syndrome",
    "DVT": "deep vein thrombosis",
    "PE": "pulmonary embolism",
    "ABC": "airway, breathing and circulation"
}

def _merge_acro_maps(seed: dict, learned: dict) -> dict:
    m = dict(seed)
    m.update(learned or {})
    return m

def _case_like(src, repl):
    if src.isupper():
        return repl.upper()
    if src[:1].isupper():
        return repl.capitalize()
    return repl

def _similarity(a, b):
    if _rf_fuzz2:
        return float(_rf_fuzz2.ratio(a, b))
    return difflib.SequenceMatcher(None, a, b).ratio() * 100.0

def _candidate_set(lw):
    _ensure_vocab()
    L = len(lw)
    cands = [w for w in _TRUSTED_VOCAB if w and w[0] == lw[0] and abs(len(w) - L) <= 2]
    if not cands:
        cands = [w for w in _TRUSTED_VOCAB if abs(len(w) - L) <= 2]
    return cands[:5000]

def _threshold_for(lw):
    L = len(lw)
    if L >= 8:
        return 66.0
    if L >= 6:
        return 68.0
    if L >= 4:
        return 72.0
    return 76.0

def _score_with_conf(lw, cand):
    s = _similarity(lw, cand)
    boost = max(0.0, _zipf(cand) - _zipf(lw)) * 4.0
    return s + boost

def _correct_token(tok):
    if not tok or not _word_re.fullmatch(tok):
        return tok
    lw = tok.lower()
    _ensure_vocab()
    if lw in _TRUSTED_VOCAB:
        return tok
    cands = _candidate_set(lw)
    if not cands:
        return tok
    best, best_conf = None, -1.0
    for c in cands:
        sc = _score_with_conf(lw, c)
        if sc > best_conf:
            best, best_conf = c, sc
    thr = _threshold_for(lw)
    if best and best_conf >= thr:
        return _case_like(tok, best)
    return tok

def _autocorrect_text(text):
    if not text:
        return text
    out, i = [], 0
    for m in _word_re.finditer(text):
        s, e = m.span()
        if s > i:
            out.append(text[i:s])
        token = text[s:e]
        if "-" in token and token.count("-") == 1:
            a, b = token.split("-")
            token = _correct_token(a) + "-" + _correct_token(b)
        else:
            token = _correct_token(token)
        out.append(token)
        i = e
    out.append(text[i:])
    return "".join(out)

def _wants_example(q: str) -> bool:
    if not q:
        return False
    return bool(re.search(r"(?i)\b(example|e\.g\.|for instance|sample calculation|worked example|with example|show.*example|give.*example)\b", q))

def _extract_dose_sentences(text: str):
    if not text:
        return []
    sents = re.split(r'(?<=[.!?])\s+', text)
    hits = []
    for s in sents:
        if re.search(r'(?i)\b(mg|mcg|µg|mg/kg|mcg/kg|units|iu)\b', s) and re.search(r'\d', s):
            hits.append(s.strip())
    return hits[:5]

def _parse_mg_per_kg(sentence: str):
    if not sentence:
        return None
    m = re.search(r'(?i)(\d+(?:\.\d+)?)\s*(?:–|-|to)\s*(\d+(?:\.\d+)?)\s*mg\s*/\s*kg', sentence)
    if m:
        try:
            lo = float(m.group(1)); hi = float(m.group(2))
            return (lo+hi)/2.0
        except Exception:
            pass
    m2 = re.search(r'(?i)(\d+(?:\.\d+)?)\s*mg\s*/\s*kg', sentence)
    if m2:
        try:
            return float(m2.group(1))
        except Exception:
            pass
    return None

def _build_example_line_from_page_text(page_text: str) -> str:
    dose_sents = _extract_dose_sentences(page_text)
    mgkg = None
    for s in dose_sents:
        mgkg = _parse_mg_per_kg(s)
        if mgkg is not None:
            break
    if mgkg is None:
        return ""
    if not (0.1 <= mgkg <= 15.0):
        return ""
    total = round(mgkg * 70, 1)
    return f"For a 70-kg adult at {mgkg:g} mg/kg, the calculated dose is {total:g} mg."

def _page_text_from_url(url):
    try:
        headers = {"User-Agent":"Mozilla/5.0"}
        rr = requests.get(url, headers=headers, timeout=15)
        if rr.status_code != 200:
            return ""
        soup = BeautifulSoup(rr.text, "lxml")
        for s in soup(["script","style","noscript","header","footer","nav"]):
            s.extract()
        return " ".join(soup.get_text("\n").split())
    except Exception:
        return ""

def _med_vocab_from_text(t):
    words = [w.lower() for w in _word_re.findall(t or "")]
    counts = {}
    for w in words:
        if len(w) >= 5:
            counts[w] = counts.get(w, 0) + 1
    base = {w for w,c in counts.items() if c >= 2}
    drug_like = {w for w in words if len(w) >= 5 and _HC_DRUG_SUFFIX_RE.search(w)}
    dose_near = {m.group(1).lower() for m in re.finditer(r"([A-Za-z][A-Za-z'-]{4,})\s+\d+(?:\.\d+)?\s*(?:mcg|µg|mg|g|iu|units?)\b", t or "", re.I)}
    return base | drug_like | dose_near

def _build_med_vocab(results, cap=5):
    vocab = set()
    for r in results:
        vocab |= _med_vocab_from_text((r.get("title","") or "") + " " + (r.get("body","") or ""))
    n = 0
    for r in results:
        u = r.get("url","")
        if not _is_credible(u):
            continue
        txt = _page_text_from_url(u)
        if not txt:
            continue
        vocab |= _med_vocab_from_text(txt)
        n += 1
        if n >= cap:
            break
    _ensure_vocab()
    return vocab

def _best_med_cand(lw, candidates):
    L = len(lw)
    pool = [w for w in candidates if w and w[0] == lw[0] and abs(len(w) - L) <= 3]
    if not pool:
        return None
    best, bsc = None, -1.0
    for c in pool:
        sc = _similarity(lw, c)
        if sc > bsc:
            best, bsc = c, sc
    thr = 64.0 if L >= 8 else 68.0
    if bsc >= thr:
        return best
    return None

def _spellfix_med_terms_in_answer(text: str, med_vocab):
    if not text:
        return text
    _ensure_vocab()
    base_known = _TRUSTED_VOCAB or set()
    out, i = [], 0
    for m in _word_re.finditer(text):
        s, e = m.span()
        if s > i:
            out.append(text[i:s])
        tok = text[s:e]
        lw = tok.lower()
        if lw not in base_known:
            cand = _best_med_cand(lw, med_vocab if med_vocab else base_known)
            if cand:
                tok = _case_like(tok, cand)
        out.append(tok)
        i = e
    out.append(text[i:])
    return "".join(out)

def _contextual_collocation_fix(text: str) -> str:
    if not text:
        return text
    pat = re.compile(r'(?i)\b([A-Za-z][A-Za-z\'-]*)\s+(or|and)\s+([A-Za-z][A-Za-z\'-]*)\b')
    def repl(m):
        a, conj, b = m.group(1), m.group(2), m.group(3)
        base = _zipf(f"{a.lower()} {conj.lower()} {b.lower()}")
        lw = b.lower()
        cands = _candidate_set(lw)
        if not cands:
            return m.group(0)
        ranked = sorted(cands, key=lambda c: -_score_with_conf(lw, c))[:8]
        best_word, best_score = b, base
        for c in ranked:
            s = _zipf(f"{a.lower()} {conj.lower()} {c}")
            if s > best_score + 0.8:
                best_word, best_score = c, s
        if best_word != b:
            return f"{a} {conj} {_case_like(b, best_word)}"
        return m.group(0)
    return pat.sub(repl, text)

def _collapse_redundant_phrases(text: str) -> str:
    if not text:
        return text
    t = re.sub(r'(?i)\b(symptoms?)\s+of\s+\1\s+of\b', r'\1 of', text)
    t = re.sub(r'(?i)\b(signs?)\s+of\s+\1\s+of\b', r'\1 of', t)
    t = re.sub(r'(?i)\b(diagnosis|treatment|management)\s+of\s+\1\s+of\b', r'\1 of', t)
    t = re.sub(r'(?i)\b(\w+)(?:\s*,\s*\1\b)+', r'\1', t)
    return t

def _apply_final_polish(text: str) -> str:
    t = _collapse_redundant_phrases(text)
    t = _contextual_collocation_fix(t)
    t = _dedupe_repeated_content(t)
    t = _dedupe_lead_title(t)
    t = re.sub(r'(\n\s*){3,}', r'\n\n', t).strip()
    return t

def _enumerations_to_bullets(text: str) -> str:
    if not text:
        return text
    enum_pat = re.compile(r'(?<!\w)(\d{1,2})[.)]\s+')
    blocks = re.split(r'(?:\n\s*\n)+', text.strip())
    def should_bullet(s: str) -> bool:
        return ":" not in s
    new_blocks = []
    for b in blocks:
        if _is_list_block(b):
            items = _items_from_list(b)
            lines = [f"• {it.strip()}" if should_bullet(it) else it.strip() for it in items if it.strip()]
            new_blocks.append("\n".join(lines))
            continue
        if len(list(enum_pat.finditer(b))) >= 2:
            parts = []
            last_end = None
            first = True
            for m in enum_pat.finditer(b):
                if first:
                    last_end = m.end(); first = False
                else:
                    seg = b[last_end:m.start()]
                    parts.append(seg.strip(" \t;:-"))
                    last_end = m.end()
            tail = b[last_end:] if last_end is not None else ""
            if tail:
                parts.append(tail.strip(" \t;:-"))
            lines = [f"• {p}" if should_bullet(p) else p for p in parts if p]
            new_blocks.append("\n".join(lines) if lines else b)
            continue
        lines = []
        for ln in b.splitlines():
            m = _list_item_re.match(ln)
            if m:
                content = m.group(1).strip()
                lines.append(f"• {content}" if should_bullet(content) else content)
            else:
                lines.append(ln)
        new_blocks.append("\n".join(lines))
    return "\n\n".join(new_blocks).strip()

def _needs_dose_answer(q: str) -> bool:
    if not q:
        return False
    return bool(re.search(r'(?i)\b(dose|dosage|how much|mg/kg|milligram|tablet|syrup)\b', q))

def _cut_at_end_token(text: str) -> str:
    if "<<<END>>>" in text:
        return text.split("<<<END>>>")[0].strip()
    return text

def _ensure_professional_overview(ans: str, q: str) -> str:
    lines = [ln for ln in (ans or "").splitlines() if ln.strip()]
    if lines and lines[0].lstrip().startswith("•"):
        topic = re.sub(r'^\s*(how to|steps? to|procedure for|management of)\s+', '', q or '', flags=re.I).strip().rstrip('?.')
        if re.search(r'(?i)\b(cpr|resuscitation|cardiac arrest|aed|bls)\b', q or ''):
            overview = "Cardiopulmonary resuscitation for an unresponsive person with no normal breathing prioritizes scene safety, rapid activation of emergency services, high-quality chest compressions, rescue breaths if trained, and early defibrillation with an AED."
        else:
            overview = f"This outlines the standard procedure for {topic if topic else 'the requested task'}, presented in concise sequence."
        return overview.strip() + "\n\n" + ans
    return ans

def _build_factual_example(query: str) -> str:
    queries = [
        query + " example",
        query + " dosing example",
        query + " mg/kg example",
        query + " site:nhs.uk",
        query + " site:fda.gov",
        query + " site:who.int",
        query + " site:nice.org.uk",
        query + " site:merckmanuals.com"
    ]
    for q in queries:
        res = duckduckgo_search(q)
        cred = [r for r in res if _is_credible(r.get("url",""))]
        pool = cred if cred else res
        for r in pool:
            url = r.get("url","")
            if not url:
                continue
            try:
                headers = {"User-Agent":"Mozilla/5.0"}
                rr = requests.get(url, headers=headers, timeout=20)
                if rr.status_code != 200:
                    continue
                soup = BeautifulSoup(rr.text, "lxml")
                for s in soup(["script","style","noscript","header","footer","nav"]):
                    s.extract()
                page_text = " ".join(soup.get_text("\n").split())
                line = _build_example_line_from_page_text(page_text)
                if line:
                    return line
            except Exception:
                continue
    return ""

_WEIGHT_RE_KG = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*kg\b")
_WEIGHT_RE_LB = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:lb|lbs|pounds?)\b")
_QH_RE = re.compile(r"(?i)\bq\s*(\d{1,2})\s*(?:h|hr|hrs)\b")
_EVERY_H_RE = re.compile(r"(?i)\bevery\s+(\d{1,2})\s*(?:hours?|hrs?)\b")
_HR_RANGE_RE = re.compile(r"(?i)\b(\d{1,2})\s*[-–—]\s*(\d{1,2})\s*(?:hours?|hrs?)\b")
_MAX_DOSES_RE = re.compile(r"(?i)\bmax(?:imum)?\s*(?:of\s*)?(\d{1,2})\s*(?:doses?|times?)\s*(?:in|per)\s*24\s*hours?\b")
_MGKG_DAY_RE = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:[-–—]\s*(\d+(?:\.\d+)?))?\s*mg\s*/\s*kg\s*/\s*(?:day|24\s*hours?)\b")
_MGKG_DOSE_RE = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:[-–—]\s*(\d+(?:\.\d+)?))?\s*mg\s*/\s*kg(?!\s*/\s*day)\b")
_MG_PER_DOSE_RE = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:[-–—]\s*(\d+(?:\.\d+)?))?\s*mg\s*(?:per\s*(?:dose|dosing|administration)|each\s*dose)\b")
_MG_PER_DAY_RE = re.compile(r"(?i)\b(\d+(?:\.\d+)?)\s*(?:[-–—]\s*(\d+(?:\.\d+)?))?\s*mg\s*/\s*(?:day|24\s*hours?)\b")

def _detect_drug_from_query(q, med_vocab):
    best, best_sc = None, -1.0
    for tok in _word_re.findall(q or ""):
        lw = tok.lower()
        cand = _best_med_cand(lw, med_vocab or set())
        if cand:
            sc = _similarity(lw, cand)
            if sc > best_sc:
                best, best_sc = cand, sc
    return best

def _convert_months_over_12_to_years(text: str) -> str:
    def repl(m):
        val = float(m.group(1))
        if val > 12:
            years = val / 12.0
            y = f"{years:.2f}".rstrip('0').rstrip('.')
            return f"{y} years"
        return m.group(0)
    return re.sub(r'(?i)\b(\d+(?:\.\d+)?)\s*(?:months?|mos?|mths?|m/o)\b', repl, text)

def _intent_key(q, med_vocab):
    if not _needs_dose_answer(q or ""):
        return None
    t = (q or "")
    text = t.lower()
    drug = (_detect_drug_from_query(t, med_vocab) or "").strip().lower()
    age_years = None
    cmp_sig = "eq"
    m = re.search(r'(\d+(?:\.\d+)?)\s*(months?|mos?)\b', text)
    if m:
        age_months = float(m.group(1))
        age_years = round(age_months / 12.0, 2)
    else:
        m = (re.search(r'(\d+(?:\.\d+)?)\s*(years?|yrs?|yo|y/o)\b', text)
             or re.search(r'(\d+(?:\.\d+)?)\s*[- ]?year[- ]?old\b', text))
        if m:
            age_years = round(float(m.group(1)), 2)
        elif (re.search(r'\b(under|less\s*than|below)\s*(?:or\s*equal\s*to\s*)?(?:2|two)\s*(?:years?|yrs?)\b', text)
              or re.search(r'(?:≤|<=)\s*2\s*(?:years?|yrs?)\b', text)
              or re.search(r'(?:≤|<=)\s*24\s*months?\b', text)):
            age_years = 2.0
            cmp_sig = "le"
        else:
            m = re.search(r'\b(under|less\s*than|below)\s*(\d{1,3})\s*months?\b', text)
            if m:
                age_years = round(float(m.group(2)) / 12.0, 2)
                cmp_sig = "lt"
    kg = _WEIGHT_RE_KG.search(t)
    lb = _WEIGHT_RE_LB.search(t) if not kg else None
    if kg:
        w = f"wkg={kg.group(1)}"
    elif lb:
        w = f"wlb={lb.group(1)}"
    else:
        w = "w=?"
    age_sig = f"yr={age_years}" if age_years is not None else "yr=?"
    return f"dose|{drug}|age:{age_sig}|cmp:{cmp_sig}|{w}".lower()

def _round_step(x, step=0.5):
    try:
        return round(round(float(x)/step)*step, 2)
    except Exception:
        return x

def _parse_doses_per_day(text: str):
    max_doses = None
    mmax = _MAX_DOSES_RE.search(text or "")
    if mmax:
        try:
            max_doses = int(mmax.group(1))
        except Exception:
            pass
    qh = _QH_RE.search(text or "")
    if qh:
        try:
            n = int(qh.group(1))
            if n > 0:
                est = max(1, min(12, int(round(24/n))))
                return est, max_doses or est
        except Exception:
            pass
    every = _EVERY_H_RE.search(text or "")
    if every:
        try:
            n = int(every.group(1))
            if n > 0:
                est = max(1, min(12, int(round(24/n))))
                return est, max_doses or est
        except Exception:
            pass
    rg = _HR_RANGE_RE.search(text or "")
    if rg:
        try:
            a = int(rg.group(1)); b = int(rg.group(2))
            lo = min(a,b); hi = max(a,b)
            mid = (lo+hi)/2.0
            est = max(1, min(12, int(round(24/mid))))
            if max_doses:
                return est, max_doses
            return est, max(est, int(24/lo))
        except Exception:
            pass
    if max_doses:
        return max_doses, max_doses
    return None, None

def _pick_hours_from_text(text: str, doses_per_day: int):
    m = _QH_RE.search(text or "")
    if m:
        try:
            n = int(m.group(1))
            if n>0:
                return n
        except Exception:
            pass
    m2 = _EVERY_H_RE.search(text or "")
    if m2:
        try:
            n = int(m2.group(1))
            if n>0:
                return n
        except Exception:
            pass
    m3 = _HR_RANGE_RE.search(text or "")
    if m3:
        try:
            a = int(m3.group(1)); b = int(m3.group(2))
            return int(round((a+b)/2.0))
        except Exception:
            pass
    if doses_per_day:
        try:
            return int(round(24/float(doses_per_day)))
        except Exception:
            return None
    return None

def _avg_pair(g1, g2):
    if g1 and g2:
        try:
            return (float(g1)+float(g2))/2.0
        except Exception:
            return None
    try:
        return float(g1 or g2) if (g1 or g2) else None
    except Exception:
        return None

def _extract_first_avg(pattern, text):
    m = pattern.search(text or "")
    if not m:
        return None
    return _avg_pair(m.group(1), m.group(2))

def _corpus_texts(results, cap=5):
    texts = []
    for r in results:
        t = (r.get("title","") or "") + " " + (r.get("body","") or "")
        if t.strip():
            texts.append(t)
    n = 0
    for r in results:
        u = r.get("url","")
        if not _is_credible(u):
            continue
        pt = _page_text_from_url(u)
        if pt:
            texts.append(pt)
            n += 1
            if n >= cap:
                break
    return texts

def _extract_phrases_from_text(t, n_min=2, n_max=4):
    words = [w.lower() for w in _word_re.findall(t or "")]
    phrases = []
    for n in range(n_min, n_max+1):
        for i in range(0, max(0, len(words)-n+1)):
            chunk = words[i:i+n]
            if not any(len(x) >= 5 for x in chunk):
                continue
            phrases.append(" ".join(chunk))
    return phrases

def _build_med_phrase_set(results):
    texts = _corpus_texts(results)
    counts = defaultdict(int)
    for tx in texts:
        for ph in _extract_phrases_from_text(tx, 2, 4):
            counts[ph] += 1
    keep = {p for p,c in counts.items() if c >= 2 and len(p) >= 9}
    return keep

def _index_phrases_by_first(phrases):
    idx = defaultdict(list)
    for p in phrases:
        toks = [w for w in p.split() if w]
        if not toks:
            continue
        key = toks[0].lower()
        if len(toks) >= 2:
            key = key + " " + toks[1].lower()
        idx[key].append(p)
    return idx

def _best_phrase_match(candidate, idx):
    toks = [w for w in candidate.split() if w]
    if not toks:
        return None, -1.0
    key = toks[0].lower()
    if len(toks) >= 2:
        key = key + " " + toks[1].lower()
    pool = idx.get(key, [])
    best, best_sc = None, -1.0
    for ph in pool:
        if len(ph.split()) != len(toks):
            continue
        if _rf_fuzz2:
            sc = _rf_fuzz2.token_set_ratio(candidate, ph)
        else:
            sc = int(_similarity_ratio(candidate, ph) * 100)
        if sc > best_sc:
            best, best_sc = ph, sc
    return best, best_sc

def _correct_phrases_with_corpus(text, phrase_set):
    if not text or not phrase_set:
        return text
    idx = _index_phrases_by_first(phrase_set)
    cands = list(set(_extract_phrases_from_text(text, 2, 4)))
    cands.sort(key=lambda s: -len(s))
    replaced = {}
    for cand in cands:
        if cand in phrase_set:
            continue
        match, score = _best_phrase_match(cand, idx)
        if match and score >= 88 and match != cand:
            replaced[cand] = match
    if not replaced:
        return text
    tokens = list(_word_re.finditer(text))
    if not tokens:
        return text
    low_words = [m.group(0).lower() for m in tokens]
    positions = [(m.start(), m.end()) for m in tokens]
    to_replace = []
    for cand, repl in replaced.items():
        n = len(cand.split())
        for i0 in range(0, len(low_words) - n + 1):
            seg = " ".join(low_words[i0:i0 + n])
            if seg == cand:
                s = positions[i0][0]
                e = positions[i0 + n - 1][1]
                to_replace.append((s, e, repl))
    if not to_replace:
        return text
    out = []
    cur = 0
    for s, e, repl in sorted(to_replace):
        out.append(text[cur:s])
        out.append(repl)
        cur = e
    out.append(text[cur:])
    return "".join(out)

_PREPOSITIONS = {"during","before","after","while","within","without","between","among","under","over","by","with","at","in","on","into","onto","from","through","toward","towards","upon","inside","outside","beneath","above","below","near","beside","around","beyond","against","until","since","past","per","via"}

_SEED_COLLOCATIONS = [
    ("eat","drink"),
    ("food","drink"),
    ("food","fluids"),
    ("fluids","water"),
    ("nausea","vomiting"),
    ("signs","symptoms"),
    ("risks","benefits"),
    ("benefits","risks"),
    ("fever","chills"),
    ("sprains","strains"),
    ("sprain","strain"),
    ("swelling","redness"),
    ("redness","swelling"),
    ("indications","contraindications"),
    ("contraindications","precautions"),
    ("ice","heat")
]

def _learn_collocations_from_corpus(results, min_count: int = 2, max_partners: int = 4):
    texts = _corpus_texts(results)
    pair_counts = defaultdict(lambda: defaultdict(int))
    pat = re.compile(r'(?i)\b([A-Za-z][A-Za-z\'-]{2,})\s+(and|or)\s+([A-Za-z][A-Za-z\'-]{2,})\b')
    for t in texts:
        for m in pat.finditer(t):
            a = m.group(1).lower()
            b = m.group(3).lower()
            pair_counts[a][b] += 1
            pair_counts[b][a] += 1
    learned = {}
    for a, bag in pair_counts.items():
        partners = [p for p, c in sorted(bag.items(), key=lambda kv: -kv[1]) if c >= min_count][:max_partners]
        if partners:
            learned[a] = set(partners)
    return learned

def _build_colloc_partner_map(seed_pairs, learned_map):
    partners = defaultdict(set)
    for a, b in seed_pairs:
        partners[a].add(b)
        partners[b].add(a)
    for a, bs in (learned_map or {}).items():
        for b in bs:
            partners[a].add(b)
    return {k: set(v) for k, v in partners.items()}

def _fix_coordination_collocations(text: str, colloc_partners: dict) -> str:
    if not text:
        return text
    if not colloc_partners:
        return text
    pat = re.compile(r'(?i)\b([A-Za-z][A-Za-z\'-]{2,})\s+(and|or)\s+([A-Za-z][A-Za-z\'-]{2,})\b')
    def choose(anchor_word, partner_word, orig_partner):
        a = anchor_word.lower()
        y = partner_word.lower()
        allowed = colloc_partners.get(a)
        if not allowed or y in allowed:
            return orig_partner
        best, best_sc = None, -1.0
        for cand in allowed:
            sc = _similarity(y, cand)
            if sc > best_sc:
                best, best_sc = cand, sc
        if y in _PREPOSITIONS and "drink" in allowed:
            return _case_like(orig_partner, "drink")
        if best and best_sc >= 74.0:
            return _case_like(orig_partner, best)
        return orig_partner
    def repl(m):
        anchor, conj, partner = m.group(1), m.group(2), m.group(3)
        fixed_partner = choose(anchor, partner, partner)
        if fixed_partner == partner:
            return m.group(0)
        return f"{anchor} {conj} {fixed_partner}"
    return pat.sub(repl, text)

_NUM_UNIT_RE = re.compile(r'(?i)\b\d+(?:\.\d+)?\s*(?:mg|mcg|µg|g|iu|units?|mL|ml|L|mg/kg|mcg/kg|bpm|mmHg|%|°C|°F)\b')

def _extract_num_units(text: str):
    from collections import Counter
    return Counter(_NUM_UNIT_RE.findall(text or ""))

def _capitalize_sentence_starts(text: str) -> str:
    if not text:
        return text
    def repl(m):
        return f"{m.group(1)}{m.group(2)}{m.group(3).upper()}"
    return re.sub(r'(^|\n|(?<=[.?!]))(\s*)([a-z])', repl, text)

_GRAMMAR_META_RE = re.compile(
    r"(?i)\b("
    r"the\s+(?:original\s+)?text\s+was\s+already\s+(?:grammatically\s+)?correct"
    r"|grammar\s+(?:is|was)\s+already\s+correct"
    r"|no\s+changes\s+were\s+needed"
    r"|no\s+edits?\s+required"
    r"|the\s+sentence[s]?\s+(?:is|are)\s+fine\s+as\s+is"
    r"|the\s+text\s+is\s+clear\s+and\s+correct"
    r")\b"
)

def _strip_grammar_meta_comments(text: str) -> str:
    if not text:
        return text
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    kept = [s for s in sentences if not _GRAMMAR_META_RE.search(s)]
    return " ".join(kept).strip()

def _fix_unmatched_parentheses_general(text: str) -> str:
    if not text:
        return text
    t = text
    t = re.sub(r'\(([^()]*)\s*([.!?])(?!\))', r'(\1)\2', t)
    t = re.sub(r'\(([^()]*)$', r'(\1)', t, flags=re.M)
    opens = t.count('('); closes = t.count(')')
    if opens > closes:
        t = t + (')' * (opens - closes))
    return t

def _smart_sentence_case(text: str) -> str:
    if not text:
        return text
    pat = re.compile(r'(^|(?<=[.!?]\s))([\'"“”(\[]*\s*)([a-z])')
    return pat.sub(lambda m: f"{m.group(1)}{m.group(2)}{m.group(3).upper()}", text)

def _preserve_acronyms_case(text: str) -> str:
    if not text:
        return text
    t = text
    t = re.sub(r'(?i)\bmmhg\b', 'mmHg', t)
    for ac in ["CPR","AED","ECG","EKG","CT","MRI","ICU","ED","BPH","PDE5","BP","HR","RR","SpO2","O2"]:
        t = re.sub(rf'(?i)\b{ac}\b', ac, t)
    return t

def _drop_the_before_mass_nouns(text: str) -> str:
    if not text:
        return text
    mass = r'(aspirin|paracetamol|acetaminophen|ibuprofen|naproxen|nitroglycerin|insulin|oxygen|water|glucose|caffeine|morphine|adrenaline|epinephrine)'
    blockers = r'(tablet|tablets|capsule|capsules|dose|doses|solution|spray|patch|sublingual|tab|cap)'
    return re.sub(rf'(?i)\bthe\s+{mass}\b(?!\s+{blockers})', lambda m: m.group(0)[4:], text)

def _one_off_grammar_sanitize(text: str) -> str:
    if not text:
        return text
    import re
    t = text

    t = re.sub(r'(?im)^\s*no\s+steps,?\s*please\.?\s*', ' ', t)
    t = re.sub(r'(?is)^(?:\s*["“”\'’]*)?(?:write|provide)\s+a\s+concise[^.!\n]*[.!?]\s*', ' ', t)
    t = re.sub(r'(?i)\bforor\b', 'or', t)
    t = re.sub(r'(?i)\bandand\b', 'and', t)
    t = re.sub(r'(?i)\bthethe\b', 'the', t)
    t = re.sub(r'(?i)\bofof\b', 'of', t)
    t = re.sub(r'\b([A-Za-z]+)(?:\s+\1\b)+', r'\1', t, flags=re.I)

    t = re.sub(r'(?<=\d)\.\)\s*(?=\d)', '.', t)
    t = re.sub(r'(?<=\d)\)\.(?=\d)', '.', t)
    t = re.sub(r'(?<=\d)\s*-\s*(?=\d)', '–', t)

    t = re.sub(r'\s+([,.;:!?])', r'\1', t)
    t = re.sub(r'([,;:])(?!\s)', r'\1 ', t)
    t = re.sub(r'([.!?])([A-Za-z])', r'\1 \2', t)
    t = re.sub(r'\(\s+\)', '', t)
    t = re.sub(r'\(\s+([^\)]+)\s+\)', r'(\1)', t)

    t = re.sub(r'\(\s*[\r\n]+\s*', ' (', t)
    t = re.sub(r'\s*[\r\n]+\s*\)', ')', t)

    t = re.sub(r'(?i)(?<!\w)e\s*[\.\)]?\s*g\s*[\.\)]?(?!\w)\s*[,;:]?', 'e.g., ', t)
    t = re.sub(r'(?i)(?<!\w)i\s*[\.\)]?\s*e\s*[\.\)]?(?!\w)\s*[,;:]?', 'i.e., ', t)

    t = re.sub(r'(?i)\bmmhg\b', 'mmHg', t)
    for ac in ["CPR","AED","ECG","EKG","CT","MRI","ICU","ED","BPH","PDE5","BP","HR","RR","SpO2","O2"]:
        t = re.sub(rf'(?i)\b{ac}\b', ac, t)

    mass = r'(aspirin|paracetamol|acetaminophen|ibuprofen|naproxen|nitroglycerin|insulin|oxygen|water|glucose|caffeine|morphine|adrenaline|epinephrine)'
    blockers = r'(tablet|tablets|capsule|capsules|dose|doses|solution|spray|patch|sublingual|tab|cap|infusion|injection)'
    t = re.sub(rf'(?i)\bthe\s+{mass}\b(?!\s+{blockers})', lambda m: m.group(0)[4:], t)

    t = re.sub(r'([.!?,;:])\1+', r'\1', t)
    t = re.sub(r'\s{2,}', ' ', t).strip()
    return t

def _proofread_with_model(text: str) -> str:
    if not text:
        return text
    prompt = (
        "You are a meticulous medical copy editor.\n"
        "Rewrite the text so that grammar, sentence structure, capitalization, and agreement are correct.\n"
        "Keep meaning, facts, acronyms, dosages, numbers, and units EXACTLY the same.\n"
        "Do not add or remove information. Do not include explanations or meta-comments.\n"
        "Return only the corrected text.\n\n"
        f"Text:\n{text}\n\nCorrected:"
    )
    try:
        raw = generate(prompt, max_new_tokens=2048, temperature=0.0)
    except TypeError:
        raw = generate(prompt)
    out = _safe_text(raw, text)
    out = _strip_meta_overview_speak(out)
    out = _one_off_grammar_sanitize(out)
    return out

def _final_grammar_pass(text: str) -> str:
    if not text:
        return text
    before = _extract_num_units(text)
    edited = _proofread_with_model(text)
    if not edited:
        return text
    edited = _strip_grammar_meta_comments(edited)
    edited = _one_off_grammar_sanitize(edited)
    if not edited.strip():
        return text
    after = _extract_num_units(edited)
    if before != after:
        fallback = _one_off_grammar_sanitize(text)
        return fallback if fallback.strip() else text
    return edited

def _strip_or_fragment_sentences(text: str) -> str:
    if not text:
        return text
    parts = re.split(r'(?<=[.!?])\s+|\n+', text.strip())
    kept = []
    for s in parts:
        st = s.strip()
        if not st:
            continue
        start = re.sub(r'^[\s"\'“”\(\)\[\]\-–—•*]+', '', st)
        if re.match(r'(?i)^or(?:\b|[,:\-–—\s])', start):
            continue
        kept.append(st)
    sep = '\n' if '\n' in text else ' '
    return sep.join(kept)

_MONTH_AGE_ANY_RE = re.compile(
    r'''(?ix)
    \b(
        \d+(?:\.\d+)?\s*(?:months?|mos?|mths?|m/o)\b(?:\s*old|\s*y/o|\s*yo)? |
        \d+\s*[-\s]?(?:month|mo)s?\s*[-\s]?old
    )\b
    '''
)

_YEAR_AGE_ANY_RE = re.compile(
    r'''(?ix)
    \b(
        (?:age\s*)?\d+(?:\.\d+)?\s*(?:years?|yrs?|y(?:/)?o)\b(?:\s*old)? |
        \d+\s*[-\s]?(?:year|yr)s?\s*[-\s]?old
    )\b
    '''
)

_CONTEXT_REQ_RE = re.compile(
    r'(?im)^(?:please|kindly|could you|can you|would you)\b.*\b(context|details|age(?: group)?|location|scenario|more information)\b.*$'
)
_SECTION_LABEL_RE = re.compile(
    r'(?im)^(adult|child(?:ren)?|pediatric(?:s)?|infant|neonate|adolescent|elderly|geriatr(?:ic|ics)|pregnant|male|female)\s*:?\s*$'
)
def _strip_context_prompts_and_labels(text: str) -> str:
    if not text:
        return text
    lines = []
    for ln in text.splitlines():
        s = ln.strip()
        if not s:
            lines.append(ln)
            continue
        if _CONTEXT_REQ_RE.match(s):
            continue
        if _SECTION_LABEL_RE.match(s):
            continue
        lines.append(ln)
    out = "\n".join(lines).strip()
    out = re.sub(r'(?i)^\s*(please|kindly)\s+(?:provide|share|give)\s+(?:more\s+)?(?:context|details|information)[^.?!]*[.?!]\s*', '', out, count=1)
    return out

def format_for_doctorvit(text: str) -> str:
    import re, html

    SENTINEL = "<<<END>>>"

    HEAD_COLON_RE = re.compile(r'^\s*([A-Z][A-Za-z0-9 /&\-\(\)\']+?)\s*:\s*$')
    HEAD_TITLE_RE = re.compile(r'^\s*([A-Z][A-Za-z0-9 /&\-\(\)\']+)\s*$')
    BULLET_RE     = re.compile(r'^\s*(?:[-*•·‣▪◦]|(?:\d+)[\.\)])\s+(.*)$', re.U)
    BRAND_RE      = re.compile(r'^\s*I\s+am\s+DoctorVIT\b', re.I)

    _ORPHANS = r'(white\s+blood\s+cell|red\s+blood\s+cell|hemoglobin|hematocrit)'
    _ORPHAN_LINE   = re.compile(rf'(?mi)^\s*(?:\d+[\.\)]\s*)?{_ORPHANS}\s*\.?\s*$')
    _ORPHAN_INLINE = re.compile(rf'(?i)(?<=\.|\:|\;|\)|\])\s*(?:\d+[\.\)]\s*)?{_ORPHANS}\s*\.?(?=\s|$)')
    _ORPHAN_BULLET = re.compile(rf'(?i)^\s*(?:\d+[\.\)]\s*)?{_ORPHANS}\s*\.?\s*$')

    ASTERISK_LINE = re.compile(r'(?m)^\s*\*+\s*$')
    def _strip_stars(s: str) -> str:
        s = re.sub(r'(?m)[ \t]*\*+\s*$', '', s)
        s = re.sub(r'(?<=\S)\s*\*+(?=(?:\s|$))', '', s)
        return s

    HEAD_INLINE_MULTI = re.compile(
        r'(?P<h>[A-Za-z][A-Za-z0-9/&\-\(\)\']*'
        r'(?:\s+(?:[A-Za-z][A-Za-z0-9/&\-\(\)\']*|and|or|of|to|for|with|the|on|in|by|from|vs\.?)){0,10}):'
    )
    HEAD_INLINE_SINGLE = re.compile(r'\b(?P<h>Disclaimer|Summary|Notes?|Caution|Safety|Warning(?:s)?)\s*:\s*')
    HEAD_SOL_LOOSE = re.compile(
        r'^(?P<h>[A-Za-z][A-Za-z0-9/&\-\(\)\']*'
        r'(?:\s+(?:[A-Za-z][A-Za-z0-9/&\-\(\)\']*|and|or|of|to|for|with|the|on|in|by|from|vs\.?)){0,10}):\s+',
        re.M
    )

    def _balance_parens(s: str) -> str:
        s = re.sub(r'\s+\)', ')', s)
        s = re.sub(r'\(\s+', '(', s)
        while s.count(')') > s.count('('):
            s = re.sub(r'\)(?!.*\))', '', s, count=1)
        while s.count('(') > s.count(')'):
            s2 = re.sub(r'\([^()]*$', '', s)
            if s2 == s:
                s = s.replace('(', '', 1)
                break
            s = s2
        return s

    def _clean_head(h: str) -> str:
        h = re.sub(r'^\(\s*', '', h)
        h = re.sub(r'\)\s*$', '', h)
        return _balance_parens(h)

    def _split_inline_headings(t: str) -> str:
        def repl_multi(m):
            h = m.group('h').strip()
            if len(h) > 72 or len(h.split()) > 12:
                return m.group(0)
            return f'\n{_clean_head(h)}:\n'
        t2 = HEAD_INLINE_MULTI.sub(repl_multi, t)
        def repl_single(m):
            return f'\n{_clean_head(m.group("h").strip())}:\n'
        t2 = HEAD_INLINE_SINGLE.sub(repl_single, t2)
        t2 = HEAD_SOL_LOOSE.sub(lambda m: f"{_clean_head(m.group('h'))}:\n", t2)
        return t2

    _STOPWORDS = {"a","an","the","and","or","of","to","for","with","in","on","by","from","vs","at","as","per"}
    _VERB_LIKE = {"is","are","was","were","be","been","being","have","has","had","do","does","did","include","includes","including","consider","drink","take","eat","aim","avoid","limit"}
    _WORD_RE = re.compile(r"[A-Za-z][A-Za-z'-]*")
    def _words(s: str):
        return _WORD_RE.findall(s)
    def _titlecase_ratio(words):
        if not words: return 0.0
        good = 0
        for w in words:
            if len(w) == 1 and w.isalpha():
                good += 1
            elif w[0].isupper() and w[1:].islower():
                good += 1
        return good / len(words)
    def _looks_like_heading(s: str) -> bool:
        s = s.strip().strip(":")
        if not s or len(s) > 80:
            return False
        if any(ch in s for ch in ",;"):
            return False
        w = _words(s)
        n = len(w)
        if n == 0:
            return False
        if any(x.lower() in _VERB_LIKE for x in w):
            return False
        if n <= 2:
            return True
        if n <= 6 and _titlecase_ratio(w) >= 0.6 and not any(x.lower() in _STOPWORDS for x in w[1:]):
            return True
        return False

    def _is_heading_line(ln: str):
        m = HEAD_COLON_RE.match(ln)
        if m:
            h = _clean_head(m.group(1))
            return h if _looks_like_heading(h) else None
        if len(ln) < 120 and not re.search(r'[.:;!?]$', ln) and HEAD_TITLE_RE.match(ln):
            h = _clean_head(HEAD_TITLE_RE.match(ln).group(1))
            return h if _looks_like_heading(h) else None
        return None

    def _clean_inline_parentheses(s: str) -> str:
        s = re.sub(r"\'\s+s\b", "'s", s)
        s = re.sub(r'\)\s*:', ':', s)
        s = _balance_parens(s)
        s = re.sub(r'\(\s*(?=[,.;:])', '', s)
        s = re.sub(r'\(\s*(initial|starting)\b', r' — \1', s, flags=re.I)
        s = re.sub(r'\(\s*$', '', s)
        s = re.sub(r'\s*\)(?=(?:\s*[—–\-,:;.!?])?\s*$)', '', s)
        return s

    def _join_to_paragraphs(lines):
        out, buf = [], []
        def flush():
            if not buf:
                return
            p = ' '.join(buf)
            p = re.sub(r'\s{2,}', ' ', p).strip()
            p = _ORPHAN_INLINE.sub(' ', p)
            p = _strip_stars(p)
            p = _clean_inline_parentheses(p)
            if p:
                out.append(p)
            buf.clear()

        i = 0
        while i < len(lines):
            ln = lines[i].strip()
            i += 1
            if not ln or ln == ')' or _ORPHAN_LINE.match(ln) or ASTERISK_LINE.match(ln):
                flush()
                continue
            if _is_heading_line(ln) or ln.lower().startswith('disclaimer:'):
                flush()
                out.append(ln)
                continue
            m = BULLET_RE.match(ln)
            if m:
                item_raw = m.group(1).strip()
                if _ORPHAN_BULLET.match(item_raw) or ASTERISK_LINE.match(item_raw):
                    flush()
                    continue
                cont = [item_raw]
                while i < len(lines):
                    nxt = lines[i].rstrip()
                    if not nxt:
                        i += 1
                        break
                    if BULLET_RE.match(nxt) or _is_heading_line(nxt) or nxt.lower().startswith('disclaimer:'):
                        break
                    cont.append(nxt)
                    i += 1
                flush()
                out.append('- ' + ' '.join(cont))
                continue
            if re.match(r'^\d+[\.\)]\s*$', ln):
                continue
            ends_sentence = bool(re.search(r'[.!?]["\')\]]?\s*$', ln))
            buf.append(ln)
            if ends_sentence and ((i < len(lines) and _is_heading_line(lines[i])) or (i < len(lines) and lines[i] == '')):
                flush()
        flush()
        return out

    t = text if isinstance(text, str) else str(text or "")
    t = t.split(SENTINEL, 1)[0]
    t = re.sub(r'\[CONTEXT — DO NOT ECHO\].*?\[/CONTEXT\]', '', t, flags=re.S)
    t = t.replace("\r\n", "\n").replace("\r", "\n")
    t = re.sub(r'(?mi)^\s*clinical\s+specialist\s+advice\s*:?\s*$', 'Clinical Guidance:', t)
    t = re.sub(
        r'(?mi)^\s*([a-z0-9 /&\-\(\)\']+?)\s+advice\s*:?\s*$',
        lambda m: f"{' '.join(w[:1].upper()+w[1:] for w in m.group(1).strip().split())} Advice:",
        t
    )
    t = re.sub(
        r'(?mi)\b([a-z][a-z0-9 /&\-\(\)\']+?)\s*\'\s*s\s+advice\s*:\s*',
        lambda m: f"\n{' '.join(w[:1].upper()+w[1:] for w in m.group(1).strip().split())} Advice:\n",
        t
    )
    t = re.sub(r'\(\s*(?:\n\s*)+', ' (', t)
    t = re.sub(r'(?:\n\s*)+\)', ')', t)
    t = re.sub(r'([^\n])\(\s+(?=\S)', r'\1 (', t)
    t = re.sub(r'([A-Za-z][^\n]*\()\s*(?:\n\s*)+([^\n]*?:)', r'\1\2', t)
    t = re.sub(r'(?<=\.)\s*\d+[\.\)]\s+(?=[A-Za-z])', ' ', t)
    t = _ORPHAN_INLINE.sub(' ', t)
    t = ASTERISK_LINE.sub('', t)
    t = re.sub(r'(?m)[ \t]*\*+\s*$', '', t)
    t = re.sub(r'(?m)^([^\n]{1,120}?):\s*$', lambda m: m.group(1) if not _looks_like_heading(m.group(1)) else m.group(0), t)
    t = _split_inline_headings(t)
    t = re.sub(r'\n{3,}', '\n\n', t)
    t = re.sub(r'^[•·‣▪◦]\s*', '- ', t, flags=re.M)
    t = re.sub(r'(?m)^\s*\d+[\.\)]\s*$', '', t)
    t = re.sub(r'(?m)([^\n])\n\s*\d+[\.\)]\s*(?=\n)', r'\1\n', t)
    t = re.sub(r'(?m)\.\s*\d+[\.\)]\s*(?=\n)', '.', t)
    t = re.sub(r'(?m)\n\s*\d+[\.\)]\s*\n(?=\s*[A-Z][^\n]{0,118}:\s*$)', '\n', t)

    t = t.strip()
    if not t:
        return '<div class="dv-card"><div class="dv-sec"><p>Unknown</p></div></div>'

    lines = _join_to_paragraphs(t.splitlines())

    has_heading = bool(lines and BRAND_RE.match(lines[0])) or any(
        bool(re.match(r'^\s*[A-Z][A-Za-z0-9 /&\-\(\)\']+?\s*:\s*$', ln)) or
        (len(ln) < 120 and not re.search(r'[.:;!?]$', ln) and HEAD_TITLE_RE.match(ln))
        for ln in lines if ln
    )
    if not has_heading:
        lines = ["Clinical Guidance:"] + lines

    parts, in_section, in_list = ['<div class="dv-card">'], False, False

    def close_list():
        nonlocal in_list
        if in_list:
            parts.append('</ul>')
            in_list = False

    def close_section():
        nonlocal in_section
        if in_section:
            close_list()
            parts.append('</div>')
            in_section = False

    def open_section(title: str):
        nonlocal in_section
        close_section()
        parts.append(f'<div class="dv-sec"><h3>{html.escape(title)}:</h3>')
        in_section = True

    def is_heading_line(ln: str):
        m = HEAD_COLON_RE.match(ln)
        if m:
            return m.group(1)
        if len(ln) < 80 and not re.search(r'[.:;!?]$', ln) and HEAD_TITLE_RE.match(ln):
            return HEAD_TITLE_RE.match(ln).group(1)
        return None

    OFFTOPIC_WARN_RE = re.compile(r"(?i)^\s*i am doctorvit\b.*health[-\s]?related questions\b")

    disclaimer_buf = []
    i = 0
    while i < len(lines):
        ln = lines[i]
        if not ln:
            i += 1
            continue

        if ln.lower().startswith("disclaimer:"):
            close_section()
            i += 1
            while i < len(lines) and lines[i] and not is_heading_line(lines[i]):
                disclaimer_buf.append(lines[i]); i += 1
            continue

        h = is_heading_line(ln)
        if h:
            open_section(h)
            i += 1
            continue

        b = BULLET_RE.match(ln)
        if b:
            if not in_section:
                open_section("General Guidance")
            if not in_list:
                parts.append('<ul>'); in_list = True
            core = b.group(1).strip()
            parts.append(f'<li>{html.escape(core)}</li>')
            i += 1
            while i < len(lines) and lines[i].startswith('- '):
                parts.append(f'<li>{html.escape(lines[i][2:].strip())}</li>')
                i += 1
            continue

        if ln.startswith('- '):
            if not in_section:
                open_section("General Guidance")
            if not in_list:
                parts.append('<ul>'); in_list = True
            parts.append(f'<li>{html.escape(ln[2:].strip())}</li>')
            i += 1
            continue

        if not in_section:
            if OFFTOPIC_WARN_RE.match(ln):
                close_list()
                parts.append(f'<p>{html.escape(ln.strip())}</p>')
                i += 1
                while (
                    i < len(lines)
                    and lines[i]
                    and not is_heading_line(lines[i])
                    and not BULLET_RE.match(lines[i])
                    and not lines[i].startswith('- ')
                ):
                    parts.append(f'<p>{html.escape(lines[i].strip())}</p>')
                    i += 1
                continue
            open_section("Clinical Specialist Advice")

        close_list()
        parts.append(f'<p>{html.escape(ln)}</p>')
        i += 1

    close_section()

    if disclaimer_buf:
        parts.append('<div class="dv-sec"><h3>Disclaimer:</h3>')
        for ln in disclaimer_buf:
            if ln.strip():
                parts.append(f'<p>{html.escape(ln.strip())}</p>')
        parts.append('</div>')

    parts.append('</div>')
    return ''.join(parts)

def _repair_topic_prompt(user_q: str) -> str:
    q = (user_q or "").strip()
    return (
        "You are a Board-Certified Specialist Clinician. Answer deterministically, directly, and clinically accurately.\n"
        "Write ONLY one section: 'Clinical Specialist Advice:'.\n"
        "'Clinical Specialist Advice:' MUST be ONE cohesive paragraph in simple clinical language.\n"
        "Stay STRICTLY on this topic: <<TOPIC>>. If any drafted sentence is not directly responsive to <<TOPIC>>, delete it before finalizing.\n"
        "Use at least two specific words or short phrases from <<TOPIC>> verbatim to anchor the explanation.\n"
        "No lists of any kind, no extra headings, no tables, no emojis, no citations, no disclaimers.\n"
        "Briefly define unavoidable medical terms. Do not invent patient data; if details are missing, state what clinicians typically check next.\n"
        "Self-Check Before Final: (1) Every sentence clearly addresses <<TOPIC>>; (2) Exactly one paragraph; (3) No bullets/numbers; (4) No generic wellness filler; (5) At least two anchor words from <<TOPIC>> appear verbatim.\n\n"
        f"User request: {q}\n\n"
        "Clinical Specialist Advice:"
    ).replace("<<TOPIC>>", q)

import re as _re
import traceback

def _strip_instructional_artifacts(text: str) -> str:
    import re as __re

    t = "" if text is None else str(text)

    t = t.replace("<<<END>>>", "")
    t = __re.sub(r"\[CONTEXT\s*[—-]\s*DO NOT ECHO\].*?\[/CONTEXT\]", "", t, flags=__re.S)
    t = __re.sub(r"^(?:User|System|Assistant|Question|Prompt)\s*:\s*.*$", "", t, flags=__re.M)
    t = __re.sub(r"^([A-Z][A-Za-z0-9 /&\-()]{2,70})\s*\([^)\n]{0,120}\)\s*:\s*$", r"\1:", t, flags=__re.M)
    t = __re.sub(r"^\s*Disclaimer\s*\([^)\n]{0,120}\)\s*:\s*$", "Disclaimer:", t, flags=__re.M)

    drop = __re.compile(
        r"^\s*(Output Rules?|Instructions?|Guidelines?|Required Sections?|Sections? ?\(|Provide the following sections|Follow these rules|Write ONLY|Do NOT|Do not|Produce .* now\.?|End exactly with)\s*:?.*$",
        __re.I | __re.M,
    )
    t = "\n".join([ln for ln in t.splitlines() if not drop.match(ln)])

    allowed_headings = (
        "Predictive Diagnosis Guidance",
        "Genetic/High-Risk Pathways and Decision Points",
        "Therapeutic Decision Points and Monitoring Targets",
        "Early Diagnosis Strategy",
        "Procedure Guidance",
        "Clinical Guidance",
        "Disclaimer",
    )
    banned_heading = "Advanced Modalities, Biomarkers, and Decision Points"

    ban_inline = __re.compile(
        r"\b(Therapeutic Options|Counseling Considerations|Follow[- ]?Up|Next Steps|Recommendations|Key Points)\b:?",
        __re.I,
    )

    t = __re.sub(r"(?m)^[ \t]*(?:[•*\-]|\d+[.)])\s+", "", t)

    t = __re.sub(r"(?i)[\s\(\[\-–—]*Advanced Modalities, Biomarkers, and Decision Points[\]\)]*\s*:?", " ", t)
    t = __re.sub(r"[ \t]{2,}", " ", t)

    heading_line_re = __re.compile(r"^[ \t]*([A-Z][A-Za-z0-9 /&–\-(),]{3,70})\s*:?\s*$", __re.M)

    lines = t.splitlines()
    cleaned_body = []
    primary_heading = None

    for ln in lines:
        s = (ln or "").strip()
        if not s:
            cleaned_body.append("")
            continue

        m = heading_line_re.match(s)
        if m:
            hdr = m.group(1).strip()
            if hdr in allowed_headings:
                if primary_heading is None:
                    primary_heading = hdr
                continue
            else:
                continue
        else:
            for h in allowed_headings:
                if h in s and not s.startswith(h) and not s.startswith(h + ":"):
                    if primary_heading is None:
                        primary_heading = h
                    s = s.replace(h, "").strip()
            s = ban_inline.sub("", s)
            s = __re.sub(r"\s{2,}", " ", s).strip()
            if s:
                cleaned_body.append(s)

    t = "\n".join(cleaned_body)

    t = __re.sub(r"[ \t]+\n", "\n", t)
    t = __re.sub(r"\n{3,}", "\n\n", t).strip()
    t = __re.sub(r"([.!?])\s*:\s+(?=\S)", r"\1 ", t)
    t = __re.sub(r"\)\s*:\s+(?=[A-Z])", ") ", t)
    t = __re.sub(r"(?m)^\s*:\s+", "", t)
    t = __re.sub(r"(?<!\n)\n(?!\n)", " ", t)
    t = __re.sub(r"[ \t]{2,}", " ", t).strip()

    if primary_heading:
        t = f"{primary_heading}:\n\n{t}".strip()

    return t

def _split_disclaimer(txt: str):
    m = _re.search(r"(?mi)^\s*Disclaimer\s*:", txt or "")
    if not m:
        return (txt.strip(), "")
    return ((txt[:m.start()] or "").rstrip(), (txt[m.start():] or "").strip())

def _strip_all_disclaimers_from_body(txt: str):
    txt = _re.sub(r"(?mis)^\s*Disclaimer\s*:.*?$", "", txt)
    txt = _re.sub(r"(?mi)^\s*This advice is not a substitute for professional medical care\..*$", "", txt)
    txt = _re.sub(r"(?mi)^\s*Always consult (?:your )?healthcare provider.*$", "", txt)
    txt = _re.sub(r"\n{3,}", "\n\n", txt).strip()
    return txt

def _strip_specialist_titles_in_body(txt: str) -> str:
    import re as _re
    heading_re = _re.compile(r"^[A-Z][A-Za-z0-9 /&–\-(),]{3,70}:\s*$")
    inline_prefix_re = _re.compile(r"(?i)^(?:[A-Z][A-Za-z0-9 /&–\-(),]{3,70})\s+(?:advice|guidance|plan|overview|summary):\s+")
    punct_trim = " '’\"“”`•·-–—"
    out_lines = []
    seen_heading = False
    first_body_seen = False
    for ln in (txt or "").splitlines():
        s = (ln or "").strip()
        if s in {"'", "’", '"', "“", "”", "`"}:
            continue
        if heading_re.match(s):
            if seen_heading:
                continue
            out_lines.append(ln)
            seen_heading = True
            first_body_seen = False
            continue
        s2 = s.lstrip(punct_trim)
        stripped_inline = inline_prefix_re.sub("", s2, count=1)
        if stripped_inline != s2:
            s2 = stripped_inline
        if seen_heading and not first_body_seen and s2:
            s2 = _re.sub(r'^[\'’"“”`]+\s*', "", s2)
        s2 = _re.sub(r'^[\'’"“”`]+\s*', "", s2)
        ln_out = s2
        out_lines.append(ln_out)
        if s2 != "":
            first_body_seen = True
    out = "\n".join(out_lines)
    out = _re.sub(r"\n{3,}", "\n\n", out).strip()
    return out

def _has_section_headings(t: str) -> bool:
    return bool(_re.search(r"(?m)^[A-Z][A-Za-z0-9 /&–\-(),]{3,70}:\s*$", t or ""))

def _sanitize_and_polish(text: str, q_local: str, acro_map, colloc_partners, med_phrases, med_vocab) -> str:
    t = _safe_text(text, q_local)
    t = _filter_age_mismatch(t, q_local)
    t = dose_verification_filter(t)
    t = _strip_sentence_initial_yes(t)
    t = _strip_meta_overview_speak(t)
    t = _correct_phrases_with_corpus(t, med_phrases)
    t = _strip_instructional_artifacts(t)
    structured = _has_section_headings(t)
    t = _strip_role_artifacts(t)
    t = _fix_bodypart_noun_confusions(t)
    t = _normalize_acronyms_in_text(t, acro_map)
    try:
        t = _fix_coordination_collocations(t, colloc_partners)
    except Exception:
        pass
    t = _fix_medical_confusables_general(t)
    t = _apply_general_safety_overrides(t, q_local)
    t = _strip_or_fragment_sentences(t)
    t = _strip_context_prompts_and_labels(t)
    if not structured:
        t = _normalize_numbered_steps(t)
        t = _enumerations_to_bullets(t)
        t = _strip_inline_enumerators(t)
        t = _organize_paragraphs(t)
    t = _final_grammar_pass(t)
    t = _apply_final_polish(t)
    t = _spellfix_med_terms_in_answer(t, med_vocab)
    t = _ensure_professional_overview(t, q_local)
    t = _strip_meta_overview_speak(t)
    t = _final_grammar_pass(t)
    t = _strip_instructional_artifacts(t)
    return t

def _dynamic_token_budget(q_local: str, base=1152, min_tok=640, max_tok=1792):
    L = max(1, len(q_local))
    est = base + min(400, int(0.6 * (L if L < 1200 else 1200)))
    return max(min_tok, min(max_tok, est))

_DIET_Q_RE  = _re.compile(r"(?i)\b(diet|nutrition|meal|diabetes|diabetic|glycemic|keto|calorie|weight|obesity|carb(?:ohydrate)?s?)\b")
_DIET_ANY_RE= _re.compile(r"(?i)\b(sugar|sugary|sweet|sweets|candy|dessert|soda|soft\s*drinks?|corn\s*syrup|fructose|glucose|added\s*sugar|refined\s*carbs?)\b")

def respond_stream(query):
    import traceback
    import re as _re
    import unicodedata

    def _re_sub_multiblank(t: str) -> str:
        return _re.sub(r"\n{3,}", "\n\n", t or "").strip()

    def _strip_instructional_artifacts(text: str) -> str:
        import re as __re
        t = "" if text is None else str(text)
        t = t.replace("<<<END>>>", "")
        t = __re.sub(r"\[CONTEXT — DO NOT ECHO\].*?\[/CONTEXT\]", "", t, flags=__re.S)
        t = __re.sub(r"^(?:User|System|Assistant|Question)\s*:\s*.*$", "", t, flags=__re.M)
        t = __re.sub(r"^([A-Z][A-Za-z0-9 /&\-()]{2,70})\s*\([^)\n]{0,120}\)\s*:\s*$", r"\1:", t, flags=__re.M)
        t = __re.sub(r"^\s*Disclaimer\s*\([^)\n]{0,120}\)\s*:\s*$", "Disclaimer:", t, flags=__re.M)
        drop = __re.compile(r"^\s*(Output Rules?|Instructions?|Guidelines?)\s*:?.*$", __re.I | __re.M)
        t = "\n".join([ln for ln in t.splitlines() if not drop.match(ln)])
        t = __re.sub(r"\n{3,}", "\n\n", t).strip()
        return t

    def _split_disclaimer(txt: str):
        m = _re.search(r"(?mi)^\s*Disclaimer\s*:", txt or "")
        if not m:
            return (txt.strip(), "")
        return ((txt[:m.start()] or "").rstrip(), (txt[m.start():] or "").strip())

    def _strip_all_disclaimers_from_body(txt: str):
        txt = _re.sub(r"(?mis)^\s*Disclaimer\s*:.*?$", "", txt)
        txt = _re_sub_multiblank(txt)
        return txt

    def _sanitize_and_polish(text: str, q_local: str, acro_map, colloc_partners, med_phrases, med_vocab) -> str:
        t = _safe_text(text, q_local)
        t = _filter_age_mismatch(t, q_local)
        t = dose_verification_filter(t)
        t = _strip_sentence_initial_yes(t)
        t = _strip_meta_overview_speak(t)
        t = _correct_phrases_with_corpus(t, med_phrases)
        t = _strip_instructional_artifacts(t)
        structured = bool(_re.search(r"(?m)^[A-Z][A-Za-z0-9 /&–\-(),]{3,70}:\s*$", t or ""))
        t = _strip_role_artifacts(t)
        t = _fix_bodypart_noun_confusions(t)
        t = _normalize_acronyms_in_text(t, acro_map)
        try:
            t = _fix_coordination_collocations(t, colloc_partners)
        except Exception:
            pass
        t = _fix_medical_confusables_general(t)
        t = _apply_general_safety_overrides(t, q_local)
        t = _strip_or_fragment_sentences(t)
        t = _strip_context_prompts_and_labels(t)
        if not structured:
            t = _normalize_numbered_steps(t)
            t = _enumerations_to_bullets(t)
            t = _strip_inline_enumerators(t)
            t = _organize_paragraphs(t)
        t = _final_grammar_pass(t)
        t = _apply_final_polish(t)
        t = _spellfix_med_terms_in_answer(t, med_vocab)
        t = _ensure_professional_overview(t, q_local)
        t = _strip_meta_overview_speak(t)
        t = _final_grammar_pass(t)
        t = _strip_instructional_artifacts(t)
        return t

    def _dynamic_token_budget(q_local: str, base=1152, min_tok=640, max_tok=1792):
        L = max(1, len(q_local))
        est = base + min(400, int(0.6 * (L if L < 1200 else 1200)))
        return max(min_tok, min(max_tok, est))

    _DIET_Q_RE  = _re.compile(r"(?i)\b(diet|nutrition|meal|diabetes|diabetic|glycemic|keto|calorie|weight|obesity|carb(?:ohydrate)?s?)\b")
    _DIET_ANY_RE= _re.compile(r"(?i)\b(sugar|sugary|sweet|sweets|candy|dessert|soda|soft\s*drinks?|corn\s*syrup|fructose|glucose|added\s*sugar|refined\s*carbs?)\b")

    _CLINICAL_INTENT_RE = _re.compile(r"(?ix)\b(diagnos(?:is|e|tic)|rule[-\s]*in|rule[-\s]*out|probab\w*|risk|likelihood|screen(?:ing)?|work[-\s]?up|biopsy|test|threshold|cut[-\s]*off|procedure|treatment|management|plan)\b")
    _CLINICIAN_PHRASE_EXACT = _re.compile(r"(?i)\byou\s+are\s+clinician\b")

    _STOP = {"the","a","an","and","or","but","for","with","without","to","of","in","on","by","at","is","are","was","were","be","can","what","which","who","how","when","why","it","that","this","these","those","about","from","as","into","than","then","so","if","because","while","during","between","within","over","under","again","further","also","not"}

    def _tok_words(s: str):
        return [w for w in _re.findall(r"[a-z]{2,}", (s or "").lower()) if w not in _STOP]

    def _sig_words(s: str, k: int = 6):
        ws = _tok_words(s)
        ws = [w for w in ws if len(w) >= 5]
        seen = set()
        out = []
        for w in sorted(ws, key=lambda x: (-len(x), ws.index(x))):
            if w not in seen:
                seen.add(w)
                out.append(w)
            if len(out) >= k:
                break
        return out

    def _ngrams(tokens, n):
        return {" ".join(tokens[i:i+n]) for i in range(max(0, len(tokens)-n+1))}

    def _lcs_contig_len(a: str, b: str, cap: int = 1000) -> int:
        A = (a or "")[:cap].lower()
        B = (b or "")[:cap].lower()
        if not A or not B:
            return 0
        prev = [0]*(len(B)+1); best = 0
        for x in A:
            curr = [0]
            for j, y in enumerate(B, start=1):
                v = (prev[j-1]+1) if x == y else 0
                curr.append(v)
                if v > best:
                    best = v
            prev = curr
        return best

    def _on_topic(q_local: str, text: str) -> bool:
        if not q_local or not text:
            return True
        q_sig = _sig_words(q_local)
        if q_sig:
            for w in q_sig:
                if _re.search(rf"\b{_re.escape(w)}\b", text, _re.I):
                    return True
        qt = _tok_words(q_local); tt = _tok_words(text)
        if qt and tt:
            if _ngrams(qt, 3) & _ngrams(tt, 3):
                return True
            if _ngrams(qt, 2) & _ngrams(tt, 2):
                return True
        if _lcs_contig_len(q_local, text) >= 18:
            return True
        if len(q_sig) <= 1 and q_sig and _re.search(rf"\b{_re.escape(q_sig[0])}\b", text, _re.I):
            return True
        return False

    def _repair_if_offtopic(q_local: str, body_text: str) -> str:
        if _on_topic(q_local, body_text):
            return body_text
        try:
            raw_r = generate(_repair_topic_prompt(q_local), max_new_tokens=640, temperature=0.0)
        except TypeError:
            raw_r = generate(_repair_topic_prompt(q_local))
        fixed = _sanitize_and_polish(raw_r, q_local, {}, {}, set(), set())
        fixed = _strip_all_disclaimers_from_body(fixed)
        if _on_topic(q_local, fixed) and fixed.strip():
            return fixed
        return body_text

    _HEADING_RE = _re.compile(r"(?m)^[A-Z][A-Za-z0-9 /&–\-(),]{3,70}:\s*$")
    _BULLET_LINE_RE = _re.compile(r"(?m)^\s*(?:•|-|\*|\d+[\.\)]|[a-z]\))\s+")
    _INLINE_LABEL_ANY = _re.compile(r"(?<!\S)([A-Za-z][A-Za-z0-9\+\-/ ]{0,24})\s*:\s+(?=\S)")
    _TRAILING_PUNCT_RE = _re.compile(r"[,:;—–-]+\s*$")
    _POST_PUNCT_CIT_RE = _re.compile(r'([.!?])\s*\b\d{1,2}\b(?=\s*(?:[)\]\}\'"»”]*\s*)(?:[.!?]|$))')
    _POST_CLOSE_CIT_RE = _re.compile(r'([\)\]\}\'"»”])\s*\b\d{1,2}\b(?=\s*(?:[.!?]|$))')
    _BRACKETED_CIT_RE  = _re.compile(r'\[\s*(?:\d{1,3}(?:\s*[-–]\s*\d{1,3})?(?:\s*,\s*\d{1,3}(?:\s*[-–]\s*\d{1,3})?)*)\s*\]')
    _PAREN_CIT_RE = _re.compile(r'\(\s*(?:\d{1,3}(?:\s*[-–]\s*\d{1,3})?(?:\s*,\s*\d{1,3}(?:\s*[-–]\s*\d{1,3})?)*)\s*\)')
    _ENUM_LINE_RE = _re.compile(r'(?m)^[ \t]*(?:\d{1,2}[.)])\s+')

    _UNITS = r'(?:mg|milligrams?|mcg|micrograms?|μg|g|grams?|kg|kilograms?|mL|ml|milliliters?|millilitres?|L|liters?|litres?|IU|U|units?|mmHg|bpm|cm|mm|km|m|mEq|mmol|mol|tablet(?:s)?|capsule(?:s)?|drop(?:s)?|puff(?:s)?|spray(?:s)?|teaspoon(?:s)?|tablespoon(?:s)?|mg/kg|mcg/kg|mg/mL|mcg/mL|°C|°F)'
    _PROTECT_NUM_UNIT = _re.compile(rf'\b\d+(?:\.\d+)?(?:\s*[-–—]\s*\d+(?:\.\d+)?)?\s*{_UNITS}\b', _re.I)
    _PROTECT_SPINE = _re.compile(r'\b[CLTS]\d{1,2}(?:\s*[-–—]\s*[CLTS]?\d{1,2})?\b', _re.I)
    _PROTECT_TIME = _re.compile(r'\b\d+(?:\.\d+)?\s*[- ]?(?:years?|yrs?|y|months?|mos?|weeks?|wks?|days?|d|hours?|hrs?|h)\b', _re.I)

    def _strip_citation_digits(txt: str) -> str:
        t = txt or ""
        protected = {}

        def _protect(regex):
            def repl(m):
                key = f"⟦{len(protected)}⟧"
                protected[key] = m.group(0)
                return key
            return repl

        t = _PROTECT_NUM_UNIT.sub(_protect(_PROTECT_NUM_UNIT), t)
        t = _PROTECT_SPINE.sub(_protect(_PROTECT_SPINE), t)
        t = _PROTECT_TIME.sub(_protect(_PROTECT_TIME), t)

        t = _BRACKETED_CIT_RE.sub('', t)
        t = _PAREN_CIT_RE.sub('', t)
        t = _POST_PUNCT_CIT_RE.sub(r'\1 ', t)
        t = _POST_CLOSE_CIT_RE.sub(r'\1', t)
        t = _ENUM_LINE_RE.sub('', t)
        t = _re.sub(r'[\u00B9\u00B2\u00B3\u2070-\u2079]+', '', t)
        t = _re.sub(r'\s{2,}', ' ', t)

        for k, v in protected.items():
            t = t.replace(k, v)

        return t.strip()

    def _paragraphify_preserve_first_heading(text: str) -> str:
        head = ""
        kept = []
        for ln in (text or "").splitlines():
            s = ln.strip()
            if not s:
                continue
            if not head and _HEADING_RE.match(s):
                head = s
                continue
            s = _BULLET_LINE_RE.sub("", s)
            s = _INLINE_LABEL_ANY.sub("", s)
            if _HEADING_RE.match(s):
                continue
            if s:
                kept.append(s)
        out = " ".join(kept)
        out = _strip_citation_digits(out)
        out = _re.sub(r"\s{2,}", " ", out).strip()
        out = _TRAILING_PUNCT_RE.sub("", out)
        if out and out[-1] not in ".!?":
            out += "."
        return (head + "\n\n" + out).strip() if head else out

    def _paragraphify_one_strict(text: str) -> str:
        kept = []
        for ln in (text or "").splitlines():
            s = ln.strip()
            if not s:
                continue
            if _HEADING_RE.match(s):
                continue
            s = _BULLET_LINE_RE.sub("", s)
            s = _INLINE_LABEL_ANY.sub("", s)
            if s:
                kept.append(s)
        out = " ".join(kept)
        out = _strip_citation_digits(out)
        out = _re.sub(r"\s{2,}", " ", out).strip()
        out = _TRAILING_PUNCT_RE.sub("", out)
        if out and out[-1] not in ".!?":
            out += "."
        return out

    def _looks_fragmentary(body: str) -> bool:
        t = (body or "").strip()
        if not t:
            return True
        sents = [s.strip() for s in _re.split(r'(?<=[.!?])\s+', t) if s.strip()]
        if not sents:
            return True
        short = sum(1 for s in sents if len(s.split()) < 6)
        if short >= 2:
            return True
        if not _re.search(r'[.!?][\'"\)\]]?\s*$', t):
            return True
        return False

    def _rephrase_if_fragmentary(q_local: str, text: str) -> str:
        t0 = (text or "").strip()
        if not t0:
            return t0
        if _looks_fragmentary(t0) and "_dual_rephrase_assist_prompt" in globals():
            try:
                raw = generate(_dual_rephrase_assist_prompt(q_local, t0), max_new_tokens=_dynamic_token_budget(q_local, base=720), temperature=0.0)
            except TypeError:
                raw = generate(_dual_rephrase_assist_prompt(q_local, t0))
            fixed = _sanitize_and_polish(raw, q_local, {}, {}, set(), set())
            fixed = _strip_all_disclaimers_from_body(fixed)
            return fixed.strip() or t0
        return t0

    def _force_route_clinical_exact(q_local: str) -> bool:
        return bool(_CLINICIAN_PHRASE_EXACT.search(q_local or ""))

    q_in = (query or "").strip()
    q = _autocorrect_text(q_in)

    if _needs_dose_answer(q) and (_MONTH_AGE_ANY_RE.search(q) or _YEAR_AGE_ANY_RE.search(q)):
        yield format_for_doctorvit("please Ask dose using words kids, children or adults for maximum accuracy.")
        return

    if _needs_dose_answer(q):
        q = _convert_months_over_12_to_years(q)

    if _needs_dose_answer(q) and _age_is_two_or_under(q):
        yield format_for_doctorvit(
            "Caution (≤2 years): Dosing and administration should be directed by a clinician. Use the supplied oral syringe, verify product strength (mg/mL), and avoid self-dosing without professional advice."
        )
        return

    if not q:
        q = "General health guidance"

    yield "<div style='font-family: system-ui; color:#6b7280; font-size:14px;'>Thinking…</div>"

    try:
        prompt_guard = guard_and_build_prompt(q, "")
        if prompt_guard == "SELF_HARM_SUPPORT":
            out = _self_harm_support_response(q)
            out = _fix_bodypart_noun_confusions(out)
            out = _normalize_acronyms_in_text(out, {})
            out = _fix_medical_confusables_general(out)
            out = _strip_context_prompts_and_labels(out)
            out = _final_grammar_pass(out)
            out = _strip_instructional_artifacts(out)
            yield format_for_doctorvit(out)
            return
        if prompt_guard == "I am DoctorVIT, and I am here only for health-related questions. I cannot answer any requests outside of healthcare or health plan topics. Please rephrase your question to focus on symptoms, first aid, prevention, medication safety, tests, treatment options, or insurance/benefits so I can help responsibly. If anyone is in immediate danger, contact local emergency services now.":
            yield format_for_doctorvit("I am DoctorVIT, and I am here only for health-related questions. I cannot answer any requests outside of healthcare or health plan topics. Please rephrase your question to focus on symptoms, first aid, prevention, medication safety, tests, treatment options, or insurance/benefits so I can help responsibly. If anyone is in immediate danger, contact local emergency services now.")
            return

        if _force_route_clinical_exact(q):
            routed = route_specialty(q, "", use_verifier=True, use_learner=True) if "route_specialty" in globals() else {}
            role_label = _specialty_label_from_bucket((routed.get("specialty") or "").lower()) if routed and routed.get("specialty") else "clinician"
            prompt = _mk_clinical(role_label, "", "", "", q)
            try:
                raw_forced = generate(prompt, max_new_tokens=_dynamic_token_budget(q, base=1152), temperature=0.0)
            except TypeError:
                raw_forced = generate(prompt)
            final_text = _sanitize_and_polish(raw_forced, q, {}, {}, set(), set())
            body, disc = _split_disclaimer(final_text)
            body = _strip_all_disclaimers_from_body(body)
            body = _paragraphify_one_strict(body)
            body = _rephrase_if_fragmentary(q, body)
            body = _repair_if_offtopic(q, body)
            disc = (disc or "").strip()
            yield format_for_doctorvit(body + (("\n\n" + disc) if disc else ""))
            return

        ctx_all = unicodedata.normalize("NFKC", f"{''}\n{q or ''}")
        is_ins = ("_is_insurance_audience" in globals() and _is_insurance_audience(ctx_all))

        if is_ins and "_mk_insurance" in globals():
            try:
                raw_ins = generate(_mk_insurance("insurance", "", "", "", q), max_new_tokens=_dynamic_token_budget(q, base=1152), temperature=0.0)
            except TypeError:
                raw_ins = generate(_mk_insurance("insurance", "", "", "", q))
            final_ins = _sanitize_and_polish(raw_ins, q, {}, {}, set(), set())
            body, disc = _split_disclaimer(final_ins)
            body = _strip_all_disclaimers_from_body(body)
            body = _strip_citation_digits(body)
            body = _repair_if_offtopic(q, body)
            disc = (disc or "").strip()
            yield format_for_doctorvit((body or "").strip() + (("\n\n" + disc) if disc else ""))
            return

        halves = _parse_dual_contrast(q or "")

        try:
            med_vocab = set()
            med_phrases = set()
            acro_seed = globals().get("_SEEDED_ACRO", {}) or {}
            acro_map = _merge_acro_maps(acro_seed, {}) if "_merge_acro_maps" in globals() else dict(acro_seed)
            seed_collocs = globals().get("_SEED_COLLOCATIONS", []) or []
            if "_build_colloc_partner_map" in globals():
                colloc_partners = _build_colloc_partner_map(seed_collocs, [])
            else:
                colloc_partners = {}
                if isinstance(seed_collocs, dict):
                    colloc_partners = seed_collocs
                elif isinstance(seed_collocs, list):
                    for item in seed_collocs:
                        if isinstance(item, (list, tuple)) and len(item) >= 2:
                            anchor = str(item[0]).lower()
                            partners = item[1] if isinstance(item[1], (list, tuple, set)) else item[1:]
                            colloc_partners.setdefault(anchor, set()).update([str(p).lower() for p in partners])
        except Exception:
            med_vocab, med_phrases, acro_map, colloc_partners = set(), set(), {}, {}

        if halves:
            qa, qb = halves
            p_a = _detect_specialty(qa, "") or guard_and_build_prompt(qa, "")
            p_b = _detect_specialty(qb, "") or guard_and_build_prompt(qb, "")

            def _gen_min(prompt_text, q_local):
                try:
                    rr = generate(prompt_text, max_new_tokens=_dynamic_token_budget(q_local, base=896), temperature=0.0)
                except TypeError:
                    rr = generate(prompt_text)
                return _sanitize_and_polish(rr, q_local, acro_map, colloc_partners, med_phrases, med_vocab)

            a_txt = _self_harm_support_response(qa) if p_a == "SELF_HARM_SUPPORT" else _gen_min(p_a, qa)
            b_txt = _self_harm_support_response(qb) if p_b == "SELF_HARM_SUPPORT" else _gen_min(p_b, qb)

            a_body, a_disc = _split_disclaimer(a_txt); a_body = _strip_all_disclaimers_from_body(a_body)
            b_body, b_disc = _split_disclaimer(b_txt); b_body = _strip_all_disclaimers_from_body(b_body)
            disclaimer = (b_disc or a_disc or "").strip()

            combined_body = "\n\n".join([x for x in [a_body.strip(), b_body.strip()] if x])

            try:
                reph_raw = generate(_dual_rephrase_assist_prompt(q, combined_body), max_new_tokens=_dynamic_token_budget(q, base=960), temperature=0.0)
            except TypeError:
                reph_raw = generate(_dual_rephrase_assist_prompt(q, combined_body))
            reph_txt = _sanitize_and_polish(reph_raw, q, acro_map, colloc_partners, med_phrases, med_vocab)

            body_reph, disc_reph = _split_disclaimer(reph_txt)
            body_reph = _strip_all_disclaimers_from_body(body_reph)
            final = (body_reph or combined_body).strip()
            final = _paragraphify_preserve_first_heading(final)
            final = _rephrase_if_fragmentary(q, final)
            final = _repair_if_offtopic(q, final)
            disc_final = (disclaimer or disc_reph or "").strip()
            yield format_for_doctorvit(final + (("\n\n" + disc_final) if disc_final else ""))
            return

        one_shot_prompt = build_dual_contrast_specialist(q, "") or guard_and_build_prompt(q, "")

        try:
            raw = generate(one_shot_prompt, max_new_tokens=_dynamic_token_budget(q, base=1152), temperature=0.0)
        except TypeError:
            raw = generate(one_shot_prompt)

        final_text = _sanitize_and_polish(raw, q, acro_map, colloc_partners, med_phrases, med_vocab)

        if not _DIET_Q_RE.search(q) and _DIET_ANY_RE.search(final_text) and "_repair_topic_prompt" in globals():
            try:
                raw_r = generate(_repair_topic_prompt(q), max_new_tokens=640, temperature=0.0)
            except TypeError:
                raw_r = generate(_repair_topic_prompt(q))
            fixed = _sanitize_and_polish(raw_r, q, acro_map, colloc_partners, med_phrases, med_vocab)
            if fixed.strip():
                final_text = fixed

        if not final_text.strip() and "_repair_med_prompt" in globals():
            try:
                raw2 = generate(_repair_med_prompt(q, ""), max_new_tokens=896, temperature=0.0)
            except TypeError:
                raw2 = generate(_repair_med_prompt(q, ""))
            final_text = _sanitize_and_polish(raw2, q, acro_map, colloc_partners, med_phrases, med_vocab)

        body, disc = _split_disclaimer(final_text)
        body = _strip_all_disclaimers_from_body(body)
        body = _paragraphify_preserve_first_heading(body)
        body = _rephrase_if_fragmentary(q, body)
        body = _repair_if_offtopic(q, body)
        disc = (disc or "").strip()
        yield format_for_doctorvit(body + (("\n\n" + disc) if disc else ""))

    except Exception:
        err = traceback.format_exc()
        yield format_for_doctorvit("An error occurred while generating the answer.\n" + err)

import gradio as gr
import html

with gr.Blocks(
    title=TITLE,
    css="""
#doctorvit .gradio-container {max-width: 980px !important;}
#doctorvit .gr-button {height: 48px; border-radius: 12px;}
#doctorvit p {margin: .75rem 0;}

#doctorvit .dv-card{background:#fff;border:1px solid #e5e7eb;border-radius:14px;padding:18px 20px;box-shadow:0 1px 2px rgba(0,0,0,.04)}
#doctorvit .dv-sec + .dv-sec{margin-top:10px}
#doctorvit .dv-sec h3{margin:8px 0 4px;font-size:15px;font-weight:700;color:#0f172a}
#doctorvit .dv-sec p{margin:6px 0;line-height:1.6;color:#0f172a}
#doctorvit .dv-sec ul{margin:6px 0 0 20px; list-style: disc; padding-left: 1.25rem;}
#doctorvit .dv-sec li{margin:2px 0}
"""
) as demo:

    with gr.Column(elem_id="doctorvit"):
        try:
            if 'model' in globals():
                wiring_text = validate_activation_wiring(model)["summary"]
            else:
                wiring_text = "Model not loaded yet — activation wiring summary unavailable."
        except Exception as e:
            wiring_text = f"Wiring check failed: {type(e).__name__}: {e}"

        gr.HTML(f"""
        <div style="font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto; margin:8px 0 10px 0;">
            <div style="font-size:22px; font-weight:500; margin:0;">{html.escape(TITLE)}</div>
            <div style="color:#475569; margin-top:2px; font-weight:400;">{html.escape(DESC)}</div>
            <div style="margin-top:10px; padding:10px 12px; background:#f8fafc; color:#0f172a; border:1px solid #e5e7eb; border-radius:12px;">
                {html.escape(wiring_text)}
            </div>
        </div>
        """)

        with gr.Row():
            query = gr.Textbox(
                label="Ask your question",
                placeholder="Ask only healthcare question…",
                lines=3,
                autofocus=True
            )

        with gr.Row():
            go = gr.Button("Generate", variant="primary")
            clr = gr.Button("Clear")

        out = gr.HTML(label="Answer")

        go.click(fn=respond_stream, inputs=[query], outputs=out)
        query.submit(fn=respond_stream, inputs=[query], outputs=out)

        def _clear():
            return gr.update(value=""), gr.update(value="")
        clr.click(_clear, inputs=None, outputs=[query, out])

port = _pick_port(7860, 30)
_free_port(port)
demo.queue()
demo.launch(server_name="0.0.0.0", server_port=port, share=True)